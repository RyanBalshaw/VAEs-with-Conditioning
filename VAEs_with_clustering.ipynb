{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAEs_with_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH3oUpu+eWfnkVgWVvMr7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanBalshaw/VAEs-with-Conditioning/blob/main/VAEs_with_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGxPR-DJgWha"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFlOlkXqvj2Z"
      },
      "source": [
        "VaDE versus CURL:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The differences are minor, you can easily show that the two are the same. Write this up at some point for reference.\n",
        "\n",
        "VaDE objective function:\n",
        "\\begin{equation}\n",
        "L_{VaDE} = \\mathbb{E}_{q(\\mathbf{z}\\vert\\mathbf{x})}\\left[ \\log p(\\mathbf{x}\\vert\\mathbf{z}) \\right] - \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ KL(q(\\mathbf{z}\\vert\\mathbf{x}))\\Vert p(\\mathbf{z}\\vert \\mathbf{y}))\\right] - KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))\n",
        "\\end{equation}\n",
        "\n",
        "CURL objective function:\n",
        "\\begin{equation}\n",
        "L_{CURL} = \\mathbb{E}_{q(\\mathbf{z}\\vert\\mathbf{x}, \\mathbf{y})q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ \\log p(\\mathbf{x}\\vert\\mathbf{z}) \\right] - \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ KL(q(\\mathbf{z}\\vert\\mathbf{x}, \\mathbf{y}))\\Vert p(\\mathbf{z}\\vert \\mathbf{y}))\\right] - KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))\n",
        "\\end{equation}\n",
        "\n",
        "Important notes:\n",
        "- Decoder: $p(\\mathbf{x}\\vert\\mathbf{z}) \\sim \\mathcal{N}(\\mathbf{x}\\vert \\mathbf{\\mu}(\\mathbf{z}), \\mathbf{\\sigma}^2(\\mathbf{z})\\mathbf{I})$\n",
        "- Encoder: $q_{VaDE}(\\mathbf{z}\\vert \\mathbf{x}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{x}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{x})\\mathbf{I})$ OR $q_{CURL}(\\mathbf{z}\\vert \\mathbf{x}, \\mathbf{y}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{x}, \\mathbf{y}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{x}, \\mathbf{y})\\mathbf{I})$\n",
        "- Prior $p(\\mathbf{z}\\vert\\mathbf{y}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{y}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{y})\\mathbf{I}))$\n",
        "\n",
        "- Prior $p(\\mathbf{y}) \\sim Cat(\\mathbf{\\pi})$ = $\\prod_{k=1}^{K}\\pi_k^{z_k}$\n",
        "\n",
        "The final component is to define $q(\\mathbf{y}\\vert\\mathbf{x})$. VaDE and CURL take vastly different approaches:\n",
        "\n",
        "for VaDE:\n",
        "$q(\\mathbf{y}\\vert\\mathbf{x}) = p(\\mathbf{y}\\vert\\mathbf{z}) = \\frac{p(\\mathbf{y})p(\\mathbf{z}\\vert\\mathbf{y})}{\\sum_{i=1}^Kp(\\mathbf{y})p(\\mathbf{z}\\vert\\mathbf{y})},$\n",
        "\n",
        "where this equation also features in linear mixture models. This term is the posterior probability for y given an observation.\n",
        "\n",
        "For CURL:\n",
        "$q(\\mathbf{y}\\vert\\mathbf{x})$ is part of the encoder, with a softmax 'task inference' head. I like this formulation a little less as I am not convinced that it works well.\n",
        "\n",
        "Why do I say this? Well I noted one potentially problematic area in how CURL estimates the 'categorical regulariser'. From their code, they take a batch and take the average of the argmax of the labels $\\mathbf{y}$, essentially estimating the batch class likelihood. The problem here is that it is not given that a batch will have equal samples from each 'hidden class', so I am not sure how useful this will be when there are unequal spread in the classes. Maybe you need to perform some pre-training inference for the prior $p(\\mathbf{y})$.\n",
        "\n",
        "It is natural, for the continuous distribution $q(\\mathbf{z}\\vert\\cdots)$, to take a Monte Carlo estimate. However, the addition of the distribution categorial distribution, any expectation over $q(\\mathbf{y}\\vert\\mathbf{x})$ then becomes a summation over K indices of the term in the expectation weighted by $q(\\mathbf{y}=i\\vert\\mathbf{x})$.\n",
        "\n",
        "Furthermore, for the middle KL divergence term, both distributions in the KL divergence are Gaussian and thus the KL divergence becomes:\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\left( tr(\\Sigma_1^{-1}\\Sigma_0) + (\\mathbf{\\mu}_1 - \\mathbf{\\mu}_0)^T\\Sigma_1^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_0) - k + \\log\\left(\\frac{det\\Sigma_1}{det\\Sigma_2}\\right) \\right)$,\n",
        "\n",
        "where $\\mathcal{N}_0\\sim\\mathcal{N}(\\mathbf{\\mu}_0, \\Sigma_0)$, $\\mathcal{N}_1\\sim\\mathcal{N}(\\mathbf{\\mu}_1, \\Sigma_1)$ and $k$ is the dimensionality of the space covered by the distribution. If $\\Sigma_1$ and $\\Sigma_2$ are parametrised as diagonal covariance distributions $\\Sigma_0 = \\mathbf{\\sigma_0^2}\\mathbf{I}$ and $\\Sigma_1 = \\mathbf{\\sigma_1^2}\\mathbf{I}$ then\n",
        "\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\left( \\sum_{i} \\frac{\\sigma^2_{0,i}}{\\sigma^2_{1,i}} + \\sum_i\\left(\\frac{\\mu_{1,i} - \\mu_{0,i})^2}{\\sigma^2_{1,i}}\\right)  - k + \\sum_i \\log\\left(\\frac{\\sigma^2_{1, i}}{\\sigma^2_{0, i}}\\right)  \\right)$,\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\sum_{i}\\left(  \\frac{\\sigma^2_{0,i}}{\\sigma^2_{1,i}} + \\left(\\frac{\\mu_{1,i} - \\mu_{0,i})^2}{\\sigma^2_{1,i}}\\right)  - 1 +  \\log\\left(\\frac{\\sigma^2_{1, i}}{\\sigma^2_{0, i}}\\right)  \\right)$,\n",
        "\n",
        "Finally, the final KL divergence term can be expanded as follows:\n",
        "$=\\sum_{k=1}^K q(\\mathbf{y}=k\\vert\\mathbf{x}) \\log \\left( \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{p(\\mathbf{y}=k)} \\right)$\n",
        "\n",
        "\n",
        "Let's now focus on the final KL term $KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))$. Since we know that this regularises the posterior conditional probability (i.e. the conditional probability given a sample from $\\mathbf{x}$, which is actually a $\\mathbf{z}$ if you think about where the MoG lies), we need a method to evaluate the KL term. The expansion of the term is straightforward:\n",
        "\n",
        "$KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}[\\left( \\log \\frac{q(\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})} \\right)]$\n",
        "\n",
        "and since y is discrete:\n",
        "\n",
        "$KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{p(\\mathbf{y}=k)} \\right) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{\\pi_k} \\right)$.\n",
        "\n",
        "So, what do CURL and VaDE do? VaDE tries to estimate $p(\\mathbf{y}=k\\vert\\mathbf{x})$ for each $\\mathbf{x}$ while CURL uses a batch-estimated posterior and effectively directly parametrises $q(\\mathbf{y}\\vert\\mathbf{x}) = \\prod_{k=1}^{K} \\gamma_{k}^{y_k}$, where $\\gamma_{k}$ is the batch estimated class likelihood. \n",
        "\n",
        "I just realised there is an alternative derivation, unlike VaDE or CURL, one which allows one to use a cross-entropy term. Let's dissect the KL term even more: since we know $\\pi_k$ is a constant scalar, we can separate the terms nicely:\n",
        "\n",
        "$ KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log q(\\mathbf{y}=k\\vert\\mathbf{x}) \\right) -  \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\log \\left( \\pi_k \\right) $\n",
        "\n",
        "where the term on the right can be grouped with the $q(\\mathbf{y}\\vert\\mathbf{x})$ terms in the previous objective functions. This leaves us with $\\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log q(\\mathbf{y}=k\\vert\\mathbf{x}) \\right)$. What do we do with this? Well if we think about it a little, this is simply the negative of the entropy $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$, which can be considered as a cross-entropy loss. However, the difference is that we do not have labels and the labels, although they should be 1-of-K, will not be. Thus, it is better to leave it as the entropy. I believe Tensorflows softmax_cross_entropy_with_logits is better suited.\n",
        "\n",
        "At the end of the day, I think simply taking the loss at face value is the way to proceed, monitoring $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$ will be useful as this will tell us if any information is encoded into $\\mathbf{y}$, or if it is just left as is by the model. We want to minimize $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$, which the objective function does do for us when we maximise the ELBO (if you follow the signs for - $KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))$), which is a positive.\n",
        "\n",
        "I found the following [entropy](https://adventuresinmachinelearning.com/cross-entropy-kl-divergence/) guide, [tensorflow](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) implementation, [pytorch](https://discuss.pytorch.org/t/equivalent-of-tensorflows-sigmoid-cross-entropy-with-logits-in-pytorch/1985) vs [tensorflow](https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop/39499486#39499486) discussion and [cross-entropy](https://sebastianraschka.com/faq/docs/pytorch-crossentropy.html) discussion useful.\n",
        "\n",
        "To make something clear: The loss we want to end up _minimising_ is $ KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))$ (as the ELBO is maximum when this term is zero [i.e. it detracts from the ELBO]) is the entropy $\\mathcal{H}(\\mathbf{y}\\vert\\mathbf{x})) -  \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\log \\left( \\pi_k \\right) $\n",
        "\n",
        "\n",
        "The alternative derivation was inspired by the semi-supervised paper by Kingma: Kingma DP, Rezende DJ, Mohamed S, Welling M (2014) Semi-supervised learning with deep generative models. Adv Neural Inf Process Syst 4:3581–3589\n",
        "\n",
        "Another thing I just realised is, what if your latent space is large? You may end up with overflow or underflow errors when calculating $q(\\mathbf{y}\\vert\\mathbf{x})$ for the VaDE case. How do we overcome this?\n",
        "\n",
        "Assuming we have access to $\\log p(\\mathbf{z}\\vert\\mathbf{y})$ (which is a Gaussian, so of course we do), we can use the log-sum-exponential trick to calculate the denominator term. However, this will leave a log in the front of $q(\\mathbf{y}\\vert\\mathbf{x})$ (as we design it to be $\\log q(\\mathbf{y}=k\\vert\\mathbf{x}) = \\frac{\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)}{\\log \\left(\\sum_{k=1}^{K}\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k) \\right)}$ and apply log-sum-exp to the denominator). Then, it is as simple to subtract the LSE from the individually weighted logarithms ($\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)$) and take the exponential of this function.\n",
        "\n",
        "In summary: $\\text{exp}(\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)) - LSE(denominator)) = \\text{exp}(\\log (\\pi_k) + \\log( p(\\mathbf{z}\\vert\\mathbf{y} = k)) - LSE(denominator))$. You will have to validate the numerical stability of this though... Check this [source](https://angusturner.github.io/generative_models/2017/11/03/pytorch-gaussian-mixture-model.html) which also does this and this [source](https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/) which discusses it more directly.\n",
        "\n",
        "Some more things to think about (this is getting messy, I know): VaDE only needs expansion for the KL divergence between the categorical distribution, and you can use Gumbel-Softmax to stop the requirement for the loss to be sampled $K$ times! It effectively omits the $\\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}$ step. \n",
        "\n",
        "How does it work? It simply replaces the expectation over a discrete distribution with a continuous equivalent, which then allows us  to perform a Monte Carlo estimate, which just reduces to taking one sample. Very useful for the CURL method!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLM8vRjkG-m"
      },
      "source": [
        "def apply_MLP_to_source(source,\n",
        "                        num_layer,\n",
        "                        num_segment = None,\n",
        "                        iter4condthresh = 10000,\n",
        "                        cond_thresh_ratio = 0.25,\n",
        "                        layer_name_base = 'ip',\n",
        "                        save_layer_data = False,\n",
        "                        Arange=None,\n",
        "                        nonlinear_type = 'ReLU',\n",
        "                        negative_slope = 0.2,\n",
        "                        random_seed=0):\n",
        "    \"\"\"Generate MLP and Apply it to source signal.\n",
        "    Args:\n",
        "        source: source signals. 2D ndarray [num_comp, num_data]\n",
        "        num_layer: number of layers\n",
        "        num_segment: (option) number of segments (only used to modulate random_seed)\n",
        "        iter4condthresh: (option) number of random iteration to decide the threshold of condition number of mixing matrices\n",
        "        cond_thresh_ratio: (option) percentile of condition number to decide its threshold\n",
        "        layer_name_base: (option) layer name\n",
        "        save_layer_data: (option) if true, save activities of all layers\n",
        "        Arange: (option) range of value of mixing matrices\n",
        "        nonlinear_type: (option) type of nonlinearity\n",
        "        negative_slope: (option) parameter of leaky-ReLU\n",
        "        random_seed: (option) random seed\n",
        "    Returns:\n",
        "        mixedsig: sensor signals. 2D ndarray [num_comp, num_data]\n",
        "        mixlayer: parameters of mixing layers\n",
        "    \"\"\"\n",
        "    if Arange is None:\n",
        "        Arange = [-1, 1]\n",
        "    #print(\"Generating sensor signal...\")\n",
        "\n",
        "    # Subfuction to normalize mixing matrix\n",
        "    def l2normalize(Amat, axis=0):\n",
        "        # axis: 0=column-normalization, 1=row-normalization\n",
        "        l2norm = np.sqrt(np.sum(Amat*Amat,axis))\n",
        "        Amat = Amat / l2norm\n",
        "        return Amat\n",
        "\n",
        "    # Initialize random generator\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # To change random_seed based on num_layer and num_segment\n",
        "    for i in range(num_layer):\n",
        "        np.random.rand()\n",
        "\n",
        "    if num_segment is not None:\n",
        "        for i in range(num_segment):\n",
        "            np.random.rand()\n",
        "\n",
        "    num_comp = source.shape[0]\n",
        "\n",
        "    # Determine condThresh ------------------------------------\n",
        "    condList = np.zeros([iter4condthresh])\n",
        "    \n",
        "    for i in range(iter4condthresh):\n",
        "        A = np.random.uniform(Arange[0],Arange[1],[num_comp,num_comp])\n",
        "        A = l2normalize(A, axis=0)\n",
        "        condList[i] = np.linalg.cond(A)\n",
        "\n",
        "    condList.sort() # Ascending order\n",
        "    condThresh = condList[int(iter4condthresh * cond_thresh_ratio)]\n",
        "    #print(\"    cond thresh: {0:f}\".format(condThresh))\n",
        "\n",
        "    # Generate mixed signal -----------------------------------\n",
        "    mixedsig = source.copy()\n",
        "    mixlayer = []\n",
        "    for ln in range(num_layer-1,-1,-1):\n",
        "\n",
        "        # Apply nonlinearity ----------------------------------\n",
        "        if ln < num_layer-1: # No nolinearity for the first layer (source signal)\n",
        "            if nonlinear_type == \"ReLU\": # Leaky-ReLU\n",
        "                mixedsig[mixedsig<0] = negative_slope * mixedsig[mixedsig<0]\n",
        "            else:\n",
        "                raise ValueError\n",
        "\n",
        "        # Generate mixing matrix ------------------------------\n",
        "        condA = condThresh + 1\n",
        "        while condA > condThresh:\n",
        "            A = np.random.uniform(Arange[0], Arange[1], [num_comp, num_comp])\n",
        "            A = l2normalize(A)  # Normalize (column)\n",
        "            condA = np.linalg.cond(A)\n",
        "            #print(\"    L{0:d}: cond={1:f}\".format(ln, condA))\n",
        "        # Bias\n",
        "        b = np.zeros([num_comp]).reshape([1,-1]).T\n",
        "\n",
        "        # Apply bias and mixing matrix ------------------------\n",
        "        mixedsig = mixedsig + b\n",
        "        mixedsig = np.dot(A, mixedsig)\n",
        "\n",
        "        # Storege ---------------------------------------------\n",
        "        layername = layer_name_base + str(ln+1)\n",
        "        mixlayer.append({\"name\":layername, \"A\":A.copy(), \"b\":b.copy()})\n",
        "        # Storege data\n",
        "        if save_layer_data:\n",
        "            mixlayer[-1][\"x\"] = mixedsig.copy()\n",
        "\n",
        "    return mixedsig, mixlayer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ8e7-cmkKou"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "        \n",
        "class iVAE_datasets(object):\n",
        "    \n",
        "    def __init__(self, n, M, Lsegments, k, batch_size = 64, randomise = True, random_seed = False, mod_flag = False, mix_L = 1, Gauss_source = True, seed = True):\n",
        "        \"\"\"\n",
        "        n = size of latent space\n",
        "        M = no. classes\n",
        "        Lsegments = no. samples per class\n",
        "        k = no. of prior parameters\n",
        "            k = 1: variance Gaussian\n",
        "            k = 2: mean and variance gaussian\n",
        "        mod_flag = case where one signal has mean modulation and the other doesn't\n",
        "        \"\"\"\n",
        "        self.latent_size = n\n",
        "        self.no_classes = M\n",
        "        self.no_samples = Lsegments\n",
        "        self.k = k\n",
        "        self.batch_size = batch_size #specifies the batch size\n",
        "        self.randomise = randomise #Specifies that sample must be obtained randomly (not uniformly)\n",
        "        self.random_seed = random_seed #If random_seed = True - specifies that a random sample is required and the counter is not increased!\n",
        "        self.mod_flag = mod_flag\n",
        "        self.mix_L = mix_L\n",
        "        self.Gauss_source = Gauss_source\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        #Define mixing model (Unused)\n",
        "        #self.mixing_model = mixing_MLP(self.latent_size, 1)\n",
        "        #self.mixing_model.to(self.device)\n",
        "        #print(self.mixing_model)\n",
        "        \n",
        "        if self.k == 1 and not self.mod_flag:\n",
        "            #print(\"\\nVariance modulated sources.\\n\")\n",
        "            self.mu_centers = np.zeros((self.no_classes, self.latent_size))\n",
        "            \n",
        "        elif self.k == 2 and not self.mod_flag:\n",
        "            #print(\"\\nMean and variance modulated sources.\\n\")\n",
        "            if seed:\n",
        "                np.random.seed(2**13 + 4)\n",
        "\n",
        "            self.mu_centers = np.random.rand(self.no_classes, self.latent_size) * 10 - 5         # in range (-5, 5)\n",
        "            self.mu_centers += np.sign(self.mu_centers) * 5 #Shift centers a outwards a little\n",
        "       \n",
        "        else:\n",
        "            self.mu_centers = np.zeros((self.no_classes, self.latent_size))\n",
        "            \n",
        "            list_range = np.arange(0, self.no_classes, 1)\n",
        "            np.random.shuffle(list_range) #random permutation gamma(u)\n",
        "            \n",
        "            a = np.random.random() * 10 - 5\n",
        "            \n",
        "            self.mu_centers[:, 1] =  a * list_range\n",
        "            \n",
        "        if not hasattr(self, \"std_centers\"):\n",
        "            self.std_centers = np.random.rand(self.no_classes, self.latent_size) * 2.5 + 0.5      # in range (0.5, 3)\n",
        "        \n",
        "        #Make the sample labels\n",
        "        self.sample_labels = []\n",
        "        for i in range(self.no_classes):\n",
        "            self.sample_labels += [i] * self.no_samples\n",
        "        self.sample_labels = np.array(self.sample_labels)\n",
        "\n",
        "        self.data = torch.from_numpy(self.sample()).to(self.device)\n",
        "        \n",
        "        #Normalise      \n",
        "        self.data_mean = torch.mean(self.data, dim = 0)\n",
        "        self.data_std = torch.std(self.data, dim = 0)\n",
        "        \n",
        "        self.data = (self.data - self.data_mean) / self.data_std\n",
        "\n",
        "        mixed_data, mix_layer = apply_MLP_to_source(self.data.cpu().numpy().T, self.mix_L, num_segment = self.no_classes)\n",
        "        mixed_data = torch.from_numpy(mixed_data.T).float()\n",
        "\n",
        "        self.mix_layer = mix_layer \n",
        "\n",
        "        if self.mod_flag:\n",
        "            self.mixed_data = torch.hstack((mixed_data[:, [0]], self.data[:, [1]]))\n",
        "        \n",
        "        else:\n",
        "            self.mixed_data = mixed_data\n",
        "        \n",
        "        #Add noise\n",
        "        self.mixed_data += torch.randn_like(self.mixed_data) * 0.01\n",
        "        \n",
        "        self.data_tuples = list(zip(self.data, self.sample_labels)) #list of tuples\n",
        "        self.mixed_data_tuples = list(zip(self.mixed_data, self.sample_labels)) #list of tuples\n",
        "\n",
        "        #shuffle mixed_data\n",
        "        self.shuffled_data_index = np.arange(0, self.mixed_data.size(0), 1, dtype = int)\n",
        "\n",
        "        if self.random_seed:\n",
        "            np.random.shuffle(self.shuffled_data_index)\n",
        "\n",
        "        #Convert self.sample_labels to torch.tensor\n",
        "        self.sample_labels = torch.from_numpy(self.sample_labels)\n",
        "    \n",
        "    def sample(self):\n",
        "        selected_centers = self.sample_labels\n",
        "        \n",
        "        latent_sample = self.mu_centers[selected_centers, :]\n",
        "\n",
        "        if self.Gauss_source:\n",
        "            latent_sample += np.random.randn(len(selected_centers), self.latent_size) * self.std_centers[selected_centers, :]\n",
        "        elif not self.Gauss_source and self.latent_size == 2:\n",
        "            s1 = np.random.laplace(loc = 0, scale = self.std_centers[selected_centers, 0]).reshape(-1, 1)\n",
        "            s2 = np.random.laplace(loc = 0, scale = self.std_centers[selected_centers, 1]).reshape(-1, 1)\n",
        "            latent_sample += np.hstack((s1, s2))\n",
        "        return latent_sample.astype(np.float32)\n",
        "    \n",
        "    #turn the class into an iterator\n",
        "    def __iter__(self):\n",
        "        \n",
        "        self.iter_cnt = 0 #initialises the iterator\n",
        "        return self #returns the iterator object\n",
        "    \n",
        "    def __next__(self):\n",
        "\n",
        "        if not self.random_seed:\n",
        "            start = self.iter_cnt * self.batch_size\n",
        "            end = start + self.batch_size\n",
        "\n",
        "            index = self.shuffled_data_index[start:end]\n",
        "\n",
        "            if end <= len(self.mixed_data_tuples):\n",
        "\n",
        "                self.iter_cnt += 1\n",
        "                \n",
        "                data = self.mixed_data[index, :]\n",
        "                labels = self.sample_labels[index]\n",
        "                \n",
        "                return data, labels\n",
        "\n",
        "            else:\n",
        "                self.iter_cnt= 0\n",
        "                raise StopIteration\n",
        "\n",
        "        else:\n",
        "            print(\"Random sampler is not implemented.\")\n",
        "            raise SystemExit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgXKzr5OWMi"
      },
      "source": [
        "# Objective functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "UPuk89DsOVsa",
        "outputId": "68dcb377-a53c-4349-d035-a95f266d98ba"
      },
      "source": [
        "class GaussianLoss(nn.Module):\n",
        "    def __init__(self, reduction = \"sum\"):\n",
        "        super(GaussianLoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, x_recon, x):\n",
        "\n",
        "        if isinstance(x_recon, tuple):\n",
        "            #Learnt a variance on the output\n",
        "            mu_recon, var_recon = x_recon\n",
        "\n",
        "        else:\n",
        "            #No learnt variance on the output\n",
        "            mu_recon = x_recon\n",
        "            var_recon = torch.ones_like(x_recon).requires_grad_(False)\n",
        "        \n",
        "        error = x - mu_recon\n",
        "\n",
        "        B, N = x.size()\n",
        "        #Assuming diagonalised covariance:\n",
        "        gauss_log_loss = torch.mul(error.pow(2), 1/(2 * var_recon + 1e-12)) #2x100 error vector is needed to do normal multiplication\n",
        "        gauss_log_loss += 1/2 * torch.log(var_recon + 1e-12)\n",
        "\n",
        "        #Sum over dimensionality\n",
        "        gauss_log_loss = torch.sum(gauss_log_loss, dim = 1, keepdim = True)\n",
        "        \n",
        "        if self.reduction.lower() == \"sum\":\n",
        "            gauss_log_loss +=  torch.sum(gauss_log_loss)\n",
        "\n",
        "        return gauss_log_loss #Unnormalised\n",
        "\n",
        "\n",
        "class KL_divergence(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Implement the KL divergence loss for Gaussian distributions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, std_normal = False):\n",
        "        super(KL_divergence, self).__init__()\n",
        "\n",
        "        self.std_normal = std_normal #A flag to check whether the loss\n",
        "\n",
        "    def forward(self, mu_0, var_0, mu_1 = None, var_1 = None):\n",
        "\n",
        "        if self.std_normal:\n",
        "            mu_1 = torch.zeros_like(mu_0).requires_grad_(False)\n",
        "            var_1 = torch.ones_like(var_0).requires_grad_(False)\n",
        "\n",
        "        #perform everything elementwise and then \n",
        "        Dkl = var_0 / var_1 + ((mu_1 - mu_0)**2) / var_1 - 1 + torch.log(var_1 / var_0  + 1e-12)\n",
        "\n",
        "        #Sum over dimensionality\n",
        "        Dkl = 0.5 * torch.sum(Dkl, dim = 1, keepdim = True)\n",
        "\n",
        "        return Dkl #Unnormalised\n",
        "\n",
        "class discrete_KL_divergence(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the KL divergence loss for sampled distributions with likelihoods\n",
        "    \"\"\"\n",
        "    def __init__(self, no_classes):\n",
        "        super(discrete_KL_divergence, self).__init__()\n",
        "\n",
        "        self.no_classes = no_classes\n",
        "\n",
        "    def forward(self, class_prob, prior_prob = None):\n",
        "\n",
        "        assert class_prob.size(1) == self.no_classes, \"There is a mis-match between the pre-defined number of classes and the number of classes given to the discrete KL divergence.\"\n",
        "\n",
        "        if prior_prob is None:\n",
        "              prior_prob = torch.ones(self.no_classes) / self.no_classes\n",
        "\n",
        "        #perform everything elementwise and then you can reduce if required\n",
        "        entropy = -1 * torch.sum(class_prob * torch.log(class_prob + 1e-12), dim = 1, keepdim = True) #Entropy term\n",
        "        cross_entropy = -1 * torch.sum(class_prob * torch.log(prior_prob + 1e-12), dim = 1, keepdim = True)  #Cross-entropy term\n",
        "\n",
        "        Dkl = entropy - cross_entropy\n",
        "\n",
        "        return Dkl, torch.mean(entropy), torch.mean(cross_entropy) #Unnormalised and I sign-corrected the entropy term.\n",
        "\n",
        "class MoG_VAE_loss(nn.Module):\n",
        "    #No ability to learn a variance, variance is controlled by the noise distribution for iVAE\n",
        "    def __init__(self, no_classes, loss_name = \"L2\", gamma = 1, beta = 1, alpha = 1):\n",
        "        super(MoG_VAE_loss, self).__init__()\n",
        "\n",
        "        self.no_classes = no_classes\n",
        "\n",
        "        self.gamma = gamma #Reconstruction loss KL parameter\n",
        "        self.beta = beta #Continuous KL parameter\n",
        "        self.alpha = alpha #Categorial KL parameter\n",
        "\n",
        "        self.loss_name = loss_name\n",
        "\n",
        "        if self.loss_name.lower() == \"l2\":\n",
        "            self.recon_loss = GaussianLoss(reduction = 'none')\n",
        "        \n",
        "        elif self.loss_name.lower() == \"l1\":\n",
        "            self.recon_loss = nn.L1Loss(reduction = 'none')\n",
        "        \n",
        "        elif self.loss_name.lower() == \"bce\":\n",
        "              self.recon_loss = nn.BCELoss(reduction = 'none')\n",
        "        \n",
        "        else:\n",
        "            print(\"Unknown loss entered.\")\n",
        "            raise SystemExit\n",
        "        \n",
        "        self.kl_loss = KL_divergence(False) #Never use a standard VAE case\n",
        "        self.discrete_kl_loss = discrete_KL_divergence(self.no_classes)\n",
        "    \n",
        "    def forward(self, x, recon_x, mu_0, var_0, mu_1, var_1, q_y_G_x, prior_prob = None, CURL = False):\n",
        "        \n",
        "        #You need to expand the input data by no_classes and then reshape it!\n",
        "        #x = torch.repeat_interleave(x, self.no_classes, dim = 0)\n",
        "\n",
        "        B, N = x.size()\n",
        "\n",
        "        if isinstance(recon_x, tuple) and self.loss_name.lower() != \"l2\": #Check if it is a tuple, will be this by default when it is fed in.\n",
        "            recon_x = recon_x[0]\n",
        "\n",
        "        #Reconstruction loss\n",
        "        if CURL:\n",
        "            x = torch.repeat_interleave(x, self.no_classes, dim = 0)\n",
        "\n",
        "            Lrecon = torch.sum(self.recon_loss(recon_x, x), dim = 1, keepdim = True)\n",
        "            Lrecon = Lrecon.reshape(B, self.no_classes)\n",
        "            Lrecon *= q_y_G_x #weight by categorical likelihood\n",
        "            Lrecon = torch.sum(Lrecon) / self.no_classes  #Sum all values and normalise by no. of classes\n",
        "\n",
        "        else:\n",
        "            Lrecon = torch.sum(self.recon_loss(recon_x, x), dim = 1, keepdim = True)\n",
        "            Lrecon = torch.sum(Lrecon)  #Sum all values\n",
        "\n",
        "        if mu_0.size(0) * self.no_classes == mu_1.size(0): #A check to see if you are using single samples for many classes (VaDE only)\n",
        "            mu_0 = torch.repeat_interleave(mu_0, self.no_classes, dim = 0) #Need to expand data for all the classes\n",
        "            var_0 = torch.repeat_interleave(var_0, self.no_classes, dim = 0) #Need to expand data for all the classes\n",
        "\n",
        "        #continuous KL divergence loss\n",
        "        Lkl_continuous = self.kl_loss(mu_0, var_0, mu_1, var_1) #Need to normalise with same values reconstruction loss (Pytorch does this automatically unless you specify)\n",
        "        Lkl_continuous = Lkl_continuous.reshape(B, self.no_classes)\n",
        "\n",
        "        Lkl_continuous *= q_y_G_x #weight by categorical likelihood\n",
        "        Lkl_continuous = torch.sum(Lkl_continuous) / self.no_classes #Sum all values and normalise by class size\n",
        "\n",
        "        #discrete KL divergence loss\n",
        "        Lkl_discrete, entropy, cross_entropy = self.discrete_kl_loss(q_y_G_x, prior_prob)\n",
        "        Lkl_discrete = torch.sum(Lkl_discrete)  #Sum all values\n",
        "\n",
        "        Ltotal = self.gamma * Lrecon + self.beta * Lkl_continuous + self.alpha * Lkl_discrete\n",
        "\n",
        "        #Normalise value\n",
        "        Lrecon /= (B * N)\n",
        "        Lkl_continuous /= (B * N)\n",
        "        Lkl_discrete /= (B * N)\n",
        "        Ltotal /= (B * N)\n",
        "\n",
        "        return Ltotal, Lrecon, Lkl_continuous, Lkl_discrete, entropy, cross_entropy\n",
        "\n",
        "\"\"\"\n",
        "#TESTING THE FUNCTIONS\n",
        "no_samples = 512\n",
        "no_classes = 3\n",
        "a = torch.randn(no_samples, 5)\n",
        "b = a + torch.randn_like(a) * 0.1\n",
        "mu_0 = torch.ones_like(a)\n",
        "mu_1 = torch.zeros_like(a)\n",
        "var_0 = torch.ones_like(a)\n",
        "var_1 = torch.ones_like(a)\n",
        "\n",
        "a = torch.repeat_interleave(a, no_classes, dim = 0)\n",
        "b = torch.repeat_interleave(b, no_classes, dim = 0)\n",
        "mu_0 = torch.repeat_interleave(mu_0, no_classes, dim = 0)\n",
        "mu_1 = torch.repeat_interleave(mu_1, no_classes, dim = 0)\n",
        "var_0 = torch.repeat_interleave(var_0, no_classes, dim = 0)\n",
        "var_1 = torch.repeat_interleave(var_1, no_classes, dim = 0)\n",
        "\n",
        "loss = MoG_VAE_loss(no_classes)\n",
        "q_y_G_x = torch.ones(no_samples, no_classes) / no_classes\n",
        "\n",
        "print(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, False))\n",
        "print(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, True))\n",
        "print(torch.mean((b - a)**2)/2, torch.mean((b - a)**2)/(2 * no_classes))\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#TESTING THE FUNCTIONS\\nno_samples = 512\\nno_classes = 3\\na = torch.randn(no_samples, 5)\\nb = a + torch.randn_like(a) * 0.1\\nmu_0 = torch.ones_like(a)\\nmu_1 = torch.zeros_like(a)\\nvar_0 = torch.ones_like(a)\\nvar_1 = torch.ones_like(a)\\n\\na = torch.repeat_interleave(a, no_classes, dim = 0)\\nb = torch.repeat_interleave(b, no_classes, dim = 0)\\nmu_0 = torch.repeat_interleave(mu_0, no_classes, dim = 0)\\nmu_1 = torch.repeat_interleave(mu_1, no_classes, dim = 0)\\nvar_0 = torch.repeat_interleave(var_0, no_classes, dim = 0)\\nvar_1 = torch.repeat_interleave(var_1, no_classes, dim = 0)\\n\\nloss = MoG_VAE_loss(no_classes)\\nq_y_G_x = torch.ones(no_samples, no_classes) / no_classes\\n\\nprint(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, False))\\nprint(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, True))\\nprint(torch.mean((b - a)**2)/2, torch.mean((b - a)**2)/(2 * no_classes))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQnjV1THp_iK"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQtrkYUZeJS"
      },
      "source": [
        "#Implement similarly to the manner I had previously\n",
        "#Dict to define layers\n",
        "#Checks for FF and Convolution\n",
        "#Add in ability to have variance generating component in decoder (unused at this point)\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, ModelDict):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.ModelDict = ModelDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "        \n",
        "        First_no_channels = self.ModelDict[\"channels\"][0]\n",
        "\n",
        "        input_tensor = input_tensor.view(-1, First_no_channels, int(input_tensor.size(1) / First_no_channels))\n",
        "        \n",
        "        return input_tensor\n",
        "\n",
        "class Flatten(nn.Module): #Same name as tensorflow tf.keras.Flatten()just because it makes sense\n",
        "    def __init__(self, DisDict):\n",
        "        super(Flatten, self).__init__()\n",
        "        self.DisDict = DisDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "        input_tensor = input_tensor.view(input_tensor.size(0), -1)\n",
        "        \n",
        "        return input_tensor\n",
        "#########################################################################  \n",
        "class MoG_Encoder(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size, encode_dict, CURL_flag = False):\n",
        "\n",
        "        #The purpose of the CURL flag is to specify whether we learn a classification layer\n",
        "        #or if we estimate the class from the data. \n",
        "\n",
        "        super(MoG_Encoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes #Controls the size of the class space\n",
        "        self.data_size = data_size\n",
        "        self.encode_dict = encode_dict\n",
        "        self.CURL_flag = CURL_flag\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        #Check if it is a standard VAE through no_classes\n",
        "        if self.no_classes == 0:\n",
        "            print(\"You are using a MoG VAE but have set the class size to zero... why?\")\n",
        "            raise SystemExit\n",
        "        \n",
        "        if self.CURL_flag:\n",
        "            print(\"\\nUsing CURL formulation, so the model has a class label head.\")\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "\n",
        "        if self.encode_dict[\"conv_flag\"]:\n",
        "            \n",
        "            for i in range(len(self.encode_dict[\"channels\"]) - 1):\n",
        "\n",
        "                #append the layer\n",
        "                self.layers.append( nn.Conv1d(in_channels = self.encode_dict[\"channels\"][i], out_channels = self.encode_dict[\"channels\"][i + 1], kernel_size = self.encode_dict[\"kernel_size\"][i], stride = self.encode_dict[\"stride\"][i], padding = self.encode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.layers.append(Flatten(self.encode_dict))\n",
        "      \n",
        "        for i in range(len(self.encode_dict[\"ff_layers\"]) - 2):\n",
        "            #append the layer\n",
        "            self.layers.append(nn.Linear(in_features = self.encode_dict[\"ff_layers\"][i], out_features = self.encode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "            #append the activation function\n",
        "            self.layers.append(self.activation)\n",
        "\n",
        "        self.layers.pop(-1)\n",
        "        self.encode_net = nn.Sequential(*self.layers) #hidden representation that gets fed into predicting the label and latent \n",
        "\n",
        "        if self.CURL_flag:\n",
        "            self.y_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.no_classes), nn.Softmax(dim = 1))\n",
        "\n",
        "            #If it is CURL, you need to feed x and y to get z ~ q(z|x, y)\n",
        "            self.mu_layer = nn.Linear(self.encode_dict[\"ff_layers\"][-2] + self.no_classes, self.encode_dict[\"ff_layers\"][-1])\n",
        "            self.var_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2] + self.no_classes, self.encode_dict[\"ff_layers\"][-1]), self.var_activation)\n",
        "        \n",
        "        else:\n",
        "            self.mu_layer = nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1])\n",
        "            self.var_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1]), self.var_activation)\n",
        "        \n",
        "        #Initialise weights if you want to\n",
        "        self.encode_net.apply(self.init_weights)\n",
        "        self.mu_layer.apply(self.init_weights)\n",
        "        self.var_layer.apply(self.init_weights)\n",
        "\n",
        "        if self.CURL_flag:\n",
        "            self.y_layer.apply(self.init_weights)\n",
        "    \n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "  \n",
        "    def forward(self, x, cont_input = None, expand_flag = True):\n",
        "        \n",
        "        #Always stack as [x, conditional labels]\n",
        "        #expand_flag controls whether we expand x_input to account for K classes or if we just wish to feed the samples through the model.\n",
        "        #If you don't use the expand flag and you use CURL, then feed y_x from classification head layer in.\n",
        "        #We need to specify the class labels, however for VaDE these are estimated from p(y|x) not q(y|x)\n",
        "            \n",
        "        #print(\"stage 1\")\n",
        "        #Account for any conditioning variables\n",
        "        if cont_input is not None:\n",
        "            x_input = torch.hstack((x, cont_input))\n",
        "\n",
        "        else:\n",
        "            x_input = x\n",
        "        \n",
        "        encode = self.encode_net(x_input)\n",
        "        \n",
        "        #print(\"stage 2\")\n",
        "        if self.CURL_flag:\n",
        "            y_x = self.y_layer(encode) #Model predicted class labels, done on non-expanded data as these are essentially weights for likelihood or KL terms\n",
        "        \n",
        "        else:#VaDE\n",
        "            y_x = None #Do nothing\n",
        "        #print(\"stage 3\")\n",
        "        with torch.no_grad(): #We still want the expanded class labels so still make them!\n",
        "            labels = torch.arange(self.no_classes).repeat(x.size(0)).type(torch.long)# #Repeat labels for each sample, required when we use CURL to control the y's. \n",
        "            \n",
        "            #print(labels, labels.dtype)\n",
        "            labels = labels.to(self.device)\n",
        "            \n",
        "            class_input = F.one_hot(labels, num_classes = self.no_classes).type(torch.float32)\n",
        "            class_input = class_input.to(self.device)\n",
        "        #print(\"stage 4\")\n",
        "        if expand_flag and self.CURL_flag: \n",
        "            #The expansion is only necessary for CURL\n",
        "            #For VaDE, you do not need to expand the samples!Only the KL divergence needs to be expanded\n",
        "            #Expand the data\n",
        "            x_input = torch.repeat_interleave(x_input, self.no_classes, dim = 0)\n",
        "            encode = self.encode_net(x_input)\n",
        "            #predict label\n",
        "            y_pred = self.y_layer(encode)\n",
        "            #encode data\n",
        "            encode = torch.hstack((encode, y_pred))\n",
        "\n",
        "        elif not expand_flag and self.CURL_flag: #If you don't perform training and you use CURL, feed q(y|x) head into encoder\n",
        "            encode = torch.hstack((encode, y_x))\n",
        "        \n",
        "        mu_z = self.mu_layer(encode)\n",
        "        var_z = self.var_layer(encode)\n",
        "            \n",
        "        return mu_z, var_z, y_x, class_input\n",
        "#########################################################################    \n",
        "\n",
        "class MoG_Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size, decode_dict, var_flag = False, binary_flag = False):\n",
        "        super(MoG_Decoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size = data_size\n",
        "        self.decode_dict = decode_dict\n",
        "        self.var_flag = var_flag\n",
        "        self.binary_flag = binary_flag\n",
        "        self.activation = nn.LeakyReLU(0.1)    \n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "\n",
        "        print(\"\\nTake note, this decoder also returns the latent sample, as you need it for the VaDE estimation step (and if you want to do it analytically)\")\n",
        "        \n",
        "        if not self.decode_dict[\"conv_flag\"]:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1])\n",
        "            \n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "\n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1]), nn.Softplus())\n",
        "                #self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "         \n",
        "        else:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 1):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.layers.append(Unflatten(self.decode_dict))\n",
        "            \n",
        "            for i in range(len(self.decode_dict[\"channels\"]) - 2):\n",
        "\n",
        "                #append the layer\n",
        "                self.layers.append( nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][i], out_channels = self.decode_dict[\"channels\"][i + 1], kernel_size = self.decode_dict[\"kernel_size\"][i], stride = self.decode_dict[\"stride\"][i], padding = self.decode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "            \n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "\n",
        "            self.decode_net.apply(self.init_weights)\n",
        "            self.gen_layer.apply(self.init_weights)\n",
        "\n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "                                               , nn.Softplus())\n",
        "                self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparametrisation_trick(mu_data, var_data):\n",
        "        with torch.no_grad():\n",
        "            eta = torch.randn_like(mu_data)\n",
        "\n",
        "        return mu_data + eta * torch.sqrt(var_data)\n",
        "\n",
        "    def forward(self, mu_latent, var_latent):\n",
        "\n",
        "        z_latent = self.reparametrisation_trick(mu_latent, var_latent)\n",
        "\n",
        "        decode_out = self.decode_net(z_latent)\n",
        "\n",
        "        x_out = self.gen_layer(decode_out)\n",
        "\n",
        "        if self.var_flag:\n",
        "            var_out = self.var_layer(decode_out)\n",
        "            \n",
        "        else:\n",
        "            var_out = torch.ones_like(x_out).requires_grad_(False)\n",
        "        \n",
        "        if self.decode_dict[\"conv_flag\"]:\n",
        "            x_out = x_out.squeeze(1)\n",
        "            var_out = var_out.squeeze(1)\n",
        "            \n",
        "        return x_out, var_out, z_latent\n",
        "\n",
        "class MoG_ConditionalPrior(nn.Module):\n",
        "    #Can adapt to have parametric densities... (only a mean and variance parameter depending on the class)\n",
        "    #I think for the MoG case, you can use continuous_prior = False\n",
        "    #Assumption for labels fed in: They are one-hot encoded! (Remember this)\n",
        "\n",
        "    def __init__(self, latent_size, no_classes, data_size, prior_dict, continuous_prior = False):\n",
        "        super(MoG_ConditionalPrior, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size = data_size\n",
        "        self.prior_dict = prior_dict\n",
        "        self.continuous_prior = continuous_prior\n",
        "\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        #Check if it is a standard VAE, if so, set continuous_prior to False and then set distribution to N(0, I)\n",
        "        if self.no_classes == 0:\n",
        "            print(\"You are using a MoG VAE but have set the class size to zero... why?\")\n",
        "            raise SystemExit\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "        \n",
        "        if self.continuous_prior:\n",
        "            #Define model - essentially another generator but with only FF layers, by design\n",
        "\n",
        "            for i in range(len(self.prior_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.prior_dict[\"ff_layers\"][i], out_features = self.prior_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "          \n",
        "            self.layers.pop(-1)\n",
        "            self.prior_net = nn.Sequential(*self.layers)\n",
        "            self.prior_mu = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "            self.prior_var = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "\n",
        "            #self.prior_net.apply(self.init_weights)\n",
        "            #self.prior_mu.apply(self.init_weights)\n",
        "            #self.prior_var.apply(self.init_weights)\n",
        "      \n",
        "        else: #Label gives a mean and variance.\n",
        "            #Lambda functions that just return the mean and variance parameters at all the class locations of interest!\n",
        "            self.prior_net = lambda U: U #Just a way to bypass the prior_net step in the forward method()\n",
        "\n",
        "            if self.no_classes == 0: #Standard VAE implementation, not useful here\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size), requires_grad = True))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size), requires_grad = True))\n",
        "\n",
        "            else:\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(self.no_classes, self.latent_size), requires_grad = True))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(self.no_classes, self.latent_size), requires_grad = True))\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(self.no_classes, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(self.no_classes, self.latent_size))#torch.ones(self.no_classes, self.latent_size).to(self.device)#\n",
        "\n",
        "                self.prior_mu = lambda U: self._prior_mu_[torch.argmax(U, dim = 1), :]\n",
        "                self.prior_var = lambda U: self._prior_var_[torch.argmax(U, dim = 1), :]\n",
        "\n",
        "            with torch.no_grad(): #initialise parameters\n",
        "                if self.no_classes == 0:\n",
        "                    #Set to N(0, I)\n",
        "                    self._prior_mu_.fill_(0)\n",
        "                    self._prior_var_.fill_(1)\n",
        "                    #Turn off gradient flag\n",
        "                    self._prior_mu_.requires_grad_(False)\n",
        "                    self._prior_var_.requires_grad_(False)\n",
        "                    \n",
        "                else:\n",
        "                    self._prior_mu_.normal_(0, 1)\n",
        "                    self._prior_var_.normal_(0, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "    \n",
        "    def forward(self, labels = None, cont_input = None): #labels = None for the standard VAE case.\n",
        "        #Always stack as [continuous, discrete]\n",
        "        if self.no_classes == 0: #For a standard VAE, not useful here.\n",
        "            return self._prior_mu_, self._prior_var_\n",
        "\n",
        "        else:\n",
        "            u_input = labels\n",
        "            \n",
        "            if cont_input is not None:\n",
        "                u_input = torch.hstack((cont_input, u_input))\n",
        "\n",
        "            prior_net = self.prior_net(u_input)\n",
        "            mu = self.prior_mu(prior_net)\n",
        "            var = self.var_activation(self.prior_var(prior_net)) \n",
        "            \n",
        "            return mu, var\n",
        "\n",
        "class MoG_ClassPrior(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size):\n",
        "        super(MoG_ClassPrior, self).__init__()\n",
        "        \n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size =data_size\n",
        "\n",
        "        self.register_parameter(name='prior_prob', param=torch.nn.Parameter(torch.Tensor(1, self.no_classes), requires_grad = False))\n",
        "        self.prior_prob.fill_(1/self.no_classes)\n",
        "\n",
        "        self.gauss_loss = GaussianLoss(reduction = 'none') #This already calculates the NLL, so you just need to add (D/2d*log(2pi)) and multiply the sum by -1\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    def posterior_likelihood(self, latent_samples, mu_class, var_class):\n",
        "        #Method:\n",
        "        #-------\n",
        "        # Calculates p(y|x) for the user. p(y|x) = p(y)p(z|y) / SUM(p(y)p(z|y)) - specifically for VaDE\n",
        "        # Need to calculate log p(z|y) (prior likelihood)\n",
        "        # p(y) is defined in this class through self.prior_prob\n",
        "        # Need to perform log-sum-exp trick to calculate denominator without overflow\n",
        "        #-------\n",
        "\n",
        "        #For each x, push to latent space and resample using reparametrisation trick and calculate log-likelihood of z under p(z|y=k) (thus, you need no_class likelihood for 1 z sample)\n",
        "        #Then calculate p(y=k|x) using \n",
        "\n",
        "        if latent_samples.size(0) * self.no_classes == mu_class.size(0): #A check to see if you are using single samples for many classes (VaDE only)\n",
        "            latent_samples = torch.repeat_interleave(latent_samples, self.no_classes, dim = 0)\n",
        "\n",
        "        kB, z_size = latent_samples.size()\n",
        "        B = kB // self.no_classes\n",
        "\n",
        "        log_samples = -1 * ( self.gauss_loss((mu_class, var_class), latent_samples) + self.latent_size/2 * (np.log(2 * np.pi)) )\n",
        "\n",
        "        log_samples = log_samples.reshape(B, self.no_classes) + torch.log(self.prior_prob)\n",
        "\n",
        "        logsumexp_denominator = torch.logsumexp(log_samples, dim = 1, keepdim = True)\n",
        "        \n",
        "        q_y_G_x = torch.exp(log_samples - logsumexp_denominator)\n",
        "\n",
        "        return q_y_G_x\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqgyVKQNv9Nc"
      },
      "source": [
        "class MoG_VAE_model(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, no_classes = None, EncodeDict = None, DecodeDict = None, PriorDict = None, binary_decode = False, var_decode = False, continuous_prior = False, CURL_flag = True):\n",
        "        super(MoG_VAE_model, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.encode_dict = EncodeDict\n",
        "        self.decode_dict = DecodeDict\n",
        "        self.prior_dict = PriorDict\n",
        "        self.binary_decode = binary_decode\n",
        "        self.var_decode = var_decode\n",
        "        self.continuous_prior = continuous_prior\n",
        "        self.CURL_flag = CURL_flag\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.model_HI_names = [\"HI_1\"]\n",
        "        self.model_HI_names_pretty = [r\"$NLL_{recon}$\"]\n",
        "\n",
        "        self.encoder = MoG_Encoder(self.latent_size, self.no_classes, self.input_size, self.encode_dict, CURL_flag = self.CURL_flag)\n",
        "        self.decoder = MoG_Decoder(self.latent_size, self.no_classes, self.input_size, self.decode_dict, var_flag = var_decode, binary_flag = self.binary_decode)\n",
        "        self.prior = MoG_ConditionalPrior(self.latent_size, self.no_classes, self.input_size, self.prior_dict, continuous_prior = self.continuous_prior)\n",
        "        self.class_prior = MoG_ClassPrior(self.latent_size, self.no_classes, self.input_size)\n",
        "\n",
        "        if self.no_classes == 0:\n",
        "            print(\"Why are you using a MoG VAE with no classes?\")\n",
        "            raise SystemExit\n",
        "\n",
        "    def train(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        self.prior.train()\n",
        "        self.class_prior.train()\n",
        "    \n",
        "    def eval(self):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "        self.prior.eval()\n",
        "        self.class_prior.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.encoder.to(device)\n",
        "        self.decoder.to(device)\n",
        "        self.prior.to(device)\n",
        "        self.class_prior.to(device)\n",
        "    \n",
        "    def one_hot_encode(self, labels):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label_mat = torch.zeros(labels.size(0), self.no_classes)\n",
        "            label_mat[range(labels.size(0)), labels] = 1\n",
        "\n",
        "            return label_mat\n",
        "\n",
        "    def compute_HIs(self, x, labels = None, cont_input = None): #Only useful if you are performing anomaly detection (specific to another project)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            mu_latent, var_latent, _, _ = self.encoder(x, expand_flag = False)\n",
        "\n",
        "            x_recon1, var_decoder, _ =  self.decoder(mu_latent, var_latent) \n",
        "            HI_1 = (1 / x.shape[1]) * torch.sum((x - x_recon1)**2 / (var_decoder), dim = 1) \n",
        "\n",
        "            return HI_1, mu_latent\n",
        "    \n",
        "    def infer_label(self, x):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #Posterior labels\n",
        "            mu_latent, var_latent, y_pred, class_labels = self.encoder(x, expand_flag = False) \n",
        "\n",
        "            z_latent = self.decoder.reparametrisation_trick(mu_latent, var_latent)\n",
        "\n",
        "            mu_prior, var_prior = self.prior(class_labels)\n",
        "\n",
        "            q_y_G_x = self.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\n",
        "\n",
        "            posterior_labels = torch.argmax(q_y_G_x, dim = 1)\n",
        "\n",
        "            #CURL evaluation\n",
        "            if self.encoder.CURL_flag:\n",
        "                curl_labels = torch.argmax(y_pred, dim = 1)\n",
        "\n",
        "            else:\n",
        "                curl_labels = None\n",
        "\n",
        "            return posterior_labels, curl_labels\n",
        "\n",
        "class MoG_VAE_optimiser(object):\n",
        "    def __init__(self, model, Params):\n",
        "        ls = list(model.encoder.parameters()) + list(model.decoder.parameters()) + list(model.prior.parameters()) + list(model.class_prior.parameters())\n",
        "        self.VAE_opt = torch.optim.Adam(ls, lr = 5e-4)\n",
        "        print(\"\\n\\ndefault LR is 1e-3.\\n\\n\")\n",
        "    \n",
        "    def step(self):\n",
        "        self.VAE_opt.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.VAE_opt.zero_grad()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "fMIwGk5-s5Gl",
        "outputId": "b115b6b7-dd7b-48bd-e091-f619390f610d"
      },
      "source": [
        "\"\"\"  \n",
        "data_size = 784\n",
        "no_classes = 3\n",
        "latent_size = 2\n",
        "CURL_flag = False\n",
        "\n",
        "encode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = None\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, binary_decode =False, var_decode = False, CURL_flag = CURL_flag)\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\n",
        "#my_trainer = MoG_VAE_trainer()\n",
        "\n",
        "B = 10\n",
        "with torch.no_grad():\n",
        "    x = torch.randn(B, data_size)\n",
        "    mu_z, var_z, y_pred, class_labels = model.encoder(x, expand_flag = True)\n",
        "\n",
        "    mu_prior, var_prior = model.prior(class_labels)\n",
        "\n",
        "    recon_x, var_x, z_latent = model.decoder(mu_z, var_z)\n",
        "\n",
        "    print(\"x\", x.size())\n",
        "    print(\"mu_z\", mu_z.size())\n",
        "    print(\"var_z\", var_z.size(), \"\\n\\n\")\n",
        "    #print(y_pred, \"\\n\\n\")\n",
        "    print(\"class labels\", class_labels.size(), \"\\n\\n\")\n",
        "    print(\"z_latent\", z_latent.size())\n",
        "    print(\"mu_prior\", mu_prior.size())\n",
        "    print(\"var_prior\", var_prior.size(), \"\\n\\n\")\n",
        "    print(\"recon_x\", recon_x.size())\n",
        "    print(\"var_x\", var_x.size(), \"\\n\\n\")\n",
        "\n",
        "    q_y_G_x = model.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\n",
        "    q_y_G_x1, q_y_G_x2 = model.infer_label(x)\n",
        "\n",
        "    print(q_y_G_x)\n",
        "    print(q_y_G_x1, q_y_G_x2)\n",
        "\n",
        "    loss_tup = MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, q_y_G_x, model.class_prior.prior_prob, CURL_flag)\n",
        "    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(q_y_G_x), dim = 1)))\n",
        "    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(model.class_prior.prior_prob), dim = 1)))\n",
        "    print(loss_tup)\n",
        "\n",
        "    if CURL_flag:\n",
        "        loss_tup =MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, y_pred, model.class_prior.prior_prob, CURL_flag)\n",
        "        print(torch.mean(-1 * torch.sum(y_pred * torch.log(y_pred), dim = 1)))\n",
        "        print(torch.mean(-1 * torch.sum(y_pred * torch.log(model.class_prior.prior_prob), dim = 1)))\n",
        "        print(loss_tup)\n",
        "    #print(q_y_G_x, torch.sum(q_y_G_x, dim = 1))\n",
        "    #print(q_y_G_x[0, :], torch.sum(q_y_G_x[0, :]))\n",
        "    #\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  \\ndata_size = 784\\nno_classes = 3\\nlatent_size = 2\\nCURL_flag = False\\n\\nencode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\\n                \"conv_flag\":False }\\n\\ndecode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\\n                \"conv_flag\":False }\\n\\nprior_dict = None\\n\\nmodel = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, binary_decode =False, var_decode = False, CURL_flag = CURL_flag)\\nMoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\\nMoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\\n#my_trainer = MoG_VAE_trainer()\\n\\nB = 10\\nwith torch.no_grad():\\n    x = torch.randn(B, data_size)\\n    mu_z, var_z, y_pred, class_labels = model.encoder(x, expand_flag = True)\\n\\n    mu_prior, var_prior = model.prior(class_labels)\\n\\n    recon_x, var_x, z_latent = model.decoder(mu_z, var_z)\\n\\n    print(\"x\", x.size())\\n    print(\"mu_z\", mu_z.size())\\n    print(\"var_z\", var_z.size(), \"\\n\\n\")\\n    #print(y_pred, \"\\n\\n\")\\n    print(\"class labels\", class_labels.size(), \"\\n\\n\")\\n    print(\"z_latent\", z_latent.size())\\n    print(\"mu_prior\", mu_prior.size())\\n    print(\"var_prior\", var_prior.size(), \"\\n\\n\")\\n    print(\"recon_x\", recon_x.size())\\n    print(\"var_x\", var_x.size(), \"\\n\\n\")\\n\\n    q_y_G_x = model.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\\n    q_y_G_x1, q_y_G_x2 = model.infer_label(x)\\n\\n    print(q_y_G_x)\\n    print(q_y_G_x1, q_y_G_x2)\\n\\n    loss_tup = MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, q_y_G_x, model.class_prior.prior_prob, CURL_flag)\\n    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(q_y_G_x), dim = 1)))\\n    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(model.class_prior.prior_prob), dim = 1)))\\n    print(loss_tup)\\n\\n    if CURL_flag:\\n        loss_tup =MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, y_pred, model.class_prior.prior_prob, CURL_flag)\\n        print(torch.mean(-1 * torch.sum(y_pred * torch.log(y_pred), dim = 1)))\\n        print(torch.mean(-1 * torch.sum(y_pred * torch.log(model.class_prior.prior_prob), dim = 1)))\\n        print(loss_tup)\\n    #print(q_y_G_x, torch.sum(q_y_G_x, dim = 1))\\n    #print(q_y_G_x[0, :], torch.sum(q_y_G_x[0, :]))\\n    #\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvetzYcyrnkm"
      },
      "source": [
        "class MoG_VAE_trainer(object):\n",
        "    def __init__(self, MoG_VAE_model, MoG_VAE_optimiser, MoG_VAE_cost, training_iterator, validation_iterator, epochs):\n",
        "        self.model = MoG_VAE_model\n",
        "        self.optimiser = MoG_VAE_optimiser\n",
        "        self.cost = MoG_VAE_cost\n",
        "        self.train_iterator = training_iterator\n",
        "        self.valid_iterator = validation_iterator\n",
        "        self.epochs = epochs\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def optimise(self, real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = True): #compute and return loss\n",
        "\n",
        "        loss, recon, kl, discrete_kl, entropy, cross_entropy = self.cost(real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, self.model.class_prior.prior_prob, self.model.CURL_flag)\n",
        "      \n",
        "        if update:\n",
        "            loss.backward()\n",
        "            self.optimiser.step()\n",
        "            self.model.zero_grad()\n",
        "        \n",
        "        return loss, recon, kl, discrete_kl, entropy, cross_entropy\n",
        "        \n",
        "    def train_model(self): #train the models\n",
        "\n",
        "        pbar = tqdm(total = self.epochs, desc = \"cost at epoch {}: {}\".format(0, np.inf)) \n",
        "\n",
        "        cost_train_list = []\n",
        "        cost_valid_list = []\n",
        "        max_valid = np.inf\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            cost_train_total = 0\n",
        "            cost_train_other = np.zeros(5)\n",
        "            cnt_train = 0\n",
        "\n",
        "            cost_valid_total = 0\n",
        "            cost_valid_other = np.zeros(5)\n",
        "            cnt_valid = 0\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            #if self.train_iterator.random_seed: #Extracts random samples from the trainer\n",
        "            #    print(\"Random iterator is not implemented.\")\n",
        "            #    raise SystemExit\n",
        "\n",
        "            #elif not self.train_iterator.random_seed: #Sequentially loops through data\n",
        "                \n",
        "            for data in self.train_iterator:\n",
        "                if isinstance(data, tuple) or isinstance(data, list): #Check to see if the input is a tuple with labels\n",
        "\n",
        "                    #Separate data\n",
        "                    Xdata = data[0].to(self.device)\n",
        "                    labels = data[1].to(self.device)\n",
        "                  \n",
        "                else:\n",
        "                    #Push to GPU\n",
        "                    Xdata = data.to(self.device)\n",
        "                    labels = None\n",
        "\n",
        "                #Encoder\n",
        "                mu_z_encoder, var_z_encoder, q_y_G_x, class_labels = self.model.encoder(Xdata, expand_flag = True)\n",
        "\n",
        "                #Prior\n",
        "                mu_z_prior, var_z_prior = self.model.prior(class_labels)\n",
        "\n",
        "                #Decoder\n",
        "                mu_recon, var_recon, z_latent = self.model.decoder(mu_z_encoder, var_z_encoder)\n",
        "                Xrecon = (mu_recon, var_recon)\n",
        "                \n",
        "                #If not CURL, calculate posterior\n",
        "                if not self.model.CURL_flag:\n",
        "                    q_y_G_x = self.model.class_prior.posterior_likelihood(z_latent, mu_z_prior, var_z_prior)\n",
        "                \n",
        "                losses = self.optimise(Xdata, Xrecon, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = True)\n",
        "\n",
        "                cost_train_total += losses[0].item()\n",
        "\n",
        "                for cnt, i in enumerate(losses[1:]):\n",
        "                    cost_train_other[cnt] += i.item()\n",
        "\n",
        "                cnt_train += 1\n",
        "\n",
        "            #TODO - add in validation iterator component\n",
        "            with torch.no_grad():\n",
        "                #if self.valid_iterator.random_seed: #Extracts random samples from the trainer\n",
        "                #    print(\"Random iterator is not implemented.\")\n",
        "                #    raise SystemExit\n",
        "\n",
        "                #elif not self.valid_iterator.random_seed: #Sequentially loops through data\n",
        "                for data in self.valid_iterator:\n",
        "\n",
        "                    if isinstance(data, tuple) or isinstance(data, list):\n",
        "                        #Separate data\n",
        "                        Xdata = data[0].to(self.device)\n",
        "                        labels = data[1].to(self.device)\n",
        "                    \n",
        "                    else:\n",
        "                        Xdata = data.to(self.device)\n",
        "                        labels = None\n",
        "\n",
        "                    #Encoder\n",
        "                    mu_z_encoder, var_z_encoder, q_y_G_x, class_labels = self.model.encoder(Xdata, expand_flag = True)\n",
        "                    #Prior\n",
        "                    mu_z_prior, var_z_prior = self.model.prior(class_labels)\n",
        "                    #Decoder\n",
        "                    mu_recon, var_recon, z_latent = self.model.decoder(mu_z_encoder, var_z_encoder)\n",
        "                    Xrecon = (mu_recon, var_recon)\n",
        "                    \n",
        "                    #If not CURL, calculate posterior\n",
        "                    if not self.model.CURL_flag:\n",
        "                        q_y_G_x = self.model.class_prior.posterior_likelihood(z_latent, mu_z_prior, var_z_prior)\n",
        "                    \n",
        "                    losses = self.optimise(Xdata, Xrecon, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = False)\n",
        "\n",
        "                    cost_valid_total += losses[0].item()\n",
        "\n",
        "                    for cnt, i in enumerate(losses[1:]):\n",
        "                        cost_valid_other[cnt] += i.item()\n",
        "\n",
        "                    cnt_valid += 1\n",
        "\n",
        "            cost_train_array = np.round(np.hstack((np.array([cost_train_total]), cost_train_other)) / cnt_train, 4)       \n",
        "            cost_valid_array = np.round(np.hstack((np.array([cost_valid_total]), cost_valid_other)) / cnt_valid, 4) \n",
        "\n",
        "            cost_train_list.append(cost_train_array)\n",
        "            cost_valid_list.append(cost_valid_array)\n",
        "\n",
        "            if cost_valid_list[-1][0] < max_valid:\n",
        "                max_valid = cost_valid_list[-1][0] #Update to be the new minimum\n",
        "                self.optimal_state_dict = self.model.state_dict() #Save the optimal state dict\n",
        "                self.index_min_valid = i\n",
        "\n",
        "            pbar.set_description(desc = \"train cost: {}, valid cost: {}\".format(cost_train_list[-1], cost_valid_list[-1]))\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        self.train_cost = cost_train_list\n",
        "        self.valid_cost = cost_valid_list\n",
        "\n",
        "        self.model.eval()\n",
        "      \n",
        "    def plotter(self):\n",
        "        \n",
        "        v1 = np.array(self.train_cost)\n",
        "        v2 = np.array(self.valid_cost)\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2)\n",
        "        ax = ax.flatten()\n",
        "\n",
        "        for i in ax:\n",
        "            i.grid()\n",
        "            i.set_xlabel(\"Epochs\")\n",
        "            i.set_ylabel(\"Cost\")\n",
        "\n",
        "        ax[0].set_title(\"Training curves\")\n",
        "        ax[0].plot(v1[:, 0], label = \"Total loss\")\n",
        "        ax[0].plot(v1[:, 1], label = \"Gaussian loss\")\n",
        "        ax[0].plot(v1[:, 2], label = \"KL divergence loss\")\n",
        "        ax[0].plot(v1[:, 3], label = \"Discrete KL divergence loss\")\n",
        "        ax[0].plot(v1[:, 4], label = \"Entropy\")\n",
        "        ax[0].plot(v1[:, 5], label = \"Cross-entropy\")\n",
        "        #ax[0].scatter([self.index_min_valid] * v2.shape[1], v1[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "        ax[0].legend()\n",
        "\n",
        "        ax[1].set_title(\"Validation curves\")\n",
        "        ax[1].plot(v2[:, 0], label = \"Total loss\")\n",
        "        ax[1].plot(v2[:, 1], label = \"Gaussian loss\")\n",
        "        ax[1].plot(v2[:, 2], label = \"KL divergence loss\")\n",
        "        ax[1].plot(v2[:, 3], label = \"Discrete KL divergence loss\")\n",
        "        ax[1].plot(v2[:, 4], label = \"Entropy\")\n",
        "        ax[1].plot(v2[:, 5], label = \"Cross-entropy\")\n",
        "        #ax[1].scatter([self.index_min_valid] * v2.shape[1], v2[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "        ax[1].legend()\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Tv4CK5b1ww2n",
        "outputId": "19572bf8-3846-4040-f4df-25d136a44387"
      },
      "source": [
        "\"\"\"\n",
        "data_size = 2\n",
        "no_classes = 5\n",
        "latent_size = 2\n",
        "\n",
        "k = 2\n",
        "L = 1024\n",
        "mixL = 2\n",
        "batch_size = 128\n",
        "CURL_flag = False\n",
        "\n",
        "epochs = 10\n",
        "data_sampler = iVAE_datasets(data_size, no_classes, L, k, batch_size = batch_size, randomise = True, random_seed = False, mod_flag = False, mix_L = mixL, Gauss_source = False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = {  \"ff_layers\":[no_classes, 128, 128, 128, latent_size],\n",
        "                 \"conv_flag\":False }\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n",
        "\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\n",
        "my_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, data_sampler, data_sampler, epochs)\n",
        "\n",
        "my_trainer.train_model()\n",
        "my_trainer.plotter()\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata_size = 2\\nno_classes = 5\\nlatent_size = 2\\n\\nk = 2\\nL = 1024\\nmixL = 2\\nbatch_size = 128\\nCURL_flag = False\\n\\nepochs = 10\\ndata_sampler = iVAE_datasets(data_size, no_classes, L, k, batch_size = batch_size, randomise = True, random_seed = False, mod_flag = False, mix_L = mixL, Gauss_source = False)\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nencode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\\n                \"conv_flag\":False }\\n\\ndecode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\\n                \"conv_flag\":False }\\n\\nprior_dict = {  \"ff_layers\":[no_classes, 128, 128, 128, latent_size],\\n                 \"conv_flag\":False }\\n\\nmodel = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\\n\\nwith torch.no_grad():\\n  labels = torch.arange(0, no_classes)\\n  U = torch.eye(no_classes)\\n  mu_zp, var_zp = model.prior(U)#\\n\\n  mu_zp = mu_zp.cpu().numpy()\\n  var_zp = var_zp.cpu().numpy()\\n\\n  print(mu_zp, var_zp)\\n\\nMoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\\nMoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\\nmy_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, data_sampler, data_sampler, epochs)\\n\\nmy_trainer.train_model()\\nmy_trainer.plotter()\\n\\nwith torch.no_grad():\\n  labels = torch.arange(0, no_classes)\\n  U = torch.eye(no_classes)\\n  mu_zp, var_zp = model.prior(U)#\\n\\n  mu_zp = mu_zp.cpu().numpy()\\n  var_zp = var_zp.cpu().numpy()\\n\\n  print(mu_zp, var_zp)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "MlOW9hqI0eW-",
        "outputId": "971c4da0-51d7-4ac8-f85b-69d04c7cbfc9"
      },
      "source": [
        "\"\"\"\n",
        "save_fig_flag = False\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    labels = torch.arange(0, no_classes)\n",
        "    U = torch.eye(no_classes)\n",
        "    mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "    mu_zp = mu_zp.cpu().numpy()\n",
        "    var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "    mu_new = mu_zp[data_sampler.sample_labels.numpy(), :]\n",
        "    var_new = var_zp[data_sampler.sample_labels.numpy(), :]\n",
        "\n",
        "    Z_new = mu_new + np.random.randn(len(data_sampler.sample_labels), latent_size) * np.sqrt(var_new)\n",
        "\n",
        "    #Latent space and prior spaces\n",
        "    fig, ax = plt.subplots(1, 5 if CURL_flag else 4, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    #Original sources\n",
        "    ax[0].set_title(\"Original samples\")\n",
        "    ax[0].scatter(data_sampler.data.cpu().numpy()[:, 0], data_sampler.data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[0].set_xlabel(r\"$s_1$\")\n",
        "    ax[0].set_ylabel(r\"$s_2$\")\n",
        "\n",
        "    #Prior space p(z|u)\n",
        "    ax[1].set_title(\"Prior space\")\n",
        "    ax[1].scatter(Z_new[:, 0], Z_new[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[1].set_xlabel(r\"$z_1$\")\n",
        "    ax[1].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    mu_z, var_z, q_y_G_x, class_labels = model.encoder(data_sampler.mixed_data.to(device), expand_flag = False)\n",
        "    z_scatter = mu_z + torch.randn_like(mu_z) * torch.sqrt(var_z)\n",
        "    z_scatter = z_scatter.cpu().numpy()\n",
        "\n",
        "    q_y_G_x_post, q_y_G_x_curl = model.infer_label(data_sampler.mixed_data.to(device))\n",
        "    \n",
        "    recon, _, _ = model.decoder(mu_z, torch.zeros_like(var_z).to(device))\n",
        "\n",
        "    error = torch.sum((recon - data_sampler.mixed_data.to(device))**2, dim = 1).cpu().numpy() / data_size\n",
        "\n",
        "    recon = recon.cpu().numpy()\n",
        "    mu_z = mu_z.cpu().numpy()\n",
        "    var_z = var_z.cpu().numpy()\n",
        "\n",
        "    U1 = F.one_hot(q_y_G_x_post, no_classes)\n",
        "    U1 = U1.cpu().numpy()\n",
        "\n",
        "    q_y_G_x_post = q_y_G_x_post.cpu().numpy()\n",
        "    \n",
        "    if q_y_G_x_curl is not None:\n",
        "        q_y_G_x_curl = q_y_G_x_curl.cpu().numpy()\n",
        "\n",
        "    #Latent space p(z|x, u)\n",
        "    ax[2].set_title(\"Latent space\")\n",
        "    ax[2].scatter(z_scatter[:, 0], z_scatter[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[2].set_xlabel(r\"$z_1$\")\n",
        "    ax[2].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    #Latent space p(z|x, u)\n",
        "    ax[3].set_title(\"Latent space - posterior label head for colour\")\n",
        "    ax[3].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_post)\n",
        "    ax[3].set_xlabel(r\"$z_1$\")\n",
        "    ax[3].set_ylabel(r\"$z_2$\")\n",
        "    \n",
        "    if CURL_flag:\n",
        "      #Latent space p(z|x, u)\n",
        "      ax[4].set_title(\"Latent space - CURL label head for colour\")\n",
        "      ax[4].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_curl)\n",
        "      ax[4].set_xlabel(r\"$z_1$\")\n",
        "      ax[4].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/latent_space_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.imshow(U1[:100, :])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Reconstruction error\")\n",
        "    plt.scatter(np.arange(len(error)), error)\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/Error_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Reconstruction - scatterplot\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Mixed samples\")\n",
        "    ax[0].scatter(data_sampler.mixed_data.cpu().numpy()[:, 0], data_sampler.mixed_data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[0].set_xlabel(r\"$x_1$\")\n",
        "    ax[0].set_ylabel(r\"$x_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Reconstructed samples\")\n",
        "    ax[1].scatter(recon[:, 0], recon[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[1].set_xlabel(r\"$x_1$\")\n",
        "    ax[1].set_ylabel(r\"$x_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/reconstruction_scatter_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Reconstruction\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Mixed samples\")\n",
        "    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 0])\n",
        "    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 1])\n",
        "    ax[0].set_xlabel(r\"$x_1$\")\n",
        "    ax[0].set_ylabel(r\"$x_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Reconstructed samples\")\n",
        "    ax[1].plot(recon[:, 0])\n",
        "    ax[1].plot(recon[:, 1])\n",
        "    ax[1].set_xlabel(r\"$x_1$\")\n",
        "    ax[1].set_ylabel(r\"$x_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/reconstruction_signals_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Sources\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Original sources\")\n",
        "    ax[0].plot(data_sampler.data.cpu().numpy()[:, 0])\n",
        "    ax[0].plot(data_sampler.data.cpu().numpy()[:, 1])\n",
        "    ax[0].set_xlabel(r\"$z_1$\")\n",
        "    ax[0].set_ylabel(r\"$z_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Latent sources\")\n",
        "    ax[1].plot(mu_z[:, 0])\n",
        "    ax[1].plot(mu_z[:, 1])\n",
        "    ax[1].set_xlabel(r\"$z_1$\")\n",
        "    ax[1].set_ylabel(r\"$z_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/source_signals_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nsave_fig_flag = False\\n\\nwith torch.no_grad():\\n\\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n    model.to(device)\\n\\n    labels = torch.arange(0, no_classes)\\n    U = torch.eye(no_classes)\\n    mu_zp, var_zp = model.prior(U)#\\n\\n    mu_zp = mu_zp.cpu().numpy()\\n    var_zp = var_zp.cpu().numpy()\\n\\n    mu_new = mu_zp[data_sampler.sample_labels.numpy(), :]\\n    var_new = var_zp[data_sampler.sample_labels.numpy(), :]\\n\\n    Z_new = mu_new + np.random.randn(len(data_sampler.sample_labels), latent_size) * np.sqrt(var_new)\\n\\n    #Latent space and prior spaces\\n    fig, ax = plt.subplots(1, 5 if CURL_flag else 4, figsize = (12, 8))\\n    ax = ax.flatten()\\n\\n    #Original sources\\n    ax[0].set_title(\"Original samples\")\\n    ax[0].scatter(data_sampler.data.cpu().numpy()[:, 0], data_sampler.data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\\n    ax[0].set_xlabel(r\"$s_1$\")\\n    ax[0].set_ylabel(r\"$s_2$\")\\n\\n    #Prior space p(z|u)\\n    ax[1].set_title(\"Prior space\")\\n    ax[1].scatter(Z_new[:, 0], Z_new[:, 1], c = data_sampler.sample_labels)\\n    ax[1].set_xlabel(r\"$z_1$\")\\n    ax[1].set_ylabel(r\"$z_2$\")\\n\\n    mu_z, var_z, q_y_G_x, class_labels = model.encoder(data_sampler.mixed_data.to(device), expand_flag = False)\\n    z_scatter = mu_z + torch.randn_like(mu_z) * torch.sqrt(var_z)\\n    z_scatter = z_scatter.cpu().numpy()\\n\\n    q_y_G_x_post, q_y_G_x_curl = model.infer_label(data_sampler.mixed_data.to(device))\\n    \\n    recon, _, _ = model.decoder(mu_z, torch.zeros_like(var_z).to(device))\\n\\n    error = torch.sum((recon - data_sampler.mixed_data.to(device))**2, dim = 1).cpu().numpy() / data_size\\n\\n    recon = recon.cpu().numpy()\\n    mu_z = mu_z.cpu().numpy()\\n    var_z = var_z.cpu().numpy()\\n\\n    U1 = F.one_hot(q_y_G_x_post, no_classes)\\n    U1 = U1.cpu().numpy()\\n\\n    q_y_G_x_post = q_y_G_x_post.cpu().numpy()\\n    \\n    if q_y_G_x_curl is not None:\\n        q_y_G_x_curl = q_y_G_x_curl.cpu().numpy()\\n\\n    #Latent space p(z|x, u)\\n    ax[2].set_title(\"Latent space\")\\n    ax[2].scatter(z_scatter[:, 0], z_scatter[:, 1], c = data_sampler.sample_labels)\\n    ax[2].set_xlabel(r\"$z_1$\")\\n    ax[2].set_ylabel(r\"$z_2$\")\\n\\n    #Latent space p(z|x, u)\\n    ax[3].set_title(\"Latent space - posterior label head for colour\")\\n    ax[3].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_post)\\n    ax[3].set_xlabel(r\"$z_1$\")\\n    ax[3].set_ylabel(r\"$z_2$\")\\n    \\n    if CURL_flag:\\n      #Latent space p(z|x, u)\\n      ax[4].set_title(\"Latent space - CURL label head for colour\")\\n      ax[4].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_curl)\\n      ax[4].set_xlabel(r\"$z_1$\")\\n      ax[4].set_ylabel(r\"$z_2$\")\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/latent_space_\" + fig_label + \".png\")\\n    plt.show()\\n    \\n    plt.figure()\\n    plt.imshow(U1[:100, :])\\n    plt.show()\\n\\n    plt.figure()\\n    plt.title(\"Reconstruction error\")\\n    plt.scatter(np.arange(len(error)), error)\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/Error_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Reconstruction - scatterplot\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Mixed samples\")\\n    ax[0].scatter(data_sampler.mixed_data.cpu().numpy()[:, 0], data_sampler.mixed_data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\\n    ax[0].set_xlabel(r\"$x_1$\")\\n    ax[0].set_ylabel(r\"$x_2$\")\\n    \\n    ax[1].set_title(\"Reconstructed samples\")\\n    ax[1].scatter(recon[:, 0], recon[:, 1], c = data_sampler.sample_labels)\\n    ax[1].set_xlabel(r\"$x_1$\")\\n    ax[1].set_ylabel(r\"$x_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/reconstruction_scatter_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Reconstruction\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Mixed samples\")\\n    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 0])\\n    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 1])\\n    ax[0].set_xlabel(r\"$x_1$\")\\n    ax[0].set_ylabel(r\"$x_2$\")\\n    \\n    ax[1].set_title(\"Reconstructed samples\")\\n    ax[1].plot(recon[:, 0])\\n    ax[1].plot(recon[:, 1])\\n    ax[1].set_xlabel(r\"$x_1$\")\\n    ax[1].set_ylabel(r\"$x_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/reconstruction_signals_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Sources\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Original sources\")\\n    ax[0].plot(data_sampler.data.cpu().numpy()[:, 0])\\n    ax[0].plot(data_sampler.data.cpu().numpy()[:, 1])\\n    ax[0].set_xlabel(r\"$z_1$\")\\n    ax[0].set_ylabel(r\"$z_2$\")\\n    \\n    ax[1].set_title(\"Latent sources\")\\n    ax[1].plot(mu_z[:, 0])\\n    ax[1].plot(mu_z[:, 1])\\n    ax[1].set_xlabel(r\"$z_1$\")\\n    ax[1].set_ylabel(r\"$z_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/source_signals_\" + fig_label + \".png\")\\n    plt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG6iC5tRCa0a"
      },
      "source": [
        "# MNIST test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdRLIYtoCaS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf81e2a9-8461-41d0-ad70-f0baadcdba56"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "transform_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x)),])#(0.1307,), (0.3081,)\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "train, valid = torch.utils.data.random_split(mnist_train,[50000,10000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=512, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=512, shuffle=True)\n",
        "\n",
        "total_train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=512, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=512, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "k0wzXF2sDW3P",
        "outputId": "afa13376-f32a-495b-94fa-01e7562bb45f"
      },
      "source": [
        "data_size = 784\n",
        "no_classes = 10\n",
        "latent_size = 50\n",
        "CURL_flag = True\n",
        "epochs = 2\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encode_dict = { \"ff_layers\":[data_size, 512, 256, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 256, 512, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = {  \"ff_layers\":[no_classes, 512, 256, 128, latent_size],\n",
        "                 \"conv_flag\":False }\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, binary_decode = True, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\n",
        "model.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    labels = torch.arange(0, no_classes)\n",
        "    U = torch.eye(no_classes)\n",
        "    mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "    mu_zp = mu_zp.cpu().numpy()\n",
        "    var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "    #print(mu_zp, var_zp)\n",
        "\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"BCE\", gamma = 1, beta = 1, alpha = 0.01)\n",
        "my_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, train_loader, valid_loader, epochs) #Not correct, as we need to split train into 80-20 but ignored for now\n",
        "\n",
        "my_trainer.train_model()\n",
        "my_trainer.plotter()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using CURL formulation, so the model has a class label head.\n",
            "\n",
            "Take note, this decoder also returns the latent sample, as you need it for the VaDE estimation step (and if you want to do it analytically)\n",
            "Making binary layer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rcost at epoch 0: inf:   0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "default LR is 1e-3.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train cost: [ 2.4500e-02  2.3900e-02  6.0000e-04 -2.9000e-03  2.6000e-03  2.3026e+00], valid cost: [ 2.3700e-02  2.2900e-02  8.0000e-04 -2.9000e-03  1.1000e-03  2.3026e+00]: 100%|██████████| 2/2 [00:12<00:00,  6.32s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIwcgkEmnzE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbbd5092-5cd0-456b-d349-9bd987c6080d"
      },
      "source": [
        "with torch.no_grad():\n",
        "    labels = torch.arange(0, no_classes)\n",
        "    U = torch.eye(no_classes)\n",
        "    mu_zp, var_zp = model.prior(U)#\n",
        "    \n",
        "    x, _, _ = model.decoder(mu_zp, var_zp)\n",
        "    \n",
        "    mu_zp = mu_zp.cpu().numpy()\n",
        "    var_zp = var_zp.cpu().numpy()\n",
        "    x = x.cpu().numpy()\n",
        "\n",
        "#fig, ax = plt.subplots(2, 5)\n",
        "#ax = ax.flatten()\n",
        "for i in range(10):\n",
        "    plt.figure()\n",
        "    plt.imshow(x[i, :].reshape(28, 28))\n",
        "    plt.show()\n",
        "\n",
        "q_post = np.array([[]])\n",
        "q_curl = np.array([[]])\n",
        "l_list = np.array([[]])\n",
        "\n",
        "for cnt, i in enumerate(test_loader):\n",
        "    d, l = i\n",
        "    d = d.to(\"cuda:0\")\n",
        "    mu_z, _, _, _ = model.encoder(d, expand_flag = False)\n",
        "    \n",
        "    mu_z = mu_z.detach().cpu().numpy()\n",
        "    \n",
        "    l_post, l_curl = model.infer_label(d)\n",
        "\n",
        "    l_post = l_post.detach().cpu().numpy()\n",
        "    \n",
        "    try:\n",
        "        l_curl = l_curl.detach().cpu().numpy()\n",
        "    except:\n",
        "        l_curl = np.ones_like(l_post) * -999\n",
        "        \n",
        "    l_actual = l.numpy()\n",
        "    \n",
        "    if cnt == 0:\n",
        "        mu_z_total = mu_z\n",
        "        l_post_total = l_post\n",
        "        l_curl_total = l_curl\n",
        "        l_actual_total = l_actual\n",
        "    else:\n",
        "        mu_z_total = np.vstack((mu_z_total, mu_z))\n",
        "        l_post_total = np.concatenate((l_post_total, l_post))\n",
        "        l_curl_total = np.concatenate((l_curl_total, l_curl))\n",
        "        l_actual_total = np.concatenate((l_actual_total, l_actual.reshape(-1)))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 3 if model.CURL_flag else 2)\n",
        "ax = ax.flatten() \n",
        "\n",
        "ax[0].set_title(\"Actual labels\")\n",
        "ax[0].scatter(mu_z_total[:, 0], mu_z_total[:, 1], c = l_actual_total, label = \"test centers\")\n",
        "ax[0].scatter(mu_zp[:, 0], mu_zp[:, 1], color = \"r\", marker = \"x\", label = \"Prior centers\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].set_title(\"predicted labels\")\n",
        "ax[1].scatter(mu_z_total[:, 0], mu_z_total[:, 1], c = l_post_total, label = \"test centers\")\n",
        "ax[1].scatter(mu_zp[:, 0], mu_zp[:, 1], color = \"r\", marker = \"x\", label = \"Prior centers\")\n",
        "ax[1].legend()\n",
        "\n",
        "try:\n",
        "    ax[2].set_title(\"predicted labels (yhead)\")\n",
        "    ax[2].scatter(mu_z_total[:, 0], mu_z_total[:, 1], c = l_curl_total, label = \"test centers\")\n",
        "    ax[2].scatter(mu_zp[:, 0], mu_zp[:, 1], color = \"r\", marker = \"x\", label = \"Prior centers\")\n",
        "    ax[2].legend()\n",
        "\n",
        "except:\n",
        "    pass\n",
        "\n",
        "fig.tight_layout\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X_CcT0mvYd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c400a72-6d69-426a-cab3-62a34d5cdae6"
      },
      "source": [
        "print(l_post_total[:100])\n",
        "print(l_curl_total[:100])\n",
        "print(l_actual_total[:100])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 8 5 6 5 3 7 5 5 9 9 4 8 6 6 4 8 3 1 9 9 4 6 3 3 4 6 8 8 1 2 1 4 5 1 7 1\n",
            " 8 5 5 8 7 9 6 8 4 7 7 4 7 7 5 7 8 8 8 5 1 8 2 3 9 5 8 0 3 4 6 0 9 6 3 0 1\n",
            " 4 9 5 8 5 5 0 1 9 8 8 4 3 1 3 0 3 9 1 4 8 2 2 1 4 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq9GjeEKeI6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931f213a-ea42-4c07-aa9c-cce010e5f969"
      },
      "source": [
        "\n",
        "for scale in [1, 10, 100, 1000, 10000]:\n",
        "    a = torch.rand(10, 10, requires_grad = False)\n",
        "    a[:, 0] = scale\n",
        "    for i in range(a.size(0)):\n",
        "        a[i, :] /= torch.sum(torch.sqrt(a[i, :]**2))\n",
        "\n",
        "    a = a.requires_grad_(True)\n",
        "    #print(a)\n",
        "\n",
        "    l = discrete_KL_divergence(10)\n",
        "    a = torch.repeat_interleave(a, 10, dim =0)\n",
        "    loss = l(a, torch.ones(1,10)/10)\n",
        "    print(torch.mean(loss[0]).item(), loss[1].item(), loss[2].item())\n",
        "\n",
        "#a = a / torch.sum(a)\n",
        "\n",
        "#print(a)\n",
        "#print(-1 * torch.sum(a * torch.log(a)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.198001429438591 2.104583501815796 2.3025848865509033\n",
            "-1.0581969022750854 1.244388461112976 2.3025853633880615\n",
            "-2.0083515644073486 0.29423344135284424 2.3025851249694824\n",
            "-2.2640957832336426 0.03848947584629059 2.3025853633880615\n",
            "-2.2978100776672363 0.004775164648890495 2.3025853633880615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJT5eGsuWAsW"
      },
      "source": [
        "# GAN losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApHIeZYIWDaG"
      },
      "source": [
        "class InfoGAN_loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InfoGAN_loss, self).__init__()\n",
        "        #Gaussian loss and Cross entropy loss\n",
        "        self.MSEloss = nn.MSELoss()\n",
        "        self.CEloss = nn.NLLLoss()\n",
        "    \n",
        "    def forward(self, s_orig, s_recon, c_recon = None, c_targets = None):\n",
        "        \n",
        "        loss_s = self.MSEloss(s_orig, s_recon)\n",
        "        \n",
        "        if c_recon is not None:\n",
        "            loss_c = self.CEloss(c_recon, c_targets)\n",
        "        \n",
        "            return loss_s, loss_c\n",
        "        \n",
        "        else:\n",
        "            return loss_s\n",
        "\n",
        "class GradientPenalty(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GradientPenalty, self).__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, x_real, x_gen, discriminator):\n",
        "        B = x_real.size(0)\n",
        "        \n",
        "        #set up data for interpolation\n",
        "        SizeList = [B] + [1] * len(x_real.size()[1:]) #BatchSize x 1 or BatchSize x 1 x 1 x 1\n",
        "        epsilon = torch.rand(SizeList).to(self.device) #Set it to a Nx1 vector that you can then expand if need be\n",
        "        epsilon = epsilon.expand_as(x_real) #Replicate for each data point\n",
        "        \n",
        "        #generate interpolated data and make it differentiable\n",
        "        with torch.no_grad():\n",
        "            interpolation = epsilon * x_real + (1 - epsilon) * x_gen\n",
        "            \n",
        "        interpolation = interpolation.requires_grad_(True).to(self.device)\n",
        "        \n",
        "        #Push through discriminator\n",
        "        Dinter = discriminator(interpolation)\n",
        "        \n",
        "        #Generate dDdX gradient vector - Make it one as we want dDdX = [[dD1/dX1 + dD2/dX1],[]] (A n by 1 vector)\n",
        "        GradOut = torch.ones_like(Dinter).requires_grad_(False)\n",
        "        \n",
        "        GradX = torch.autograd.grad(outputs = Dinter, inputs = interpolation, grad_outputs = GradOut,  create_graph = True, retain_graph = True)[0]\n",
        "        NormX = torch.sqrt(torch.sum(GradX.view(B, -1).pow(2), dim = 1) + 1e-12)\n",
        "        \n",
        "        GP = (NormX - 1).pow(2).mean()\n",
        "\n",
        "        return GP\n",
        "\n",
        "class ConsensusOptimisation(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(ConsensusOptimisation, self).__init__()\n",
        "      #TODO implement CO loss calculator\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "    def foward(self, lossD, lossG, discriminator, generator):\n",
        "        #################\n",
        "        #Consensus Losses\n",
        "        #################\n",
        "\n",
        "        #Get gradients (not using .backward)\n",
        "        GradD = torch.autograd.grad(lossD, discriminator.parameters(), create_graph = True)\n",
        "        GradG = torch.autograd.grad(lossG, generator.parameters(), create_graph = True)\n",
        "        #GradDz = torch.autograd.grad(torch.mean(outputs[2]), outputs[3], create_graph = True, retain_graph = True)     \n",
        "        \n",
        "        normD = sum([torch.norm(gradient).pow(2) for gradient in GradD])\n",
        "        normG = sum([torch.norm(gradient).pow(2) for gradient in GradG])\n",
        "        #normZ = sum([torch.norm(gradient) for gradient in GradDz])\n",
        "        #lossNorm =  self.gamma * (1/2) * (normD + normG)\n",
        "        #lossNormZ = self._lambda * normZ\n",
        "    \n",
        "        #CalculateNormPercentages\n",
        "        #percent_normD = np.round(normD.item(), 3)\n",
        "        #percent_normG = np.round(normG.item(), 3) \n",
        "\n",
        "        return normD + normG\n",
        "\n",
        "class GANloss(nn.Module):\n",
        "    def __init__(self, GANType, GenType, InfoGAN = False, CO_flag = False):\n",
        "        super(GANloss, self).__init__()\n",
        "        self.gan_type = GANType\n",
        "        self.gen_type = GenType\n",
        "        self.InfoGAN = InfoGAN\n",
        "        self.CO_flag = CO_flag\n",
        "        \n",
        "        if self.gan_type.lower() == \"wasserstein\":\n",
        "            print(\"Using Wasserstein GAN loss\")\n",
        "            self.CostD = self.GANLoss_D(Wasserstein = True)\n",
        "            self.CostG = self.GANLoss_G(Wasserstein = True, GenType = self.gen_type)\n",
        "            self.GP = GradientPenalty()\n",
        "\n",
        "        elif self.gan_type.lower() == \"hinge\":\n",
        "            print(\"Using hinge GAN loss\")\n",
        "            self.CostD = self.GANLoss_D(Hinge = True)\n",
        "            self.CostG = self.GANLoss_G(Hinge = True, GenType = self.gen_type)\n",
        "        \n",
        "        else:\n",
        "            print(\"Using standard GAN loss\")\n",
        "            self.CostD = self.GANLoss_D()\n",
        "            self.CostG = self.GANLoss_G(GenType = self.gen_type)\n",
        "        \n",
        "        if self.InfoGAN:\n",
        "            self.CostInfo = InfoGAN_loss()\n",
        "        \n",
        "        if self.CO_flag:\n",
        "            self.COloss = ConsensusOptimisation()\n",
        "            \n",
        "    @staticmethod  \n",
        "    def GANLoss_D(Wasserstein = False, Hinge = False):\n",
        "        \n",
        "        if Wasserstein and not Hinge:\n",
        "            print(\"\\nUsing Wasserstein GAN loss on D\")\n",
        "            \n",
        "            def DiscriminatorLoss(Data, Type):\n",
        "                if Type.lower() == \"real\":\n",
        "                    BCE = Data\n",
        "\n",
        "                        \n",
        "                elif Type.lower() == \"fake\":\n",
        "                    BCE = -1 * Data\n",
        "\n",
        "                return -1 * torch.mean(BCE)\n",
        "        \n",
        "        elif Hinge and not Wasserstein:\n",
        "            print(\"\\nUsing Hinge GAN loss on D\")\n",
        "            \n",
        "            def DiscriminatorLoss(Data, Type):\n",
        "                if Type.lower() == \"real\":\n",
        "                    BCE = -1 + Data\n",
        "                    with torch.no_grad():\n",
        "                        scale = 1 * (BCE < 0)\n",
        "                    \n",
        "                    BCE = BCE * scale\n",
        "\n",
        "                        \n",
        "                elif Type.lower() == \"fake\":\n",
        "                    BCE = -1 - Data\n",
        "                    with torch.no_grad():\n",
        "                        scale = 1 * (BCE < 0)\n",
        "                    \n",
        "                    BCE = BCE * scale\n",
        "\n",
        "                return -1 * torch.mean(BCE)\n",
        "        \n",
        "        else:\n",
        "            print(\"\\nUsing Standard GAN loss on D\")\n",
        "            \n",
        "            def DiscriminatorLoss(Data, Type):\n",
        "                if Type.lower() == \"real\":\n",
        "                    BCE = torch.log(Data + 1e-16)\n",
        "                        \n",
        "                elif Type.lower() == \"fake\":\n",
        "                    BCE = torch.log(1 - Data + 1e-16)\n",
        "        \n",
        "                return -1 * torch.mean(BCE)\n",
        "            \n",
        "        \n",
        "        return DiscriminatorLoss\n",
        "    \n",
        "    @staticmethod  \n",
        "    def GANLoss_G(Wasserstein = False, Hinge = False, GenType = 1):\n",
        "        \n",
        "        if not Wasserstein and not Hinge:\n",
        "            \n",
        "            if GenType == 1:\n",
        "                print(\"\\nUsing Standard GAN loss on G\")\n",
        "                \n",
        "                def GeneratorLoss(Data):\n",
        "                    \n",
        "                    BCE = torch.log(1 - Data + 1e-16)\n",
        "                    return torch.mean(BCE)\n",
        "\n",
        "            \n",
        "            if GenType == 2:\n",
        "                print(\"\\nUsing non-saturating GAN loss on G\")\n",
        "                \n",
        "                def GeneratorLoss(Data):\n",
        "\n",
        "                    BCE = torch.log(Data + 1e-16)\n",
        "                    return -1 * torch.mean(BCE)\n",
        "\n",
        "                \n",
        "            if GenType == 3:\n",
        "                print(\"\\nUsing KL divergence GAN loss on G\")\n",
        "                def GeneratorLoss(Data):\n",
        "                    KL = torch.log(Data + 1e-16) - torch.log(1 - Data + 1e-16)\n",
        "                    return -1 * torch.mean(KL)\n",
        "        \n",
        "        elif Hinge and not Wasserstein:\n",
        "            \n",
        "            print(\"\\nUsing Hinge GAN loss on G\")\n",
        "            def GeneratorLoss(Data):\n",
        "                return -1 * torch.mean(Data)\n",
        "        \n",
        "        else:\n",
        "            print(\"\\nUsing Wasserstein GAN loss on G\")\n",
        "            def GeneratorLoss(Data):\n",
        "                Wass = Data\n",
        "                return -1 * torch.mean(Wass)\n",
        "        \n",
        "        return GeneratorLoss\n",
        "  \n",
        "    def forward(self, x_real, x_gen, generator, discriminator, dis_update = True, CO_flag = False):\n",
        "\n",
        "        if self.CO_flag:\n",
        "            print(\"You have not implemented Consensus optimisation...\")\n",
        "            raise SystemExit\n",
        "\n",
        "            loss_real = self.CostD(discriminator(x_real), \"real\")\n",
        "            loss_fake = self.CostD(discriminator(x_gen.detach()), \"fake\")\n",
        "\n",
        "            lossD = loss_real + loss_fake\n",
        "            lossG = self.cost.CostG(discriminator(x_gen))\n",
        "\n",
        "            #CO is defined for both losses\n",
        "            loss_total = self.COloss(lossD, lossG, generator, discriminator)\n",
        "\n",
        "        if dis_update:\n",
        "            \n",
        "            loss_real = self.CostD(discriminator(x_real), \"real\")\n",
        "            loss_fake = self.CostD(discriminator(x_gen.detach()), \"fake\")\n",
        "\n",
        "            if self.gan_type.lower() == \"wasserstein\": #Add gradient penalty to discriminator loss\n",
        "                loss_GP = self.GP(x_real, x_gen, discriminator)\n",
        "\n",
        "                loss_total = loss_real + loss_fake + loss_GP\n",
        "\n",
        "            else:\n",
        "                loss_total = loss_real + loss_fake\n",
        "        \n",
        "        else:\n",
        "            loss_real = 0 #real loss does not contribute to generator update\n",
        "            loss_fake = self.CostG(discriminator(x_gen))\n",
        "\n",
        "            loss_total = loss_real + loss_fake\n",
        "        \n",
        "        return loss_total\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZhrCZEWRtWy"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jun  9 14:19:53 2021\n",
        "\n",
        "@author: ryanb\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Implement similarly to the manner I had previously\n",
        "#Dict to define layers\n",
        "#Checks for FF and Convolution\n",
        "#Add in ability to have variance generating component in decoder (unused at this point)\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, ModelDict):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.ModelDict = ModelDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "        \n",
        "        First_no_channels = self.ModelDict[\"channels\"][0]\n",
        "\n",
        "        input_tensor = input_tensor.view(-1, First_no_channels, int(input_tensor.size(1) / First_no_channels))\n",
        "        \n",
        "        return input_tensor\n",
        "\n",
        "class Flatten(nn.Module): #Same name as tensorflow tf.keras.Flatten()\n",
        "    def __init__(self, DisDict):\n",
        "        super(Flatten, self).__init__()\n",
        "        self.DisDict = DisDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "        input_tensor = input_tensor.view(input_tensor.size(0), -1)\n",
        "        \n",
        "        return input_tensor\n",
        "\n",
        "class CondEncoder(nn.Module): #conditional VAE\n",
        "    def __init__(self, encode_dict, activation):\n",
        "        super(CondEncoder, self).__init__()\n",
        "        \n",
        "        self.encode_dict = encode_dict\n",
        "        self.activation = activation\n",
        "        self.layers = []\n",
        "        \n",
        "        if self.encode_dict[\"conv_flag\"]:\n",
        "            \n",
        "            self.conv_layers = []\n",
        "            for i in range(len(self.encode_dict[\"channels\"]) - 1):\n",
        "\n",
        "                #append the layer\n",
        "                self.conv_layers.append( nn.Conv1d(in_channels = self.encode_dict[\"channels\"][i], out_channels = self.encode_dict[\"channels\"][i + 1], kernel_size = self.encode_dict[\"kernel_size\"][i], stride = self.encode_dict[\"stride\"][i], padding = self.encode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.conv_layers.append(self.activation)\n",
        "            \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.conv_layers.append(Flatten(self.encode_dict))\n",
        "            \n",
        "            self.conv_encode = nn.Sequential(*self.conv_layers)\n",
        "                \n",
        "            \n",
        "        for i in range(len(self.encode_dict[\"ff_layers\"]) - 2):\n",
        "            #append the layer\n",
        "            self.layers.append(nn.Linear(in_features = self.encode_dict[\"ff_layers\"][i], out_features = self.encode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "            #append the activation function\n",
        "            self.layers.append(self.activation)\n",
        "        \n",
        "        self.layers.pop(-1)\n",
        "        self.ff_encode = nn.Sequential(*self.layers)\n",
        "        \n",
        "    def forward(self, x, labels = None, cont_input = None):\n",
        "        #Takes in both the x and u variables\n",
        "        #Just so that you don't forget, you coded this so that it takes both inputs in, combines them and then spits out the output\n",
        "        #Always stack as [continuous, discrete]\n",
        "        \n",
        "        if self.encode_dict['conv_flag']:\n",
        "            \n",
        "            x = self.conv_encode(x)\n",
        "            \n",
        "        if cont_input is not None:\n",
        "            x_input = torch.hstack((x, cont_input))\n",
        "\n",
        "        if labels is not None:\n",
        "            u_input = labels#self.one_hot_encode(labels)\n",
        "            x_input = torch.hstack((x, u_input))\n",
        "        \n",
        "        z_encode = self.ff_encode(x_input)\n",
        "        \n",
        "        return z_encode\n",
        "            \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size, Usize, data_size, encode_dict):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.Usize = Usize\n",
        "        self.data_size = data_size\n",
        "        self.encode_dict = encode_dict\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        #Check if it is a standard VAE through Usize\n",
        "        if self.Usize == 0:\n",
        "            self.standard_flag = True\n",
        "\n",
        "        else:\n",
        "            self.standard_flag = False\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "        \n",
        "        if self.standard_flag: #standard VAE\n",
        "            if self.encode_dict[\"conv_flag\"]:\n",
        "                \n",
        "                for i in range(len(self.encode_dict[\"channels\"]) - 1):\n",
        "    \n",
        "                    #append the layer\n",
        "                    self.layers.append( nn.Conv1d(in_channels = self.encode_dict[\"channels\"][i], out_channels = self.encode_dict[\"channels\"][i + 1], kernel_size = self.encode_dict[\"kernel_size\"][i], stride = self.encode_dict[\"stride\"][i], padding = self.encode_dict[\"padding\"][i]) )\n",
        "                    #append the activation function\n",
        "                    self.layers.append(self.activation)\n",
        "                \n",
        "                #append the transform to take the nn.linear to a convolutional layer\n",
        "                self.layers.append(Flatten(self.encode_dict))\n",
        "          \n",
        "            for i in range(len(self.encode_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.encode_dict[\"ff_layers\"][i], out_features = self.encode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            self.layers.pop(-1)\n",
        "            self.encode_net = nn.Sequential(*self.layers)\n",
        "            \n",
        "        else:\n",
        "            #Add Usize to first FF layer\n",
        "            self.encode_net = CondEncoder(self.encode_dict, self.activation)\n",
        "            \n",
        "        self.mu_layer = nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1])\n",
        "        self.var_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1]), self.var_activation)\n",
        "        \n",
        "        #self.encode_net.apply(self.init_weights)\n",
        "        #self.mu_layer.apply(self.init_weights)\n",
        "        #self.var_layer.apply(self.init_weights)\n",
        "    \n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "    \n",
        "    def one_hot_encode(self, labels):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label_mat = torch.zeros(labels.size(0), self.Usize)\n",
        "\n",
        "            label_mat[range(labels.size(0)), labels] = 1\n",
        "\n",
        "            return label_mat\n",
        "  \n",
        "    def forward(self, x, labels = None, cont_input = None):\n",
        "        \n",
        "        if self.encode_dict['conv_flag']:\n",
        "            x = x.unsqueeze(1)\n",
        "        \n",
        "        if self.standard_flag:\n",
        "            encode = self.encode_net(x)\n",
        "        \n",
        "        else:\n",
        "            encode = self.encode_net(x, labels, cont_input)\n",
        "        \n",
        "        mu_z = self.mu_layer(encode)\n",
        "        var_z = self.var_layer(encode)\n",
        "\n",
        "        return mu_z, var_z\n",
        "        \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, Usize, data_size, decode_dict, var_flag = False, binary_flag = False):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.Usize = Usize\n",
        "        self.data_size = data_size\n",
        "        self.decode_dict = decode_dict\n",
        "        self.var_flag = var_flag\n",
        "        self.binary_flag = binary_flag\n",
        "        self.activation = nn.LeakyReLU(0.1)    \n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "        \n",
        "        if not self.decode_dict[\"conv_flag\"]:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1])\n",
        "\n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "            \n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1]), nn.Softplus())\n",
        "                #self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "         \n",
        "        else:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 1):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.layers.append(Unflatten(self.decode_dict))\n",
        "            \n",
        "            for i in range(len(self.decode_dict[\"channels\"]) - 2):\n",
        "\n",
        "                #append the layer\n",
        "                self.layers.append( nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][i], out_channels = self.decode_dict[\"channels\"][i + 1], kernel_size = self.decode_dict[\"kernel_size\"][i], stride = self.decode_dict[\"stride\"][i], padding = self.decode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "\n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "\n",
        "            #self.decode_net.apply(self.init_weights)\n",
        "            #self.gen_layer.apply(self.init_weights)\n",
        "\n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "                                               , nn.Softplus())\n",
        "                #self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparametrisation_trick(mu_data, var_data):\n",
        "        with torch.no_grad():\n",
        "            eta = torch.randn_like(mu_data)\n",
        "\n",
        "        return mu_data + eta * torch.sqrt(var_data)\n",
        "\n",
        "    def forward(self, mu_latent, var_latent):\n",
        "\n",
        "        z_latent = self.reparametrisation_trick(mu_latent, var_latent)\n",
        "\n",
        "        decode_out = self.decode_net(z_latent)\n",
        "\n",
        "        x_out = self.gen_layer(decode_out)\n",
        "\n",
        "        if self.var_flag:\n",
        "            var_out = self.var_layer(decode_out)\n",
        "            \n",
        "        else:\n",
        "            var_out = torch.ones_like(x_out).requires_grad_(False)\n",
        "        \n",
        "        if self.decode_dict[\"conv_flag\"]:\n",
        "            x_out = x_out.squeeze(1)\n",
        "            var_out = var_out.squeeze(1)\n",
        "            \n",
        "        return x_out, var_out\n",
        "\n",
        "        \n",
        "  \n",
        "class ConditionalPrior(nn.Module):\n",
        "    #Can adapt to have parametric densities... (only a mean and variance parameter depending on the class)\n",
        "    def __init__(self, latent_size, Usize, data_size, prior_dict, continuous_prior = True):\n",
        "        super(ConditionalPrior, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.Usize = Usize\n",
        "        self.data_size = data_size\n",
        "        self.prior_dict = prior_dict\n",
        "        self.continuous_prior = continuous_prior\n",
        "\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        #Check if it is a standard VAE, if so, set continuous_prior to False and then set distribution to N(0, I)\n",
        "        if self.Usize == 0:\n",
        "            self.continuous_prior = False\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "        \n",
        "        if self.continuous_prior:\n",
        "            #Define model - essentially another generator but with only FF layers, by design\n",
        "\n",
        "            for i in range(len(self.prior_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.prior_dict[\"ff_layers\"][i], out_features = self.prior_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "          \n",
        "            self.layers.pop(-1)\n",
        "            self.prior_net = nn.Sequential(*self.layers)\n",
        "            self.prior_mu = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "            self.prior_var = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "\n",
        "            #self.prior_net.apply(self.init_weights)\n",
        "            #self.prior_mu.apply(self.init_weights)\n",
        "            #self.prior_var.apply(self.init_weights)\n",
        "      \n",
        "        else:\n",
        "            #Lambda functions that just return the mean and variance parameters at all the class locations of interest!\n",
        "\n",
        "            self.prior_net = lambda U: U\n",
        "            \n",
        "            \n",
        "            if self.Usize == 0:\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size)))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size)))\n",
        "\n",
        "            else:\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(self.Usize, self.latent_size)))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(self.Usize, self.latent_size)))\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(self.Usize, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(self.Usize, self.latent_size))#torch.ones(self.Usize, self.latent_size).to(self.device)#\n",
        "\n",
        "                self.prior_mu = lambda U: self._prior_mu_[torch.argmax(U, dim = 1), :]\n",
        "                self.prior_var = lambda U: self._prior_var_[torch.argmax(U, dim = 1), :]\n",
        "\n",
        "            with torch.no_grad(): #initialise parameters\n",
        "                if self.Usize == 0:\n",
        "                    #Set to N(0, I)\n",
        "                    self._prior_mu_.fill_(0)\n",
        "                    self._prior_var_.fill_(1)\n",
        "                    #Turn off gradient flag\n",
        "                    self._prior_mu_.requires_grad_(False)\n",
        "                    self._prior_var_.requires_grad_(False)\n",
        "                    \n",
        "                else:\n",
        "                    self._prior_mu_.normal_(0, 0.1)\n",
        "                    self._prior_var_.normal_(0, 0.1)\n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "    \n",
        "    def one_hot_encode(self, labels):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label_mat = torch.zeros(labels.size(0), self.Usize)\n",
        "            label_mat[range(labels.size(0)), labels] = 1\n",
        "\n",
        "            return label_mat\n",
        "    \n",
        "    def forward(self, labels = None, cont_input = None):\n",
        "        #Always stack as [continuous, discrete]\n",
        "        if self.Usize == 0:\n",
        "            return self._prior_mu_, self._prior_var_\n",
        "\n",
        "        else:\n",
        "            #if self.continuous_prior:\n",
        "            #    u_input = self.one_hot_encode(labels)\n",
        "            \n",
        "            #else:\n",
        "            u_input = labels\n",
        "            \n",
        "            \n",
        "            if cont_input is not None:\n",
        "                u_input = torch.hstack((cont_input, u_input))\n",
        "\n",
        "            prior_net = self.prior_net(u_input)\n",
        "            mu = self.prior_mu(prior_net)\n",
        "            var = self.var_activation(self.prior_var(prior_net)) \n",
        "            \n",
        "            return mu, var\n",
        "\n",
        "class VAE_model(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, U_size = None, EncodeDict = None, DecodeDict = None, PriorDict = None, var_decode = False, continuous_prior = True):\n",
        "        super(VAE_model, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.U_size = U_size\n",
        "        self.encode_dict = EncodeDict\n",
        "        self.decode_dict = DecodeDict\n",
        "        self.prior_dict = PriorDict\n",
        "        self.var_decode = var_decode\n",
        "        self.continuous_prior = continuous_prior\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.model_HI_names = [\"HI_1\"]\n",
        "        self.model_HI_names_pretty = [r\"$NLL_{recon}$\"]\n",
        "        \n",
        "        #self.U_size\n",
        "        self.encoder = Encoder(self.latent_size, 0, self.input_size, self.encode_dict)\n",
        "        self.decoder = Decoder(self.latent_size, self.U_size, self.input_size, self.decode_dict, var_flag = var_decode)\n",
        "        self.prior = ConditionalPrior(self.latent_size, self.U_size, self.input_size, self.prior_dict, continuous_prior = self.continuous_prior)\n",
        "\n",
        "        if self.U_size == 0:\n",
        "            print(\"\\nInitialising a normal VAE!\\n\")\n",
        "            self.standard_flag = True\n",
        "        \n",
        "        else:\n",
        "            self.standard_flag = False \n",
        "  \n",
        "    def train(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        self.prior.train()\n",
        "    \n",
        "    def eval(self):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "        self.prior.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.encoder.to(device)\n",
        "        self.decoder.to(device)\n",
        "        self.prior.to(device)\n",
        "    \n",
        "    def one_hot_encode(self, labels):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label_mat = torch.zeros(labels.size(0), self.Usize)\n",
        "            label_mat[range(labels.size(0)), labels] = 1\n",
        "\n",
        "            return label_mat\n",
        "\n",
        "    def compute_HIs(self, x, labels = None, cont_input = None): #Only useful if you are performing anomaly detection (specific to another project)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            mu_latent, var_latent = self.encoder(x, labels, cont_input)\n",
        "\n",
        "            x_recon1, var_decoder =  self.decoder(mu_latent, var_latent) \n",
        "            HI_1 = (1 / x.shape[1]) * torch.sum((x - x_recon1)**2 / (var_decoder), dim = 1) \n",
        "\n",
        "            return HI_1, mu_latent\n",
        "\n",
        "class VAE_optimiser(object):\n",
        "    def __init__(self, model, Params):\n",
        "        ls = list(model.encoder.parameters()) + list(model.decoder.parameters()) + list(model.prior.parameters())\n",
        "        self.VAE_opt = torch.optim.Adam(ls, lr = Params.learning_rate)\n",
        "    \n",
        "    def step(self):\n",
        "        self.VAE_opt.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.VAE_opt.zero_grad()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19jTgBWjfHyo"
      },
      "source": [
        "# AAE formulation\n",
        "\n",
        "This code is designed to interface with the iVAE code specifically. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_tWpGNfMYO"
      },
      "source": [
        "#Implement AAE model, optimiser and trainer\n",
        "class WGAN_discriminator(nn.Module):\n",
        "    def __init__(self, input_size, net_size = 1000):\n",
        "        super(WGAN_discriminator, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.net_size = net_size\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.WGAN_net = nn.Sequential(nn.Linear(self.input_size, self.net_size),\n",
        "                                      nn.LeakyReLU(0.1),\n",
        "                                      nn.Linear(self.net_size, self.net_size),\n",
        "                                      nn.LeakyReLU(0.1),\n",
        "                                      nn.Linear(self.net_size, self.net_size),\n",
        "                                      nn.LeakyReLU(0.1),\n",
        "                                      nn.Linear(self.net_size, 1)) #Output is linear for WGAN\n",
        "\n",
        "    def forward(self, input_data):\n",
        "\n",
        "        return self.WGAN_net(input_data)\n",
        "\n",
        "class AAE_model(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, EncodeDict = None, DecodeDict = None, PriorDict = None, var_decode = False, binary_decode = False, continuous_prior = False):\n",
        "        super(AAE_model, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.U_size = 0 #To ensure that it is a standard GAN\n",
        "        self.encode_dict = EncodeDict\n",
        "        self.decode_dict = DecodeDict\n",
        "        self.prior_dict = PriorDict\n",
        "        self.var_decode = var_decode\n",
        "        self.binary_decode = binary_decode\n",
        "        self.continuous_prior = continuous_prior\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.model_HI_names = [\"HI_1\", \"HI_3\"]\n",
        "        self.model_HI_names_pretty = [r\"$NLL_{recon}$\", r\"$\\mathcal{D}_\\mathbf{z}$\"]\n",
        "        \n",
        "        #self.U_size\n",
        "        self.encoder = Encoder(self.latent_size, self.U_size, self.input_size, self.encode_dict)\n",
        "        self.decoder = Decoder(self.latent_size, self.U_size, self.input_size, self.decode_dict, var_flag = var_decode, binary_flag = self.binary_decode)\n",
        "        self.prior = ConditionalPrior(self.latent_size, self.U_size, self.input_size, self.prior_dict, continuous_prior = self.continuous_prior)\n",
        "        self.latent_discriminator = WGAN_discriminator(self.latent_size)\n",
        "\n",
        "        if self.U_size == 0:\n",
        "            print(\"\\nInitialising a normal VAE!\\n\")\n",
        "            self.standard_flag = True\n",
        "        \n",
        "        else:\n",
        "            self.standard_flag = False \n",
        "  \n",
        "    def train(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        self.prior.train()\n",
        "        self.latent_discriminator.train()\n",
        "    \n",
        "    def eval(self):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "        self.prior.eval()\n",
        "        self.latent_discriminator.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.encoder.to(device)\n",
        "        self.decoder.to(device)\n",
        "        self.prior.to(device)\n",
        "        self.latent_discriminator.to(device)\n",
        "\n",
        "    def compute_HIs(self, x, labels = None, cont_input = None): #Only useful if you are performing anomaly detection (specific to another project)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            mu_latent, var_latent = self.encoder(x, labels, cont_input)\n",
        "\n",
        "            x_recon1, var_decoder =  self.decoder(mu_latent, torch.zeros_like(var_latent))\n",
        "            HI_1 = (1 / x.shape[1]) * torch.sum((x - x_recon1)**2 / (var_decoder), dim = 1) \n",
        "\n",
        "            Dz = self.latent_discriminator(mu_latent)\n",
        "\n",
        "            return HI_1, Dz, mu_latent\n",
        "\n",
        "class AAE_optimiser(object):\n",
        "    def __init__(self, model, Params = None, pair_flag = False):\n",
        "\n",
        "        self.pair_flag = pair_flag\n",
        "\n",
        "        ls_recon = list(model.encoder.parameters()) + list(model.decoder.parameters()) + list(model.prior.parameters())\n",
        "\n",
        "        self.recon_opt = torch.optim.Adam(ls_recon, lr = 1e-3)\n",
        "        self.D_regularisation_opt = torch.optim.Adam(model.latent_discriminator.parameters(), lr = 1e-3)\n",
        "        self.G_regularisation_opt = torch.optim.Adam(model.encoder.parameters(), lr = 1e-3)\n",
        "\n",
        "        if self.pair_flag:\n",
        "            print(\"Adding pairwise loss.\")\n",
        "            self.pair_opt = torch.optim.Adam(model.encoder.parameters(), lr = 1e-3)\n",
        "\n",
        "        print(\"\\nLR is 1e-3.\")\n",
        "\n",
        "    def step_recon(self):\n",
        "        self.recon_opt.step()\n",
        "    \n",
        "    def step_D_regularisation(self):\n",
        "        self.D_regularisation_opt.step()\n",
        "    \n",
        "    def step_G_regularisation(self):\n",
        "        self.G_regularisation_opt.step()\n",
        "    \n",
        "    def step_pair(self):\n",
        "        self.pair_opt.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.recon_opt.zero_grad()\n",
        "        self.D_regularisation_opt.zero_grad()\n",
        "        self.G_regularisation_opt.zero_grad()\n",
        "\n",
        "        if self.pair_flag:\n",
        "            self.pair_opt.zero_grad()\n",
        "\n",
        "class AAE_loss(nn.Module):\n",
        "\n",
        "    def __init__(self, loss_name = \"L2\", gamma = 1, beta = 1):\n",
        "        super(AAE_loss, self).__init__()\n",
        "        self.loss_name = loss_name\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        if self.loss_name.lower() == \"l2\":\n",
        "            self.recon_loss = GaussianLoss(reduction = 'none')\n",
        "\n",
        "        elif self.loss_name.lower() == \"l1\":\n",
        "            self.recon_loss = nn.L1Loss(reduction = 'none')\n",
        "        \n",
        "        self.latent_loss = GANloss('wasserstein', 3)\n",
        "    \n",
        "    def sample_prior(self, mu_prior, var_prior, batch_size):\n",
        "        latent_size = mu_prior.size(1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(batch_size, latent_size).to(device)\n",
        "            sample = mu_prior + noise * torch.sqrt(var_prior)\n",
        "            return sample\n",
        "\n",
        "\n",
        "    def forward(self, x, recon_x, mu_0, var_0, mu_1, var_1, generator, discriminator, recon_update = True, dis_update = True):\n",
        "\n",
        "        B, N = x.size()\n",
        "        \n",
        "        if recon_update:\n",
        "            \n",
        "            if isinstance(recon_x, tuple) and self.loss_name.lower() != \"l2\": #Check if it is a tuple, will be this by default when it is fed in.\n",
        "                recon_x = recon_x[0]\n",
        "\n",
        "            Lrecon = self.recon_loss(recon_x, x)\n",
        "            return torch.mean(Lrecon) / (B * N)\n",
        "        \n",
        "        else: #Update discriminator or generator\n",
        "            z_gen = self.sample_prior(mu_1, var_1, B)\n",
        "\n",
        "            Lreg =  self.latent_loss(z_gen, mu_0, generator, discriminator, dis_update)\n",
        "            \n",
        "            return Lreg  / (B * N)\n",
        "\n",
        "\n",
        "#Need to train with the following steps:\n",
        "#Recon\n",
        "#Regularisation\n",
        "#Pairwise\n",
        "\n",
        "class AAE_trainer(object):\n",
        "    def __init__(self, AAE_model, AAE_optimiser, AAE_cost, training_iterator, validation_iterator, epochs, pairwise_samples = None):\n",
        "        self.model = AAE_model\n",
        "        self.optimiser = AAE_optimiser\n",
        "        self.cost = AAE_cost\n",
        "        self.train_iterator = training_iterator\n",
        "        self.valid_iterator = validation_iterator\n",
        "        self.epochs = epochs\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.d_iters = 2\n",
        "        self.pairwise_loss = nn.MSELoss()\n",
        "\n",
        "        self.pairwise_points = torch.tensor([[0, 7],\n",
        "                                             [7, 0]]).float().to(self.device)\n",
        "        \n",
        "        self.pairwise_samples = pairwise_samples\n",
        "\n",
        "        if self.pairwise_samples is not None:\n",
        "            assert self.pairwise_samples.size(0) == self.pairwise_points.size(0), \"The pair latent points and sample size is not the same.\"\n",
        "\n",
        "    def optimise(self, real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, update = True, recon_update = False, dis_update = False): #compute and return loss\n",
        "        \n",
        "        loss = self.cost(real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, self.model.encoder, self.model.latent_discriminator, recon_update, dis_update)\n",
        "\n",
        "        if update:\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            if recon_update: #Update Encoder and Decoder\n",
        "                self.optimiser.step_recon()\n",
        "            \n",
        "            elif dis_update: #Update latent discriminator\n",
        "                self.optimiser.step_D_regularisation()\n",
        "            \n",
        "            else: #Update 'generator' (actually the encoder)\n",
        "                self.optimiser.step_G_regularisation()\n",
        "\n",
        "            self.model.zero_grad()\n",
        "        \n",
        "        return loss\n",
        "        \n",
        "    def train_model(self): #train the models\n",
        "\n",
        "        pbar = tqdm(total = self.epochs, desc = \"cost at epoch {}: {}\".format(0, np.inf)) \n",
        "\n",
        "        cost_train_list = []\n",
        "        cost_valid_list = []\n",
        "        max_valid = np.inf\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            cost_train = np.zeros(3 if self.pairwise_samples is None else 4)\n",
        "            cnt_train = 0\n",
        "\n",
        "            cost_valid = np.zeros(3)\n",
        "            cnt_valid = 0\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            #if self.train_iterator.random_seed: #Extracts random samples from the trainer\n",
        "            ######################\n",
        "            #Update reconstruction\n",
        "            ######################\n",
        "            data = next(iter(self.train_iterator))\n",
        "\n",
        "            if isinstance(data, tuple) or isinstance(data, list): #Check to see if the input is a tuple with labels\n",
        "                      \n",
        "                #Separate data\n",
        "                Xdata = data[0].to(self.device)\n",
        "                labels = data[1].to(self.device)\n",
        "              \n",
        "            else:\n",
        "                #Push to GPU\n",
        "                Xdata = data.to(self.device)\n",
        "                labels = None\n",
        "            \n",
        "            mu_z, var_z = self.model.encoder(Xdata)\n",
        "            mu_recon, var_recon = self.model.decoder(mu_z, var_z)\n",
        "            Xrecon = (mu_recon, var_recon)\n",
        "\n",
        "            Lrecon = self.optimise(Xdata, Xrecon, mu_z, var_z, None, None, update = True, recon_update = True, dis_update = False)\n",
        "            cost_train[0] += Lrecon.item()\n",
        "\n",
        "            ######################\n",
        "            #Update regularisation\n",
        "            ######################\n",
        "            #Update discriminator\n",
        "            for i in range(self.d_iters): \n",
        "                data = next(iter(self.train_iterator))\n",
        "\n",
        "                if isinstance(data, tuple) or isinstance(data, list): #Check to see if the input is a tuple with labels\n",
        "                          \n",
        "                    #Separate data\n",
        "                    Xdata = data[0].to(self.device)\n",
        "                    labels = data[1].to(self.device)\n",
        "                  \n",
        "                else:\n",
        "                    #Push to GPU\n",
        "                    Xdata = data.to(self.device)\n",
        "                    labels = None\n",
        "            \n",
        "                mu_z, var_z = self.model.encoder(Xdata)\n",
        "                mu_p, var_p = self.model.prior()\n",
        "\n",
        "                Ld_latent = self.optimise(Xdata, None, mu_z, var_z, mu_p, var_p, update = True, recon_update = False, dis_update = True)\n",
        "                cost_train[1] += Ld_latent.item()\n",
        "            \n",
        "            cost_train[1] /= self.d_iters\n",
        "            #Update generator\n",
        "            data = next(iter(self.train_iterator))\n",
        "\n",
        "            if isinstance(data, tuple) or isinstance(data, list): #Check to see if the input is a tuple with labels\n",
        "                      \n",
        "                #Separate data\n",
        "                Xdata = data[0].to(self.device)\n",
        "                labels = data[1].to(self.device)\n",
        "              \n",
        "            else:\n",
        "                #Push to GPU\n",
        "                Xdata = data.to(self.device)\n",
        "                labels = None\n",
        "        \n",
        "            mu_z, var_z = self.model.encoder(Xdata)\n",
        "            mu_p, var_p = self.model.prior()\n",
        "\n",
        "            Lg_latent = self.optimise(Xdata, None, mu_z, var_z, mu_p, var_p, update = True, recon_update = False, dis_update = False)\n",
        "            cost_train[2] += Lg_latent.item()\n",
        "            \n",
        "            ######################\n",
        "            #Update pair\n",
        "            ######################\n",
        "            if self.pairwise_samples is not None:\n",
        "                mu_pair, var_pair = self.model.encoder(self.pairwise_samples)\n",
        "                pair_sample = self.model.decoder.reparametrisation_trick(mu_pair, var_pair)\n",
        "\n",
        "                loss_pair = self.pairwise_loss(self.pairwise_points, pair_sample)\n",
        "                loss_pair.backward()\n",
        "                self.optimiser.step_pair()\n",
        "                self.model.zero_grad()\n",
        "                cost_train[3] = loss_pair.item()\n",
        "            \n",
        "            #elif not self.train_iterator.random_seed: #Sequentially loops through data\n",
        "            #    print(\"Please do not use a sequential trainer for the AAE.\")\n",
        "            #    raise SystemExit\n",
        "                \n",
        "            #TODO - add in validation iterator component\n",
        "            #with torch.no_grad(): Turn this off otherwise you cannot evaluate the data...\n",
        "              #if self.valid_iterator.random_seed: #Extracts random samples from the trainer\n",
        "              #    print(\"Random validation iterator is not implemented.\")\n",
        "              #    raise SystemExit\n",
        "\n",
        "              #elif not self.valid_iterator.random_seed: #Sequentially loops through data\n",
        "           \n",
        "            for data in self.valid_iterator:\n",
        "\n",
        "                if isinstance(data, tuple) or isinstance(data, list):\n",
        "                    #Separate data\n",
        "                    Xdata = data[0].to(self.device)\n",
        "                    labels = data[1].to(self.device)\n",
        "                \n",
        "                else:\n",
        "                    Xdata = data.to(self.device)\n",
        "                    labels = None\n",
        "\n",
        "                mu_z, var_z = self.model.encoder(Xdata)\n",
        "                mu_p, var_p = self.model.prior()\n",
        "\n",
        "                mu_recon, var_recon = self.model.decoder(mu_z, var_z)\n",
        "\n",
        "                Xrecon = (mu_recon, var_recon)\n",
        "\n",
        "                lrecon = self.optimise(Xdata, Xrecon, mu_z, var_z, mu_p, var_p, update = False, recon_update = True, dis_update = False)\n",
        "                ld = self.optimise(Xdata, Xrecon, mu_z, var_z, mu_p, var_p, update = False, recon_update = False, dis_update = True)\n",
        "                lg = self.optimise(Xdata, Xrecon, mu_z, var_z, mu_p, var_p, update = False, recon_update = False, dis_update = False)\n",
        "\n",
        "                cost_valid[0] += lrecon.item()\n",
        "                cost_valid[1] += ld.item()\n",
        "                cost_valid[2] += lg.item()\n",
        "                cnt_valid += 1\n",
        "\n",
        "            cost_train_list.append(np.round(cost_train, 4))\n",
        "            cost_valid_list.append(np.round(cost_valid / cnt_valid, 4))\n",
        "\n",
        "            #if cost_valid[-1][0] < max_valid:\n",
        "            #    max_valid = cost_valid_list[-1][0] #Update to be the new minimum\n",
        "            #    self.optimal_state_dict = self.model.state_dict() #Save the optimal state dict\n",
        "            #    self.index_min_valid = i\n",
        "\n",
        "            pbar.set_description(desc = \"train cost: {}, valid cost: {}\".format(cost_train_list[-1], cost_valid_list[-1]))\n",
        "            pbar.update(1)\n",
        "        \n",
        "        pbar.close()\n",
        "\n",
        "        self.train_cost = cost_train_list\n",
        "        self.valid_cost = cost_valid_list\n",
        "\n",
        "        self.model.eval()\n",
        "      \n",
        "    def plotter(self):\n",
        "\n",
        "      v1 = np.array(self.train_cost)\n",
        "      v2 = np.array(self.valid_cost)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 2)\n",
        "      ax = ax.flatten()\n",
        "\n",
        "      for i in ax:\n",
        "          i.grid()\n",
        "          i.set_xlabel(\"Epochs\")\n",
        "          i.set_ylabel(\"Cost\")\n",
        "      \n",
        "      ax[0].set_title(\"Training curves\")\n",
        "      ax[0].plot(v1[:, 0], label = \"Reconstruction loss\")\n",
        "      ax[0].plot(v1[:, 1], label = \"Discriminator loss\")\n",
        "      ax[0].plot(v1[:, 2], label = \"Generator loss\")\n",
        "\n",
        "      if self.pairwise_samples is not None:\n",
        "          ax[0].plot(v1[:, 3], label = \"Pairwise loss\")\n",
        "      #ax[0].scatter([self.index_min_valid] * 3, v1[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "      ax[0].legend()\n",
        "\n",
        "      ax[1].set_title(\"Validation curves\")\n",
        "      ax[1].plot(v2[:, 0], label = \"Reconstruction loss\")\n",
        "      ax[1].plot(v2[:, 1], label = \"Discriminator loss\")\n",
        "      ax[1].plot(v2[:, 2], label = \"Generator loss\")\n",
        "      #ax[1].scatter([self.index_min_valid] * 3, v2[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "      ax[1].legend()\n",
        "\n",
        "      fig.tight_layout()\n",
        "      plt.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luMd-8CHVovG"
      },
      "source": [
        "# Train AAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjrIT27Tesyo"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "transform_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x)),])#(0.1307,), (0.3081,)\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "train, valid = torch.utils.data.random_split(mnist_train,[50000,10000])\n",
        "\n",
        "random_sampler = torch.utils.data.RandomSampler(train, replacement = True, num_samples = 512)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=512, sampler = random_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=512, shuffle=True)\n",
        "\n",
        "total_train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=512, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=512, shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3pnL-BpQ-_r",
        "outputId": "0a02b366-47d8-4a7d-f468-745c03f2fb5b"
      },
      "source": [
        "data_size = 784\n",
        "no_classes = 10\n",
        "latent_size = 2\n",
        "epochs = 4000\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encode_dict = { \"ff_layers\":[data_size, 512, 256, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 256, 512, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = None\n",
        "\n",
        "#Define model\n",
        "model = AAE_model(data_size, latent_size, encode_dict, decode_dict, prior_dict, var_decode = False, binary_decode = True)\n",
        "\n",
        "#push to training device\n",
        "model.to(model.device)\n",
        "\n",
        "#Define optimiser\n",
        "AAE_opt = AAE_optimiser(model, pair_flag = True)\n",
        "\n",
        "#Define VAE cost\n",
        "AAE_cost = AAE_loss(\"L2\", gamma = 1, beta = 1)\n",
        "\n",
        "#setup model trainer\n",
        "#indices 1 and 3 are digits zero and one\n",
        "pair_points = torch.from_numpy(np.vstack((mnist_train[1][0], mnist_train[3][0]))).float().cuda()\n",
        "\n",
        "\n",
        "my_trainer = AAE_trainer(model, AAE_opt, AAE_cost, train_loader, valid_loader, epochs, pairwise_samples = pair_points)\n",
        "\n",
        "#View model\n",
        "print(model)\n",
        "\n",
        "#Train model\n",
        "my_trainer.train_model()\n",
        "\n",
        "#Plot results\n",
        "#my_trainer.plotter()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rcost at epoch 0: inf:   0%|          | 0/4000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Making binary layer\n",
            "\n",
            "Initialising a normal VAE!\n",
            "\n",
            "Adding pairwise loss.\n",
            "\n",
            "LR is 1e-3.\n",
            "Using Wasserstein GAN loss\n",
            "\n",
            "Using Wasserstein GAN loss on D\n",
            "\n",
            "Using Wasserstein GAN loss on G\n",
            "AAE_model(\n",
            "  (encoder): Encoder(\n",
            "    (activation): LeakyReLU(negative_slope=0.1)\n",
            "    (var_activation): Softplus(beta=1, threshold=20)\n",
            "    (encode_net): Sequential(\n",
            "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "      (1): LeakyReLU(negative_slope=0.1)\n",
            "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (3): LeakyReLU(negative_slope=0.1)\n",
            "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    )\n",
            "    (mu_layer): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (var_layer): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=2, bias=True)\n",
            "      (1): Softplus(beta=1, threshold=20)\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (activation): LeakyReLU(negative_slope=0.1)\n",
            "    (decode_net): Sequential(\n",
            "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
            "      (1): LeakyReLU(negative_slope=0.1)\n",
            "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "      (3): LeakyReLU(negative_slope=0.1)\n",
            "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
            "    )\n",
            "    (gen_layer): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=784, bias=True)\n",
            "      (1): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (prior): ConditionalPrior(\n",
            "    (activation): LeakyReLU(negative_slope=0.1)\n",
            "    (var_activation): Softplus(beta=1, threshold=20)\n",
            "  )\n",
            "  (latent_discriminator): WGAN_discriminator(\n",
            "    (WGAN_net): Sequential(\n",
            "      (0): Linear(in_features=2, out_features=1000, bias=True)\n",
            "      (1): LeakyReLU(negative_slope=0.1)\n",
            "      (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "      (3): LeakyReLU(negative_slope=0.1)\n",
            "      (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "      (5): LeakyReLU(negative_slope=0.1)\n",
            "      (6): Linear(in_features=1000, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train cost: [ 0.0001 -0.      0.      0.0544], valid cost: [ 0.0001 -0.      0.    ]:   1%|          | 37/4000 [00:40<1:11:24,  1.08s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_eH9VqLjIO1"
      },
      "source": [
        "for cnt, i in enumerate(test_loader):\n",
        "    d, l = i\n",
        "    d = d.to(\"cuda:0\")\n",
        "    mu_z, var_z = model.encoder(d)\n",
        "    recon, _ = model.decoder(mu_z, var_z)\n",
        "\n",
        "    mu_z = mu_z.detach().cpu().numpy()\n",
        "    l = l.detach().cpu().numpy()\n",
        "    recon = recon.detach().cpu().numpy()\n",
        "\n",
        "    if cnt == 0:\n",
        "        mu_z_total = mu_z\n",
        "        l_total = l\n",
        "        recon_total = recon\n",
        "    else:\n",
        "        mu_z_total = np.vstack((mu_z_total, mu_z))\n",
        "        l_total = np.concatenate((l_total, l))\n",
        "        recon_total = np.concatenate((recon_total, recon))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "ax.set_title(\"Actual labels\")\n",
        "ax.scatter(mu_z_total[:, 0], mu_z_total[:, 1], c = l_total)\n",
        "\n",
        "fig.tight_layout\n",
        "plt.show()\n",
        "\n",
        "mu_z_p, var_z_p = model.prior()\n",
        "print(mu_z_p, var_z_p)\n",
        "\n",
        "fig, ax = plt.subplots(2,10, figsize = (10, 2))\n",
        "ax = ax.flatten()\n",
        "for i in range(20):\n",
        "  ax[i].set_title(\"Number: {}\".format(l_total[i]))\n",
        "  ax[i].imshow(recon_total[i, :].reshape(28, 28))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAEs_with_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfOVSQmy0joe0J6DvAfWEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanBalshaw/VAEs-with-Conditioning/blob/main/VAEs_with_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGxPR-DJgWha"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFlOlkXqvj2Z"
      },
      "source": [
        "VaDE versus CURL:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The differences are minor, you can easily show that the two are the same. Write this up at some point for reference.\n",
        "\n",
        "VaDE objective function:\n",
        "\\begin{equation}\n",
        "L_{VaDE} = \\mathbb{E}_{q(\\mathbf{z}\\vert\\mathbf{x})}\\left[ \\log p(\\mathbf{x}\\vert\\mathbf{z}) \\right] - \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ KL(q(\\mathbf{z}\\vert\\mathbf{x}))\\Vert p(\\mathbf{z}\\vert \\mathbf{y}))\\right] - KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))\n",
        "\\end{equation}\n",
        "\n",
        "CURL objective function:\n",
        "\\begin{equation}\n",
        "L_{CURL} = \\mathbb{E}_{q(\\mathbf{z}\\vert\\mathbf{x}, \\mathbf{y})q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ \\log p(\\mathbf{x}\\vert\\mathbf{z}) \\right] - \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}\\left[ KL(q(\\mathbf{z}\\vert\\mathbf{x}, \\mathbf{y}))\\Vert p(\\mathbf{z}\\vert \\mathbf{y}))\\right] - KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))\n",
        "\\end{equation}\n",
        "\n",
        "Important notes:\n",
        "- Decoder: $p(\\mathbf{x}\\vert\\mathbf{z}) \\sim \\mathcal{N}(\\mathbf{x}\\vert \\mathbf{\\mu}(\\mathbf{z}), \\mathbf{\\sigma}^2(\\mathbf{z})\\mathbf{I})$\n",
        "- Encoder: $q_{VaDE}(\\mathbf{z}\\vert \\mathbf{x}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{x}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{x})\\mathbf{I})$ OR $q_{CURL}(\\mathbf{z}\\vert \\mathbf{x}, \\mathbf{y}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{x}, \\mathbf{y}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{x}, \\mathbf{y})\\mathbf{I})$\n",
        "- Prior $p(\\mathbf{z}\\vert\\mathbf{y}) \\sim \\mathcal{N}(\\mathbf{z}\\vert \\mathbf{\\mu}_{\\mathbf{z}}(\\mathbf{y}), \\mathbf{\\sigma}_{\\mathbf{z}}^2(\\mathbf{y})\\mathbf{I}))$\n",
        "\n",
        "- Prior $p(\\mathbf{y}) \\sim Cat(\\mathbf{\\pi})$ = $\\prod_{k=1}^{K}\\pi_k^{z_k}$\n",
        "\n",
        "The final component is to define $q(\\mathbf{y}\\vert\\mathbf{x})$. VaDE and CURL take vastly different approaches:\n",
        "\n",
        "for VaDE:\n",
        "$q(\\mathbf{y}\\vert\\mathbf{x}) = p(\\mathbf{y}\\vert\\mathbf{z}) = \\frac{p(\\mathbf{y})p(\\mathbf{z}\\vert\\mathbf{y})}{\\sum_{i=1}^Kp(\\mathbf{y})p(\\mathbf{z}\\vert\\mathbf{y})},$\n",
        "\n",
        "where this equation also features in linear mixture models. This term is the posterior probability for y given an observation.\n",
        "\n",
        "For CURL:\n",
        "$q(\\mathbf{y}\\vert\\mathbf{x})$ is part of the encoder, with a softmax 'task inference' head. I like this formulation a little less as I am not convinced that it works well.\n",
        "\n",
        "Why do I say this? Well I noted one potentially problematic area in how CURL estimates the 'categorical regulariser'. From their code, they take a batch and take the average of the argmax of the labels $\\mathbf{y}$, essentially estimating the batch class likelihood. The problem here is that it is not given that a batch will have equal samples from each 'hidden class', so I am not sure how useful this will be when there are unequal spread in the classes. Maybe you need to perform some pre-training inference for the prior $p(\\mathbf{y})$.\n",
        "\n",
        "It is natural, for the continuous distribution $q(\\mathbf{z}\\vert\\cdots)$, to take a Monte Carlo estimate. However, the addition of the distribution categorial distribution, any expectation over $q(\\mathbf{y}\\vert\\mathbf{x})$ then becomes a summation over K indices of the term in the expectation weighted by $q(\\mathbf{y}=i\\vert\\mathbf{x})$.\n",
        "\n",
        "Furthermore, for the middle KL divergence term, both distributions in the KL divergence are Gaussian and thus the KL divergence becomes:\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\left( tr(\\Sigma_1^{-1}\\Sigma_0) + (\\mathbf{\\mu}_1 - \\mathbf{\\mu}_0)^T\\Sigma_1^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_0) - k + \\log\\left(\\frac{det\\Sigma_1}{det\\Sigma_2}\\right) \\right)$,\n",
        "\n",
        "where $\\mathcal{N}_0\\sim\\mathcal{N}(\\mathbf{\\mu}_0, \\Sigma_0)$, $\\mathcal{N}_1\\sim\\mathcal{N}(\\mathbf{\\mu}_1, \\Sigma_1)$ and $k$ is the dimensionality of the space covered by the distribution. If $\\Sigma_1$ and $\\Sigma_2$ are parametrised as diagonal covariance distributions $\\Sigma_0 = \\mathbf{\\sigma_0^2}\\mathbf{I}$ and $\\Sigma_1 = \\mathbf{\\sigma_1^2}\\mathbf{I}$ then\n",
        "\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\left( \\sum_{i} \\frac{\\sigma^2_{0,i}}{\\sigma^2_{1,i}} + \\sum_i\\left(\\frac{\\mu_{1,i} - \\mu_{0,i})^2}{\\sigma^2_{1,i}}\\right)  - k + \\sum_i \\log\\left(\\frac{\\sigma^2_{1, i}}{\\sigma^2_{0, i}}\\right)  \\right)$,\n",
        "$KL(\\mathcal{N}_0\\Vert\\mathcal{N}_1) = \\frac{1}{2}\\sum_{i}\\left(  \\frac{\\sigma^2_{0,i}}{\\sigma^2_{1,i}} + \\left(\\frac{\\mu_{1,i} - \\mu_{0,i})^2}{\\sigma^2_{1,i}}\\right)  - 1 +  \\log\\left(\\frac{\\sigma^2_{1, i}}{\\sigma^2_{0, i}}\\right)  \\right)$,\n",
        "\n",
        "Finally, the final KL divergence term can be expanded as follows:\n",
        "$=\\sum_{k=1}^K q(\\mathbf{y}=k\\vert\\mathbf{x}) \\log \\left( \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{p(\\mathbf{y}=k)} \\right)$\n",
        "\n",
        "\n",
        "Let's now focus on the final KL term $KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))$. Since we know that this regularises the posterior conditional probability (i.e. the conditional probability given a sample from $\\mathbf{x}$, which is actually a $\\mathbf{z}$ if you think about where the MoG lies), we need a method to evaluate the KL term. The expansion of the term is straightforward:\n",
        "\n",
        "$KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}[\\left( \\log \\frac{q(\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})} \\right)]$\n",
        "\n",
        "and since y is discrete:\n",
        "\n",
        "$KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{p(\\mathbf{y}=k)} \\right) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log \\frac{q(\\mathbf{y}=k\\vert\\mathbf{x})}{\\pi_k} \\right)$.\n",
        "\n",
        "So, what do CURL and VaDE do? VaDE tries to estimate $p(\\mathbf{y}=k\\vert\\mathbf{x})$ for each $\\mathbf{x}$ while CURL uses a batch-estimated posterior and effectively directly parametrises $q(\\mathbf{y}\\vert\\mathbf{x}) = \\prod_{k=1}^{K} \\gamma_{k}^{y_k}$, where $\\gamma_{k}$ is the batch estimated class likelihood. \n",
        "\n",
        "I just realised there is an alternative derivation, unlike VaDE or CURL, one which allows one to use a cross-entropy term. Let's dissect the KL term even more: since we know $\\pi_k$ is a constant scalar, we can separate the terms nicely:\n",
        "\n",
        "$ KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y})) = \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log q(\\mathbf{y}=k\\vert\\mathbf{x}) \\right) -  \\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\log \\left( pi_k \\right) $\n",
        "\n",
        "where the term on the right can be grouped with the $q(\\mathbf{y}\\vert\\mathbf{x})$ terms in the previous objective functions. This leaves us with $\\sum_{k=1}^{K}q(\\mathbf{y}=k\\vert\\mathbf{x})\\left( \\log q(\\mathbf{y}=k\\vert\\mathbf{x}) \\right)$. What do we do with this? Well if we think about it a little, this is simply the negative of the entropy $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$, which can be considered as a cross-entropy loss. However, the difference is that we do not have labels and the labels, although they should be 1-of-K, will not be. Thus, it is better to leave it as the entropy. I believe Tensorflows softmax_cross_entropy_with_logits is better suited.\n",
        "\n",
        "At the end of the day, I think simply taking the loss at face value is the way to proceed, monitoring $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$ will be useful as this will tell us if any information is encoded into $\\mathbf{y}$, or if it is just left as is by the model. We want to minimize $\\mathcal{H}(q(\\mathbf{y}\\vert\\mathbf{x}))$, which the objective function does do for us when we maximise the ELBO (if you follow the signs for - $KL(q(\\mathbf{y}\\vert\\mathbf{x})\\Vert p(\\mathbf{y}))$), which is a positive.\n",
        "\n",
        "I found the following [entropy](https://adventuresinmachinelearning.com/cross-entropy-kl-divergence/) guide, [tensorflow](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) implementation, [pytorch](https://discuss.pytorch.org/t/equivalent-of-tensorflows-sigmoid-cross-entropy-with-logits-in-pytorch/1985) vs [tensorflow](https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop/39499486#39499486) discussion and [cross-entropy](https://sebastianraschka.com/faq/docs/pytorch-crossentropy.html) discussion useful.\n",
        "\n",
        "The alternative derivation was inspired by the semi-supervised paper by Kingma: Kingma DP, Rezende DJ, Mohamed S, Welling M (2014) Semi-supervised learning with deep generative models. Adv Neural Inf Process Syst 4:3581â€“3589\n",
        "\n",
        "Another thing I just realised is, what if your latent space is large? You may end up with overflow or underflow errors when calculating $q(\\mathbf{y}\\vert\\mathbf{x})$ for the VaDE case. How do we overcome this?\n",
        "\n",
        "Assuming we have access to $\\log p(\\mathbf{z}\\vert\\mathbf{y})$ (which is a Gaussian, so of course we do), we can use the log-sum-exponential trick to calculate the denominator term. However, this will leave a log in the front of $q(\\mathbf{y}\\vert\\mathbf{x})$ (as we design it to be $\\log q(\\mathbf{y}=k\\vert\\mathbf{x}) = \\frac{\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)}{\\log \\left(\\sum_{k=1}^{K}\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k) \\right)}$ and apply log-sum-exp to the denominator). Then, it is as simple to subtract the LSE from the individually weighted logarithms ($\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)$) and take the exponential of this function.\n",
        "\n",
        "In summary: $\\text{exp}(\\log (\\pi_k p(\\mathbf{z}\\vert\\mathbf{y} = k)) - LSE(denominator)) = \\text{exp}(\\log (\\pi_k) + \\log( p(\\mathbf{z}\\vert\\mathbf{y} = k)) - LSE(denominator))$. You will have to validate the numerical stability of this though... Check this [source](https://angusturner.github.io/generative_models/2017/11/03/pytorch-gaussian-mixture-model.html) which also does this and this [source](https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/) which discusses it more directly.\n",
        "\n",
        "Some more things to think about (this is getting messy, I know): VaDE only needs expansion for the KL divergence between the categorical distribution, and you can use Gumbel-Softmax to stop the requirement for the loss to be sampled $K$ times! It effectively omits the $\\mathbb{E}_{q(\\mathbf{y}\\vert\\mathbf{x})}$ step. \n",
        "\n",
        "How does it work? It simply replaces the expectation over a discrete distribution with a continuous equivalent, which then allows us  to perform a Monte Carlo estimate, which just reduces to taking one sample. Very useful for the CURL method!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLM8vRjkG-m"
      },
      "source": [
        "def apply_MLP_to_source(source,\n",
        "                        num_layer,\n",
        "                        num_segment = None,\n",
        "                        iter4condthresh = 10000,\n",
        "                        cond_thresh_ratio = 0.25,\n",
        "                        layer_name_base = 'ip',\n",
        "                        save_layer_data = False,\n",
        "                        Arange=None,\n",
        "                        nonlinear_type = 'ReLU',\n",
        "                        negative_slope = 0.2,\n",
        "                        random_seed=0):\n",
        "    \"\"\"Generate MLP and Apply it to source signal.\n",
        "    Args:\n",
        "        source: source signals. 2D ndarray [num_comp, num_data]\n",
        "        num_layer: number of layers\n",
        "        num_segment: (option) number of segments (only used to modulate random_seed)\n",
        "        iter4condthresh: (option) number of random iteration to decide the threshold of condition number of mixing matrices\n",
        "        cond_thresh_ratio: (option) percentile of condition number to decide its threshold\n",
        "        layer_name_base: (option) layer name\n",
        "        save_layer_data: (option) if true, save activities of all layers\n",
        "        Arange: (option) range of value of mixing matrices\n",
        "        nonlinear_type: (option) type of nonlinearity\n",
        "        negative_slope: (option) parameter of leaky-ReLU\n",
        "        random_seed: (option) random seed\n",
        "    Returns:\n",
        "        mixedsig: sensor signals. 2D ndarray [num_comp, num_data]\n",
        "        mixlayer: parameters of mixing layers\n",
        "    \"\"\"\n",
        "    if Arange is None:\n",
        "        Arange = [-1, 1]\n",
        "    #print(\"Generating sensor signal...\")\n",
        "\n",
        "    # Subfuction to normalize mixing matrix\n",
        "    def l2normalize(Amat, axis=0):\n",
        "        # axis: 0=column-normalization, 1=row-normalization\n",
        "        l2norm = np.sqrt(np.sum(Amat*Amat,axis))\n",
        "        Amat = Amat / l2norm\n",
        "        return Amat\n",
        "\n",
        "    # Initialize random generator\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # To change random_seed based on num_layer and num_segment\n",
        "    for i in range(num_layer):\n",
        "        np.random.rand()\n",
        "\n",
        "    if num_segment is not None:\n",
        "        for i in range(num_segment):\n",
        "            np.random.rand()\n",
        "\n",
        "    num_comp = source.shape[0]\n",
        "\n",
        "    # Determine condThresh ------------------------------------\n",
        "    condList = np.zeros([iter4condthresh])\n",
        "    \n",
        "    for i in range(iter4condthresh):\n",
        "        A = np.random.uniform(Arange[0],Arange[1],[num_comp,num_comp])\n",
        "        A = l2normalize(A, axis=0)\n",
        "        condList[i] = np.linalg.cond(A)\n",
        "\n",
        "    condList.sort() # Ascending order\n",
        "    condThresh = condList[int(iter4condthresh * cond_thresh_ratio)]\n",
        "    #print(\"    cond thresh: {0:f}\".format(condThresh))\n",
        "\n",
        "    # Generate mixed signal -----------------------------------\n",
        "    mixedsig = source.copy()\n",
        "    mixlayer = []\n",
        "    for ln in range(num_layer-1,-1,-1):\n",
        "\n",
        "        # Apply nonlinearity ----------------------------------\n",
        "        if ln < num_layer-1: # No nolinearity for the first layer (source signal)\n",
        "            if nonlinear_type == \"ReLU\": # Leaky-ReLU\n",
        "                mixedsig[mixedsig<0] = negative_slope * mixedsig[mixedsig<0]\n",
        "            else:\n",
        "                raise ValueError\n",
        "\n",
        "        # Generate mixing matrix ------------------------------\n",
        "        condA = condThresh + 1\n",
        "        while condA > condThresh:\n",
        "            A = np.random.uniform(Arange[0], Arange[1], [num_comp, num_comp])\n",
        "            A = l2normalize(A)  # Normalize (column)\n",
        "            condA = np.linalg.cond(A)\n",
        "            #print(\"    L{0:d}: cond={1:f}\".format(ln, condA))\n",
        "        # Bias\n",
        "        b = np.zeros([num_comp]).reshape([1,-1]).T\n",
        "\n",
        "        # Apply bias and mixing matrix ------------------------\n",
        "        mixedsig = mixedsig + b\n",
        "        mixedsig = np.dot(A, mixedsig)\n",
        "\n",
        "        # Storege ---------------------------------------------\n",
        "        layername = layer_name_base + str(ln+1)\n",
        "        mixlayer.append({\"name\":layername, \"A\":A.copy(), \"b\":b.copy()})\n",
        "        # Storege data\n",
        "        if save_layer_data:\n",
        "            mixlayer[-1][\"x\"] = mixedsig.copy()\n",
        "\n",
        "    return mixedsig, mixlayer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ8e7-cmkKou"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "        \n",
        "class iVAE_datasets(object):\n",
        "    \n",
        "    def __init__(self, n, M, Lsegments, k, batch_size = 64, randomise = True, random_seed = False, mod_flag = False, mix_L = 1, Gauss_source = True, seed = True):\n",
        "        \"\"\"\n",
        "        n = size of latent space\n",
        "        M = no. classes\n",
        "        Lsegments = no. samples per class\n",
        "        k = no. of prior parameters\n",
        "            k = 1: variance Gaussian\n",
        "            k = 2: mean and variance gaussian\n",
        "        mod_flag = case where one signal has mean modulation and the other doesn't\n",
        "        \"\"\"\n",
        "        self.latent_size = n\n",
        "        self.no_classes = M\n",
        "        self.no_samples = Lsegments\n",
        "        self.k = k\n",
        "        self.batch_size = batch_size #specifies the batch size\n",
        "        self.randomise = randomise #Specifies that sample must be obtained randomly (not uniformly)\n",
        "        self.random_seed = random_seed #If random_seed = True - specifies that a random sample is required and the counter is not increased!\n",
        "        self.mod_flag = mod_flag\n",
        "        self.mix_L = mix_L\n",
        "        self.Gauss_source = Gauss_source\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        #Define mixing model (Unused)\n",
        "        #self.mixing_model = mixing_MLP(self.latent_size, 1)\n",
        "        #self.mixing_model.to(self.device)\n",
        "        #print(self.mixing_model)\n",
        "        \n",
        "        if self.k == 1 and not self.mod_flag:\n",
        "            #print(\"\\nVariance modulated sources.\\n\")\n",
        "            self.mu_centers = np.zeros((self.no_classes, self.latent_size))\n",
        "            \n",
        "        elif self.k == 2 and not self.mod_flag:\n",
        "            #print(\"\\nMean and variance modulated sources.\\n\")\n",
        "            if seed:\n",
        "                np.random.seed(2**13 + 4)\n",
        "\n",
        "            self.mu_centers = np.random.rand(self.no_classes, self.latent_size) * 10 - 5         # in range (-5, 5)\n",
        "            self.mu_centers += np.sign(self.mu_centers) * 5 #Shift centers a outwards a little\n",
        "       \n",
        "        else:\n",
        "            self.mu_centers = np.zeros((self.no_classes, self.latent_size))\n",
        "            \n",
        "            list_range = np.arange(0, self.no_classes, 1)\n",
        "            np.random.shuffle(list_range) #random permutation gamma(u)\n",
        "            \n",
        "            a = np.random.random() * 10 - 5\n",
        "            \n",
        "            self.mu_centers[:, 1] =  a * list_range\n",
        "            \n",
        "        if not hasattr(self, \"std_centers\"):\n",
        "            self.std_centers = np.random.rand(self.no_classes, self.latent_size) * 2.5 + 0.5      # in range (0.5, 3)\n",
        "        \n",
        "        #Make the sample labels\n",
        "        self.sample_labels = []\n",
        "        for i in range(self.no_classes):\n",
        "            self.sample_labels += [i] * self.no_samples\n",
        "        self.sample_labels = np.array(self.sample_labels)\n",
        "\n",
        "        self.data = torch.from_numpy(self.sample()).to(self.device)\n",
        "        \n",
        "        #Normalise      \n",
        "        self.data_mean = torch.mean(self.data, dim = 0)\n",
        "        self.data_std = torch.std(self.data, dim = 0)\n",
        "        \n",
        "        self.data = (self.data - self.data_mean) / self.data_std\n",
        "\n",
        "        mixed_data, mix_layer = apply_MLP_to_source(self.data.cpu().numpy().T, self.mix_L, num_segment = self.no_classes)\n",
        "        mixed_data = torch.from_numpy(mixed_data.T).float()\n",
        "\n",
        "        self.mix_layer = mix_layer \n",
        "\n",
        "        if self.mod_flag:\n",
        "            self.mixed_data = torch.hstack((mixed_data[:, [0]], self.data[:, [1]]))\n",
        "        \n",
        "        else:\n",
        "            self.mixed_data = mixed_data\n",
        "        \n",
        "        #Add noise\n",
        "        self.mixed_data += torch.randn_like(self.mixed_data) * 0.01\n",
        "        \n",
        "        self.data_tuples = list(zip(self.data, self.sample_labels)) #list of tuples\n",
        "        self.mixed_data_tuples = list(zip(self.mixed_data, self.sample_labels)) #list of tuples\n",
        "\n",
        "        #shuffle mixed_data\n",
        "        self.shuffled_data_index = np.arange(0, self.mixed_data.size(0), 1, dtype = int)\n",
        "\n",
        "        if self.random_seed:\n",
        "            np.random.shuffle(self.shuffled_data_index)\n",
        "\n",
        "        #Convert self.sample_labels to torch.tensor\n",
        "        self.sample_labels = torch.from_numpy(self.sample_labels)\n",
        "    \n",
        "    def sample(self):\n",
        "        selected_centers = self.sample_labels\n",
        "        \n",
        "        latent_sample = self.mu_centers[selected_centers, :]\n",
        "\n",
        "        if self.Gauss_source:\n",
        "            latent_sample += np.random.randn(len(selected_centers), self.latent_size) * self.std_centers[selected_centers, :]\n",
        "        elif not self.Gauss_source and self.latent_size == 2:\n",
        "            s1 = np.random.laplace(loc = 0, scale = self.std_centers[selected_centers, 0]).reshape(-1, 1)\n",
        "            s2 = np.random.laplace(loc = 0, scale = self.std_centers[selected_centers, 1]).reshape(-1, 1)\n",
        "            latent_sample += np.hstack((s1, s2))\n",
        "        return latent_sample.astype(np.float32)\n",
        "    \n",
        "    #turn the class into an iterator\n",
        "    def __iter__(self):\n",
        "        \n",
        "        self.iter_cnt = 0 #initialises the iterator\n",
        "        return self #returns the iterator object\n",
        "    \n",
        "    def __next__(self):\n",
        "\n",
        "        if not self.random_seed:\n",
        "            start = self.iter_cnt * self.batch_size\n",
        "            end = start + self.batch_size\n",
        "\n",
        "            index = self.shuffled_data_index[start:end]\n",
        "\n",
        "            if end <= len(self.mixed_data_tuples):\n",
        "\n",
        "                self.iter_cnt += 1\n",
        "                \n",
        "                data = self.mixed_data[index, :]\n",
        "                labels = self.sample_labels[index]\n",
        "                \n",
        "                return data, labels\n",
        "\n",
        "            else:\n",
        "                self.iter_cnt= 0\n",
        "                raise StopIteration\n",
        "\n",
        "        else:\n",
        "              print(\"Random sampler is not implemented.\")\n",
        "              raise SystemExit"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgXKzr5OWMi"
      },
      "source": [
        "# Objective functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "UPuk89DsOVsa",
        "outputId": "1af3eb71-08d3-4cb7-dbde-5da8a4b2dc64"
      },
      "source": [
        "class GaussianLoss(nn.Module):\n",
        "    def __init__(self, reduction = \"sum\"):\n",
        "        super(GaussianLoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, x_recon, x):\n",
        "\n",
        "        if isinstance(x_recon, tuple):\n",
        "            #Learnt a variance on the output\n",
        "            mu_recon, var_recon = x_recon\n",
        "\n",
        "        else:\n",
        "            #No learnt variance on the output\n",
        "            mu_recon = x_recon\n",
        "            var_recon = torch.ones_like(x_recon).requires_grad_(False)\n",
        "        \n",
        "        error = x - mu_recon\n",
        "\n",
        "        B, N = x.size()\n",
        "        #Assuming diagonalised covariance:\n",
        "        gauss_log_loss = torch.mul(error.pow(2), 1/(2 * var_recon + 1e-12)) #2x100 error vector is needed to do normal multiplication\n",
        "        gauss_log_loss += 1/2 * torch.log(var_recon + 1e-12)\n",
        "\n",
        "        #Sum over dimensionality\n",
        "        gauss_log_loss = torch.sum(gauss_log_loss, dim = 1, keepdim = True)\n",
        "        \n",
        "        if self.reduction.lower() == \"sum\":\n",
        "            gauss_log_loss +=  torch.sum(gauss_log_loss)\n",
        "\n",
        "        return gauss_log_loss #Unnormalised\n",
        "\n",
        "\n",
        "class KL_divergence(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Implement the KL divergence loss for Gaussian distributions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, std_normal = False):\n",
        "        super(KL_divergence, self).__init__()\n",
        "\n",
        "        self.std_normal = std_normal #A flag to check whether the loss\n",
        "\n",
        "    def forward(self, mu_0, var_0, mu_1 = None, var_1 = None):\n",
        "\n",
        "        if self.std_normal:\n",
        "            mu_1 = torch.zeros_like(mu_0).requires_grad_(False)\n",
        "            var_1 = torch.ones_like(var_0).requires_grad_(False)\n",
        "\n",
        "        #perform everything elementwise and then \n",
        "        Dkl = var_0 / var_1 + ((mu_1 - mu_0)**2) / var_1 - 1 + torch.log(var_1 / var_0)\n",
        "\n",
        "        #Sum over dimensionality\n",
        "        Dkl = 0.5 * torch.sum(Dkl, dim = 1, keepdim = True)\n",
        "\n",
        "        return Dkl #Unnormalised\n",
        "\n",
        "class discrete_KL_divergence(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the KL divergence loss for sampled distributions with likelihoods\n",
        "    \"\"\"\n",
        "    def __init__(self, no_classes):\n",
        "        super(discrete_KL_divergence, self).__init__()\n",
        "\n",
        "        self.no_classes = no_classes\n",
        "\n",
        "    def forward(self, class_prob, prior_prob = None):\n",
        "\n",
        "        assert class_prob.size(1) == self.no_classes, \"There is a mis-match between the pre-defined number of classes and the number of classes given to the discrete KL divergence.\"\n",
        "\n",
        "        if prior_prob is None:\n",
        "          prior_prob = torch.ones(self.no_classes) / self.no_classes\n",
        "\n",
        "        #perform everything elementwise and then you can reduce if required\n",
        "        H_q_G_x = -1 * torch.sum(class_prob * torch.log(class_prob), dim = 1, keepdim = True) #Entropy term\n",
        "        H_p_and_q = -1 * torch.sum(class_prob * torch.log(prior_prob), dim = 1, keepdim = True)  #Cross-entropy term\n",
        "\n",
        "        Dkl = H_p_and_q - H_q_G_x\n",
        "\n",
        "        return Dkl, torch.mean(H_q_G_x), torch.mean(H_p_and_q) #Unnormalised and I sign-corrected the entropy term.\n",
        "\n",
        "class MoG_VAE_loss(nn.Module):\n",
        "    #No ability to learn a variance, variance is controlled by the noise distribution for iVAE\n",
        "    def __init__(self, no_classes, loss_name = \"L2\", gamma = 1, beta = 1, alpha = 1):\n",
        "        super(MoG_VAE_loss, self).__init__()\n",
        "\n",
        "        self.no_classes = no_classes\n",
        "\n",
        "        self.gamma = gamma #Reconstruction loss KL parameter\n",
        "        self.beta = beta #Continuous KL parameter\n",
        "        self.alpha = alpha #Categorial KL parameter\n",
        "\n",
        "        self.loss_name = loss_name\n",
        "\n",
        "        if self.loss_name.lower() == \"l2\":\n",
        "            self.recon_loss = GaussianLoss(reduction = 'none')\n",
        "        \n",
        "        elif self.loss_name.lower() == \"l1\":\n",
        "            self.recon_loss = nn.L1Loss(reduction = 'none')\n",
        "        \n",
        "        elif self.loss_name.lower() == \"bce\":\n",
        "          self.recon_loss = nn.BCELoss(reduction = 'none')\n",
        "        \n",
        "        else:\n",
        "            print(\"Unknown loss entered.\")\n",
        "            raise SystemExit\n",
        "        \n",
        "        self.kl_loss = KL_divergence(False) #Never use a standard VAE case\n",
        "        self.discrete_kl_loss = discrete_KL_divergence(self.no_classes)\n",
        "    \n",
        "    def forward(self, x, recon_x, mu_0, var_0, mu_1, var_1, q_y_G_x, prior_prob = None, CURL = False):\n",
        "        \n",
        "        #You need to expand the input data by no_classes and then reshape it!\n",
        "        #x = torch.repeat_interleave(x, self.no_classes, dim = 0)\n",
        "\n",
        "        B, N = x.size()\n",
        "\n",
        "        if isinstance(recon_x, tuple) and self.loss_name.lower() != \"l2\": #Check if it is a tuple, will be this by default when it is fed in.\n",
        "            recon_x = recon_x[0]\n",
        "\n",
        "        #Reconstruction loss\n",
        "        if CURL:\n",
        "            x = torch.repeat_interleave(x, self.no_classes, dim = 0)\n",
        "\n",
        "            Lrecon = torch.sum(self.recon_loss(recon_x, x), dim = 1, keepdim = True)\n",
        "            Lrecon = Lrecon.reshape(B, self.no_classes)\n",
        "            Lrecon *= q_y_G_x #weight by categorical likelihood\n",
        "            Lrecon = torch.sum(Lrecon) / self.no_classes  #Sum all values and normalise by no. of classes\n",
        "\n",
        "        else:\n",
        "            Lrecon = torch.sum(self.recon_loss(recon_x, x), dim = 1, keepdim = True)\n",
        "            Lrecon = torch.sum(Lrecon)  #Sum all values\n",
        "\n",
        "        if mu_0.size(0) * self.no_classes == mu_1.size(0): #A check to see if you are using single samples for many classes (VaDE only)\n",
        "            mu_0 = torch.repeat_interleave(mu_0, self.no_classes, dim = 0) #Need to expand data for all the classes\n",
        "            var_0 = torch.repeat_interleave(var_0, self.no_classes, dim = 0) #Need to expand data for all the classes\n",
        "\n",
        "        #continuous KL divergence loss\n",
        "        Lkl_continuous = self.kl_loss(mu_0, var_0, mu_1, var_1) #Need to normalise with same values reconstruction loss (Pytorch does this automatically unless you specify)\n",
        "        Lkl_continuous = Lkl_continuous.reshape(B, self.no_classes)\n",
        "\n",
        "        Lkl_continuous *= q_y_G_x #weight by categorical likelihood\n",
        "        Lkl_continuous = torch.sum(Lkl_continuous) / self.no_classes #Sum all values and normalise by class size\n",
        "\n",
        "        #discrete KL divergence loss\n",
        "        Lkl_discrete, entropy, cross_entropy = self.discrete_kl_loss(q_y_G_x, prior_prob)\n",
        "        Lkl_discrete = torch.sum(Lkl_discrete)  #Sum all values\n",
        "\n",
        "        Ltotal = 0 * Lrecon + 0 * Lkl_continuous + 10 * Lkl_discrete\n",
        "\n",
        "        #Normalise value\n",
        "        Lrecon /= (B * N)\n",
        "        Lkl_continuous /= (B * N)\n",
        "        Lkl_discrete /= (B * N)\n",
        "        Ltotal /= (B * N)\n",
        "\n",
        "        return Ltotal, Lrecon, Lkl_continuous, Lkl_discrete, entropy, cross_entropy\n",
        "\n",
        "\"\"\"\n",
        "#TESTING THE FUNCTIONS\n",
        "no_samples = 512\n",
        "no_classes = 3\n",
        "a = torch.randn(no_samples, 5)\n",
        "b = a + torch.randn_like(a) * 0.1\n",
        "mu_0 = torch.ones_like(a)\n",
        "mu_1 = torch.zeros_like(a)\n",
        "var_0 = torch.ones_like(a)\n",
        "var_1 = torch.ones_like(a)\n",
        "\n",
        "a = torch.repeat_interleave(a, no_classes, dim = 0)\n",
        "b = torch.repeat_interleave(b, no_classes, dim = 0)\n",
        "mu_0 = torch.repeat_interleave(mu_0, no_classes, dim = 0)\n",
        "mu_1 = torch.repeat_interleave(mu_1, no_classes, dim = 0)\n",
        "var_0 = torch.repeat_interleave(var_0, no_classes, dim = 0)\n",
        "var_1 = torch.repeat_interleave(var_1, no_classes, dim = 0)\n",
        "\n",
        "loss = MoG_VAE_loss(no_classes)\n",
        "q_y_G_x = torch.ones(no_samples, no_classes) / no_classes\n",
        "\n",
        "print(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, False))\n",
        "print(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, True))\n",
        "print(torch.mean((b - a)**2)/2, torch.mean((b - a)**2)/(2 * no_classes))\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#TESTING THE FUNCTIONS\\nno_samples = 512\\nno_classes = 3\\na = torch.randn(no_samples, 5)\\nb = a + torch.randn_like(a) * 0.1\\nmu_0 = torch.ones_like(a)\\nmu_1 = torch.zeros_like(a)\\nvar_0 = torch.ones_like(a)\\nvar_1 = torch.ones_like(a)\\n\\na = torch.repeat_interleave(a, no_classes, dim = 0)\\nb = torch.repeat_interleave(b, no_classes, dim = 0)\\nmu_0 = torch.repeat_interleave(mu_0, no_classes, dim = 0)\\nmu_1 = torch.repeat_interleave(mu_1, no_classes, dim = 0)\\nvar_0 = torch.repeat_interleave(var_0, no_classes, dim = 0)\\nvar_1 = torch.repeat_interleave(var_1, no_classes, dim = 0)\\n\\nloss = MoG_VAE_loss(no_classes)\\nq_y_G_x = torch.ones(no_samples, no_classes) / no_classes\\n\\nprint(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, False))\\nprint(loss(a, b, mu_0, var_0, mu_1, var_1, q_y_G_x, True))\\nprint(torch.mean((b - a)**2)/2, torch.mean((b - a)**2)/(2 * no_classes))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQnjV1THp_iK"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQtrkYUZeJS"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Implement similarly to the manner I had previously\n",
        "#Dict to define layers\n",
        "#Checks for FF and Convolution\n",
        "#Add in ability to have variance generating component in decoder (unused at this point)\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, ModelDict):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.ModelDict = ModelDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "        \n",
        "        First_no_channels = self.ModelDict[\"channels\"][0]\n",
        "\n",
        "        input_tensor = input_tensor.view(-1, First_no_channels, int(input_tensor.size(1) / First_no_channels))\n",
        "        \n",
        "        return input_tensor\n",
        "\n",
        "class Flatten(nn.Module): #Same name as tensorflow tf.keras.Flatten()just because it makes sense\n",
        "    def __init__(self, DisDict):\n",
        "        super(Flatten, self).__init__()\n",
        "        self.DisDict = DisDict\n",
        "        \n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "        input_tensor = input_tensor.view(input_tensor.size(0), -1)\n",
        "        \n",
        "        return input_tensor\n",
        "\n",
        "class MoG_Encoder(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size, encode_dict, CURL_flag = False):\n",
        "\n",
        "        #The purpose of the CURL flag is to specify whether we learn a classification layer\n",
        "        #or if we estimate the class from the data. \n",
        "\n",
        "        super(MoG_Encoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes #Controls the size of the class space\n",
        "        self.data_size = data_size\n",
        "        self.encode_dict = encode_dict\n",
        "        self.CURL_flag = CURL_flag\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        #Check if it is a standard VAE through no_classes\n",
        "        if self.no_classes == 0:\n",
        "            print(\"You are using a MoG VAE but have set the class size to zero... why?\")\n",
        "            raise SystemExit\n",
        "        \n",
        "        if self.CURL_flag:\n",
        "            print(\"\\nUsing CURL formulation, so the model has a class label head.\")\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "\n",
        "        if self.encode_dict[\"conv_flag\"]:\n",
        "            \n",
        "            for i in range(len(self.encode_dict[\"channels\"]) - 1):\n",
        "\n",
        "                #append the layer\n",
        "                self.layers.append( nn.Conv1d(in_channels = self.encode_dict[\"channels\"][i], out_channels = self.encode_dict[\"channels\"][i + 1], kernel_size = self.encode_dict[\"kernel_size\"][i], stride = self.encode_dict[\"stride\"][i], padding = self.encode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.layers.append(Flatten(self.encode_dict))\n",
        "      \n",
        "        for i in range(len(self.encode_dict[\"ff_layers\"]) - 2):\n",
        "            #append the layer\n",
        "            self.layers.append(nn.Linear(in_features = self.encode_dict[\"ff_layers\"][i], out_features = self.encode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "            #append the activation function\n",
        "            self.layers.append(self.activation)\n",
        "\n",
        "        self.layers.pop(-1)\n",
        "        self.encode_net = nn.Sequential(*self.layers) #hidden representation that gets fed into predicting the label and latent \n",
        "\n",
        "        if self.CURL_flag:\n",
        "            self.y_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.no_classes), nn.Softmax(dim = 1))\n",
        "\n",
        "            #If it is CURL, you need to feed x and y to get z ~ q(z|x, y)\n",
        "            self.mu_layer = nn.Linear(self.encode_dict[\"ff_layers\"][-2] + self.no_classes, self.encode_dict[\"ff_layers\"][-1])\n",
        "            self.var_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2] + self.no_classes, self.encode_dict[\"ff_layers\"][-1]), self.var_activation)\n",
        "        \n",
        "        else:\n",
        "            self.mu_layer = nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1])\n",
        "            self.var_layer = nn.Sequential(nn.Linear(self.encode_dict[\"ff_layers\"][-2], self.encode_dict[\"ff_layers\"][-1]), self.var_activation)\n",
        "        \n",
        "        #Initialise weights if you want to\n",
        "        self.encode_net.apply(self.init_weights)\n",
        "        self.mu_layer.apply(self.init_weights)\n",
        "        self.var_layer.apply(self.init_weights)\n",
        "\n",
        "        if self.CURL_flag:\n",
        "            self.y_layer.apply(self.init_weights)\n",
        "    \n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "  \n",
        "    def forward(self, x, cont_input = None, expand_flag = True):\n",
        "        \n",
        "        #Always stack as [x, conditional labels]\n",
        "        #expand_flag controls whether we expand x_input to account for K classes or if we just wish to feed the samples through the model.\n",
        "        #If you don't use the expand flag and you use CURL, then feed y_x from classification head layer in.\n",
        "        #We need to specify the class labels, however for VaDE these are estimated from p(y|x) not q(y|x)\n",
        "\n",
        "        #Account for any conditioning variables\n",
        "        if cont_input is not None:\n",
        "            x_input = torch.hstack((x, cont_input))\n",
        "\n",
        "        else:\n",
        "            x_input = x\n",
        "\n",
        "        encode = self.encode_net(x_input)\n",
        "\n",
        "        if self.CURL_flag:\n",
        "            y_x = self.y_layer(encode) #Model predicted class labels, done on non-expanded data as these are essentially weights for likelihood or KL terms\n",
        "        \n",
        "        else:#VaDE\n",
        "            y_x = None #Do nothing, but we may still want the expanded class labels!\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            labels = torch.arange(self.no_classes).repeat(x.size(0)).to(self.device) #Repeat labels for each sample, required when we use CURL to control the y's. \n",
        "            class_input = F.one_hot(labels, num_classes = self.no_classes).float().to(self.device)\n",
        "\n",
        "        if expand_flag and self.CURL_flag: \n",
        "            #The expansion is only necessary for CURL\n",
        "            #For VaDE, you do not need to expand the samples!Only the KL divergence needs to be expanded\n",
        "            #Expand the data\n",
        "            x_input = torch.repeat_interleave(x_input, self.no_classes, dim = 0)\n",
        "            encode = self.encode_net(x_input)\n",
        "\n",
        "            encode = torch.hstack((encode, class_input))\n",
        "\n",
        "        elif not expand_flag and self.CURL_flag: #If you don't perform training and you use CURL, feed q(y|x) head into encoder\n",
        "            encode = torch.hstack((encode, y_x))\n",
        "        \n",
        "        mu_z = self.mu_layer(encode)\n",
        "        var_z = self.var_layer(encode)\n",
        "            \n",
        "        return mu_z, var_z, y_x, class_input\n",
        "        \n",
        "class MoG_Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size, decode_dict, var_flag = False, binary_flag = True):\n",
        "        super(MoG_Decoder, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size = data_size\n",
        "        self.decode_dict = decode_dict\n",
        "        self.var_flag = var_flag\n",
        "        self.binary_flag = binary_flag\n",
        "        self.activation = nn.LeakyReLU(0.1)    \n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "\n",
        "        print(\"\\nTake note, this decoder also returns the latent sample, as you need it for the VaDE estimation step (and if you want to do it analytically)\")\n",
        "        \n",
        "        if not self.decode_dict[\"conv_flag\"]:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "            \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1])\n",
        "            \n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "\n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.Linear(self.decode_dict[\"ff_layers\"][-2], self.decode_dict[\"ff_layers\"][-1]), nn.Softplus())\n",
        "                #self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "         \n",
        "        else:\n",
        "            for i in range(len(self.decode_dict[\"ff_layers\"]) - 1):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.decode_dict[\"ff_layers\"][i], out_features = self.decode_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            #append the transform to take the nn.linear to a convolutional layer\n",
        "            self.layers.append(Unflatten(self.decode_dict))\n",
        "            \n",
        "            for i in range(len(self.decode_dict[\"channels\"]) - 2):\n",
        "\n",
        "                #append the layer\n",
        "                self.layers.append( nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][i], out_channels = self.decode_dict[\"channels\"][i + 1], kernel_size = self.decode_dict[\"kernel_size\"][i], stride = self.decode_dict[\"stride\"][i], padding = self.decode_dict[\"padding\"][i]) )\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "        \n",
        "            self.layers.pop(-1) #remove the final activation for linear outputs\n",
        "    \n",
        "            self.decode_net = nn.Sequential(*self.layers)\n",
        "            self.gen_layer = nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "\n",
        "            if self.binary_flag: #For MNIST or something like that\n",
        "                print(\"Making binary layer\")\n",
        "                self.gen_layer = nn.Sequential(self.gen_layer, nn.Sigmoid())\n",
        "\n",
        "            self.decode_net.apply(self.init_weights)\n",
        "            self.gen_layer.apply(self.init_weights)\n",
        "\n",
        "            if self.var_flag:\n",
        "                self.var_layer = nn.Sequential(nn.ConvTranspose1d(in_channels = self.decode_dict[\"channels\"][-2], out_channels = self.decode_dict[\"channels\"][-1], kernel_size = self.decode_dict[\"kernel_size\"][-1], stride = self.decode_dict[\"stride\"][-1], padding = self.decode_dict[\"padding\"][-1])\n",
        "                                               , nn.Softplus())\n",
        "                self.var_layer.apply(self.init_weights)\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparametrisation_trick(mu_data, var_data):\n",
        "        with torch.no_grad():\n",
        "            eta = torch.randn_like(mu_data)\n",
        "\n",
        "        return mu_data + eta * torch.sqrt(var_data)\n",
        "\n",
        "    def forward(self, mu_latent, var_latent):\n",
        "\n",
        "        z_latent = self.reparametrisation_trick(mu_latent, var_latent)\n",
        "\n",
        "        decode_out = self.decode_net(z_latent)\n",
        "\n",
        "        x_out = self.gen_layer(decode_out)\n",
        "\n",
        "        if self.var_flag:\n",
        "            var_out = self.var_layer(decode_out)\n",
        "            \n",
        "        else:\n",
        "            var_out = torch.ones_like(x_out).requires_grad_(False)\n",
        "        \n",
        "        if self.decode_dict[\"conv_flag\"]:\n",
        "            x_out = x_out.squeeze(1)\n",
        "            var_out = var_out.squeeze(1)\n",
        "            \n",
        "        return x_out, var_out, z_latent\n",
        "\n",
        "class MoG_ConditionalPrior(nn.Module):\n",
        "    #Can adapt to have parametric densities... (only a mean and variance parameter depending on the class)\n",
        "    #I think for the MoG case, you can use continuous_prior = False\n",
        "    #Assumption for labels fed in: They are one-hot encoded! (Remember this)\n",
        "\n",
        "    def __init__(self, latent_size, no_classes, data_size, prior_dict, continuous_prior = False):\n",
        "        super(MoG_ConditionalPrior, self).__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size = data_size\n",
        "        self.prior_dict = prior_dict\n",
        "        self.continuous_prior = continuous_prior\n",
        "\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.var_activation = nn.Softplus()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        #Check if it is a standard VAE, if so, set continuous_prior to False and then set distribution to N(0, I)\n",
        "        if self.no_classes == 0:\n",
        "            print(\"You are using a MoG VAE but have set the class size to zero... why?\")\n",
        "            raise SystemExit\n",
        "\n",
        "        self.layers = [] #Initialise layers \n",
        "        \n",
        "        if self.continuous_prior:\n",
        "            #Define model - essentially another generator but with only FF layers, by design\n",
        "\n",
        "            for i in range(len(self.prior_dict[\"ff_layers\"]) - 2):\n",
        "                #append the layer\n",
        "                self.layers.append(nn.Linear(in_features = self.prior_dict[\"ff_layers\"][i], out_features = self.prior_dict[\"ff_layers\"][i + 1], bias = True))\n",
        "                #append the activation function\n",
        "                self.layers.append(self.activation)\n",
        "          \n",
        "            self.layers.pop(-1)\n",
        "            self.prior_net = nn.Sequential(*self.layers)\n",
        "            self.prior_mu = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "            self.prior_var = nn.Linear(self.prior_dict[\"ff_layers\"][-2], self.prior_dict[\"ff_layers\"][-1])\n",
        "\n",
        "            #self.prior_net.apply(self.init_weights)\n",
        "            #self.prior_mu.apply(self.init_weights)\n",
        "            #self.prior_var.apply(self.init_weights)\n",
        "      \n",
        "        else: #Label gives a mean and variance.\n",
        "            #Lambda functions that just return the mean and variance parameters at all the class locations of interest!\n",
        "            self.prior_net = lambda U: U #Just a way to bypass the prior_net step in the forward method()\n",
        "\n",
        "            if self.no_classes == 0: #Standard VAE implementation, not useful here\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(1, self.latent_size))\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size), requires_grad = True))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(1, self.latent_size), requires_grad = True))\n",
        "\n",
        "            else:\n",
        "                self.register_parameter(name='_prior_mu_', param=torch.nn.Parameter(torch.Tensor(self.no_classes, self.latent_size), requires_grad = True))\n",
        "                self.register_parameter(name='_prior_var_', param=torch.nn.Parameter(torch.Tensor(self.no_classes, self.latent_size), requires_grad = True))\n",
        "                #self._prior_mu_ = nn.parameter.Parameter(torch.Tensor(self.no_classes, self.latent_size))\n",
        "                #self._prior_var_ = nn.parameter.Parameter(torch.Tensor(self.no_classes, self.latent_size))#torch.ones(self.no_classes, self.latent_size).to(self.device)#\n",
        "\n",
        "                self.prior_mu = lambda U: self._prior_mu_[torch.argmax(U, dim = 1), :]\n",
        "                self.prior_var = lambda U: self._prior_var_[torch.argmax(U, dim = 1), :]\n",
        "\n",
        "            with torch.no_grad(): #initialise parameters\n",
        "                if self.no_classes == 0:\n",
        "                    #Set to N(0, I)\n",
        "                    self._prior_mu_.fill_(0)\n",
        "                    self._prior_var_.fill_(1)\n",
        "                    #Turn off gradient flag\n",
        "                    self._prior_mu_.requires_grad_(False)\n",
        "                    self._prior_var_.requires_grad_(False)\n",
        "                    \n",
        "                else:\n",
        "                    self._prior_mu_.normal_(0, 1)\n",
        "                    self._prior_var_.normal_(0, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            #m.bias.data.fill_(0.01)\n",
        "    \n",
        "    def forward(self, labels = None, cont_input = None): #labels = None for the standard VAE case.\n",
        "        #Always stack as [continuous, discrete]\n",
        "        if self.no_classes == 0: #For a standard VAE, not useful here.\n",
        "            return self._prior_mu_, self._prior_var_\n",
        "\n",
        "        else:\n",
        "            u_input = labels\n",
        "            \n",
        "            if cont_input is not None:\n",
        "                u_input = torch.hstack((cont_input, u_input))\n",
        "\n",
        "            prior_net = self.prior_net(u_input)\n",
        "            mu = self.prior_mu(prior_net)\n",
        "            var = self.var_activation(self.prior_var(prior_net)) \n",
        "            \n",
        "            return mu, var\n",
        "\n",
        "class MoG_ClassPrior(nn.Module):\n",
        "    def __init__(self, latent_size, no_classes, data_size):\n",
        "        super(MoG_ClassPrior, self).__init__()\n",
        "        \n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.data_size =data_size\n",
        "\n",
        "        self.register_parameter(name='prior_prob', param=torch.nn.Parameter(torch.Tensor(1, self.no_classes), requires_grad = False))\n",
        "        self.prior_prob.fill_(1/self.no_classes)\n",
        "\n",
        "        self.gauss_loss = GaussianLoss(reduction = 'none') #This already calculates the NLL, so you just need to add (D/2d*log(2pi)) and multiply the sum by -1\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    def posterior_likelihood(self, latent_samples, mu_class, var_class):\n",
        "        #Method:\n",
        "        #-------\n",
        "        # Calculates p(y|x) for the user. p(y|x) = p(y)p(z|y) / SUM(p(y)p(z|y)) - specifically for VaDE\n",
        "        # Need to calculate log p(z|y) (prior likelihood)\n",
        "        # p(y) is defined in this class through self.prior_prob\n",
        "        # Need to perform log-sum-exp trick to calculate denominator without overflow\n",
        "        #-------\n",
        "\n",
        "        #For each x, push to latent space and resample using reparametrisation trick and calculate log-likelihood of z under p(z|y=k) (thus, you need no_class likelihood for 1 z sample)\n",
        "        #Then calculate p(y=k|x) using \n",
        "\n",
        "        if latent_samples.size(0) * self.no_classes == mu_class.size(0): #A check to see if you are using single samples for many classes (VaDE only)\n",
        "            latent_samples = torch.repeat_interleave(latent_samples, self.no_classes, dim = 0)\n",
        "\n",
        "        kB, z_size = latent_samples.size()\n",
        "        B = kB // self.no_classes\n",
        "\n",
        "        log_samples = -1 * ( self.gauss_loss((mu_class, var_class), latent_samples) + self.latent_size/2 * (np.log(2 * np.pi)) )\n",
        "\n",
        "        log_samples = log_samples.reshape(B, self.no_classes) + torch.log(self.prior_prob)\n",
        "\n",
        "        logsumexp_denominator = torch.logsumexp(log_samples, dim = 1, keepdim = True)\n",
        "        \n",
        "        q_y_G_x = torch.exp(log_samples - logsumexp_denominator)\n",
        "\n",
        "        return q_y_G_x\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJOUTxGIeyA",
        "outputId": "3e56b708-986a-4cbe-ec4f-f15d40bdb1c3"
      },
      "source": [
        "labels = torch.arange(2).repeat(10)\n",
        "F.one_hot(labels, num_classes = 2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqgyVKQNv9Nc"
      },
      "source": [
        "class MoG_VAE_model(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, no_classes = None, EncodeDict = None, DecodeDict = None, PriorDict = None, var_decode = False, continuous_prior = False, CURL_flag = True):\n",
        "        super(MoG_VAE_model, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.no_classes = no_classes\n",
        "        self.encode_dict = EncodeDict\n",
        "        self.decode_dict = DecodeDict\n",
        "        self.prior_dict = PriorDict\n",
        "        self.var_decode = var_decode\n",
        "        self.continuous_prior = continuous_prior\n",
        "        self.CURL_flag = CURL_flag\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.model_HI_names = [\"HI_1\"]\n",
        "        self.model_HI_names_pretty = [r\"$NLL_{recon}$\"]\n",
        "\n",
        "        self.encoder = MoG_Encoder(self.latent_size, self.no_classes, self.input_size, self.encode_dict, CURL_flag = self.CURL_flag)\n",
        "        self.decoder = MoG_Decoder(self.latent_size, self.no_classes, self.input_size, self.decode_dict, var_flag = var_decode)\n",
        "        self.prior = MoG_ConditionalPrior(self.latent_size, self.no_classes, self.input_size, self.prior_dict, continuous_prior = self.continuous_prior)\n",
        "        self.class_prior = MoG_ClassPrior(self.latent_size, self.no_classes, self.input_size)\n",
        "\n",
        "        if self.no_classes == 0:\n",
        "            print(\"Why are you using a MoG VAE with no classes?\")\n",
        "            raise SystemExit\n",
        "\n",
        "    def train(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        self.prior.train()\n",
        "    \n",
        "    def eval(self):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "        self.prior.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.encoder.to(device)\n",
        "        self.decoder.to(device)\n",
        "        self.prior.to(device)\n",
        "        self.class_prior = MoG_ClassPrior(self.latent_size, self.no_classes, self.input_size).to(device)\n",
        "    \n",
        "    def one_hot_encode(self, labels):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label_mat = torch.zeros(labels.size(0), self.no_classes)\n",
        "            label_mat[range(labels.size(0)), labels] = 1\n",
        "\n",
        "            return label_mat\n",
        "\n",
        "    def compute_HIs(self, x, labels = None, cont_input = None): #Only useful if you are performing anomaly detection (specific to another project)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            mu_latent, var_latent, _, _ = self.encoder(x, expand_flag = False)\n",
        "\n",
        "            x_recon1, var_decoder, _ =  self.decoder(mu_latent, var_latent) \n",
        "            HI_1 = (1 / x.shape[1]) * torch.sum((x - x_recon1)**2 / (var_decoder), dim = 1) \n",
        "\n",
        "            return HI_1, mu_latent\n",
        "    \n",
        "    def infer_label(self, x):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #Posterior labels\n",
        "            mu_latent, var_latent, y_pred, class_labels = self.encoder(x, expand_flag = False) \n",
        "\n",
        "            z_latent = self.decoder.reparametrisation_trick(mu_latent, var_latent)\n",
        "\n",
        "            mu_prior, var_prior = self.prior(class_labels)\n",
        "\n",
        "            q_y_G_x = self.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\n",
        "\n",
        "            posterior_labels = torch.argmax(q_y_G_x, dim = 1)\n",
        "\n",
        "            #CURL evaluation\n",
        "            if self.encoder.CURL_flag:\n",
        "                curl_labels = torch.argmax(y_pred, dim = 1)\n",
        "\n",
        "            else:\n",
        "                curl_labels = None\n",
        "\n",
        "            return posterior_labels, curl_labels\n",
        "\n",
        "class MoG_VAE_optimiser(object):\n",
        "    def __init__(self, model, Params):\n",
        "        ls = list(model.encoder.parameters()) + list(model.decoder.parameters()) + list(model.prior.parameters()) + list(model.class_prior.parameters())\n",
        "        self.VAE_opt = torch.optim.Adam(ls, lr = 5e-4)\n",
        "        print(\"\\n\\ndefault LR is 1e-3.\\n\\n\")\n",
        "    \n",
        "    def step(self):\n",
        "        self.VAE_opt.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.VAE_opt.zero_grad()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "fMIwGk5-s5Gl",
        "outputId": "4c0b7d6d-ef5e-4b14-a31a-b8da1ae53937"
      },
      "source": [
        "\"\"\"\n",
        "data_size = 784\n",
        "no_classes = 3\n",
        "latent_size = 2\n",
        "CURL_flag = True\n",
        "\n",
        "encode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = None\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, CURL_flag = CURL_flag)\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\n",
        "#my_trainer = MoG_VAE_trainer()\n",
        "\n",
        "B = 10\n",
        "with torch.no_grad():\n",
        "    x = torch.randn(B, data_size)\n",
        "    mu_z, var_z, y_pred, class_labels = model.encoder(x, expand_flag = True)\n",
        "\n",
        "    mu_prior, var_prior = model.prior(class_labels)\n",
        "\n",
        "    recon_x, var_x, z_latent = model.decoder(mu_z, var_z)\n",
        "\n",
        "    print(\"x\", x.size())\n",
        "    print(\"mu_z\", mu_z.size())\n",
        "    print(\"var_z\", var_z.size(), \"\\n\\n\")\n",
        "    #print(y_pred, \"\\n\\n\")\n",
        "    print(\"class labels\", class_labels.size(), \"\\n\\n\")\n",
        "    print(\"z_latent\", z_latent.size())\n",
        "    print(\"mu_prior\", mu_prior.size())\n",
        "    print(\"var_prior\", var_prior.size(), \"\\n\\n\")\n",
        "    print(\"recon_x\", recon_x.size())\n",
        "    print(\"var_x\", var_x.size(), \"\\n\\n\")\n",
        "\n",
        "    q_y_G_x = model.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\n",
        "    q_y_G_x1, q_y_G_x2 = model.infer_label(x)\n",
        "\n",
        "    print(q_y_G_x)\n",
        "    print(q_y_G_x1, q_y_G_x2)\n",
        "\n",
        "    loss_tup = MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, q_y_G_x, model.class_prior.prior_prob, CURL_flag)\n",
        "    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(q_y_G_x), dim = 1)))\n",
        "    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(model.class_prior.prior_prob), dim = 1)))\n",
        "    print(loss_tup)\n",
        "\n",
        "    if CURL_flag:\n",
        "        loss_tup =MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, y_pred, model.class_prior.prior_prob, CURL_flag)\n",
        "        print(torch.mean(-1 * torch.sum(y_pred * torch.log(y_pred), dim = 1)))\n",
        "        print(torch.mean(-1 * torch.sum(y_pred * torch.log(model.class_prior.prior_prob), dim = 1)))\n",
        "        print(loss_tup)\n",
        "    #print(q_y_G_x, torch.sum(q_y_G_x, dim = 1))\n",
        "    #print(q_y_G_x[0, :], torch.sum(q_y_G_x[0, :]))\n",
        "    #\n",
        "\n",
        "\"\"\"   "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata_size = 784\\nno_classes = 3\\nlatent_size = 2\\nCURL_flag = True\\n\\nencode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\\n                \"conv_flag\":False }\\n\\ndecode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\\n                \"conv_flag\":False }\\n\\nprior_dict = None\\n\\nmodel = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, CURL_flag = CURL_flag)\\nMoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\\nMoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\\n#my_trainer = MoG_VAE_trainer()\\n\\nB = 10\\nwith torch.no_grad():\\n    x = torch.randn(B, data_size)\\n    mu_z, var_z, y_pred, class_labels = model.encoder(x, expand_flag = True)\\n\\n    mu_prior, var_prior = model.prior(class_labels)\\n\\n    recon_x, var_x, z_latent = model.decoder(mu_z, var_z)\\n\\n    print(\"x\", x.size())\\n    print(\"mu_z\", mu_z.size())\\n    print(\"var_z\", var_z.size(), \"\\n\\n\")\\n    #print(y_pred, \"\\n\\n\")\\n    print(\"class labels\", class_labels.size(), \"\\n\\n\")\\n    print(\"z_latent\", z_latent.size())\\n    print(\"mu_prior\", mu_prior.size())\\n    print(\"var_prior\", var_prior.size(), \"\\n\\n\")\\n    print(\"recon_x\", recon_x.size())\\n    print(\"var_x\", var_x.size(), \"\\n\\n\")\\n\\n    q_y_G_x = model.class_prior.posterior_likelihood(z_latent, mu_prior, var_prior)\\n    q_y_G_x1, q_y_G_x2 = model.infer_label(x)\\n\\n    print(q_y_G_x)\\n    print(q_y_G_x1, q_y_G_x2)\\n\\n    loss_tup = MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, q_y_G_x, model.class_prior.prior_prob, CURL_flag)\\n    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(q_y_G_x), dim = 1)))\\n    print(torch.mean(-1 * torch.sum(q_y_G_x * torch.log(model.class_prior.prior_prob), dim = 1)))\\n    print(loss_tup)\\n\\n    if CURL_flag:\\n        loss_tup =MoG_VAE_cost(x, (recon_x, var_x), mu_z, var_z, mu_prior, var_prior, y_pred, model.class_prior.prior_prob, CURL_flag)\\n        print(torch.mean(-1 * torch.sum(y_pred * torch.log(y_pred), dim = 1)))\\n        print(torch.mean(-1 * torch.sum(y_pred * torch.log(model.class_prior.prior_prob), dim = 1)))\\n        print(loss_tup)\\n    #print(q_y_G_x, torch.sum(q_y_G_x, dim = 1))\\n    #print(q_y_G_x[0, :], torch.sum(q_y_G_x[0, :]))\\n    #\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvetzYcyrnkm"
      },
      "source": [
        "class MoG_VAE_trainer(object):\n",
        "    def __init__(self, MoG_VAE_model, MoG_VAE_optimiser, MoG_VAE_cost, training_iterator, validation_iterator, epochs):\n",
        "        self.model = MoG_VAE_model\n",
        "        self.optimiser = MoG_VAE_optimiser\n",
        "        self.cost = MoG_VAE_cost\n",
        "        self.train_iterator = training_iterator\n",
        "        self.valid_iterator = validation_iterator\n",
        "        self.epochs = epochs\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def optimise(self, real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = True): #compute and return loss\n",
        "        \n",
        "        loss, recon, kl, discrete_kl, entropy, cross_entropy = self.cost(real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, self.model.class_prior.prior_prob, self.model.CURL_flag)\n",
        "\n",
        "        if update:\n",
        "            loss.backward()\n",
        "            self.optimiser.step()\n",
        "            self.model.zero_grad()\n",
        "        \n",
        "        return loss, recon, kl, discrete_kl, entropy, cross_entropy\n",
        "        \n",
        "    def train_model(self): #train the models\n",
        "\n",
        "        pbar = tqdm(total = self.epochs, desc = \"cost at epoch {}: {}\".format(0, np.inf)) \n",
        "\n",
        "        model.to(self.device)\n",
        "\n",
        "        cost_train_list = []\n",
        "        cost_valid_list = []\n",
        "        max_valid = np.inf\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            cost_train_total = 0\n",
        "            cost_train_other = np.zeros(5)\n",
        "            cnt_train = 0\n",
        "\n",
        "            cost_valid_total = 0\n",
        "            cost_valid_other = np.zeros(5)\n",
        "            cnt_valid = 0\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            #if self.train_iterator.random_seed: #Extracts random samples from the trainer\n",
        "            #    print(\"Random iterator is not implemented.\")\n",
        "            #    raise SystemExit\n",
        "\n",
        "            #elif not self.train_iterator.random_seed: #Sequentially loops through data\n",
        "                \n",
        "            for data in self.train_iterator:\n",
        "                if isinstance(data, tuple) or isinstance(data, list): #Check to see if the input is a tuple with labels\n",
        "                      \n",
        "                      #Separate data\n",
        "                      Xdata = data[0].to(self.device)\n",
        "                      labels = data[1].to(self.device)\n",
        "                  \n",
        "                else:\n",
        "                      #Push to GPU\n",
        "                      Xdata = data.to(self.device)\n",
        "                      labels = None\n",
        "\n",
        "                #Encoder\n",
        "                mu_z_encoder, var_z_encoder, q_y_G_x, class_labels = self.model.encoder(Xdata, expand_flag = True)\n",
        "                #Prior\n",
        "                mu_z_prior, var_z_prior = self.model.prior(class_labels)\n",
        "                #Decoder\n",
        "                mu_recon, var_recon, z_latent = self.model.decoder(mu_z_encoder, var_z_encoder)\n",
        "                Xrecon = (mu_recon, var_recon)\n",
        "                \n",
        "                #If not CURL, calculate posterior\n",
        "                if not self.model.CURL_flag:\n",
        "                    q_y_G_x = self.model.class_prior.posterior_likelihood(z_latent, mu_z_prior, var_z_prior)\n",
        "                \n",
        "                losses = self.optimise(Xdata, Xrecon, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = True)\n",
        "                \n",
        "                cost_train_total += losses[0].item()\n",
        "\n",
        "                for cnt, i in enumerate(losses[1:]):\n",
        "                    cost_train_other[cnt] += i.item()\n",
        "\n",
        "                cnt_train += 1\n",
        "\n",
        "            #TODO - add in validation iterator component\n",
        "            with torch.no_grad():\n",
        "                #if self.valid_iterator.random_seed: #Extracts random samples from the trainer\n",
        "                #    print(\"Random iterator is not implemented.\")\n",
        "                #    raise SystemExit\n",
        "\n",
        "                #elif not self.valid_iterator.random_seed: #Sequentially loops through data\n",
        "                for data in self.valid_iterator:\n",
        "\n",
        "                    if isinstance(data, tuple) or isinstance(data, list):\n",
        "                        #Separate data\n",
        "                        Xdata = data[0].to(self.device)\n",
        "                        labels = data[1].to(self.device)\n",
        "                    \n",
        "                    else:\n",
        "                        Xdata = data.to(self.device)\n",
        "                        labels = None\n",
        "\n",
        "                    #Encoder\n",
        "                    mu_z_encoder, var_z_encoder, q_y_G_x, class_labels = self.model.encoder(Xdata, expand_flag = True)\n",
        "                    #Prior\n",
        "                    mu_z_prior, var_z_prior = self.model.prior(class_labels)\n",
        "                    #Decoder\n",
        "                    mu_recon, var_recon, z_latent = self.model.decoder(mu_z_encoder, var_z_encoder)\n",
        "                    Xrecon = (mu_recon, var_recon)\n",
        "                    \n",
        "                    #If not CURL, calculate posterior\n",
        "                    if not self.model.CURL_flag:\n",
        "                        q_y_G_x = self.model.class_prior.posterior_likelihood(z_latent, mu_z_prior, var_z_prior)\n",
        "                    \n",
        "                    losses = self.optimise(Xdata, Xrecon, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update = False)\n",
        "\n",
        "                    cost_valid_total += losses[0].item()\n",
        "\n",
        "                    for cnt, i in enumerate(losses[1:]):\n",
        "                        cost_valid_other[cnt] += i.item()\n",
        "\n",
        "                    cnt_valid += 1\n",
        "\n",
        "            cost_train_array = np.round(np.hstack((np.array([cost_train_total]), cost_train_other)) / cnt_train, 4)       \n",
        "            cost_valid_array = np.round(np.hstack((np.array([cost_valid_total]), cost_valid_other)) / cnt_valid, 4) \n",
        "\n",
        "            cost_train_list.append(cost_train_array)\n",
        "            cost_valid_list.append(cost_valid_array)\n",
        "\n",
        "            if cost_valid_list[-1][0] < max_valid:\n",
        "                max_valid = cost_valid_list[-1][0] #Update to be the new minimum\n",
        "                self.optimal_state_dict = self.model.state_dict() #Save the optimal state dict\n",
        "                self.index_min_valid = i\n",
        "\n",
        "            pbar.set_description(desc = \"train cost: {}, valid cost: {}\".format(cost_train_list[-1], cost_valid_list[-1]))\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        self.train_cost = cost_train_list\n",
        "        self.valid_cost = cost_valid_list\n",
        "\n",
        "        self.model.eval()\n",
        "      \n",
        "    def plotter(self):\n",
        "\n",
        "      v1 = np.array(self.train_cost)\n",
        "      v2 = np.array(self.valid_cost)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 2)\n",
        "      ax = ax.flatten()\n",
        "\n",
        "      for i in ax:\n",
        "          i.grid()\n",
        "          i.set_xlabel(\"Epochs\")\n",
        "          i.set_ylabel(\"Cost\")\n",
        "      \n",
        "      ax[0].set_title(\"Training curves\")\n",
        "      ax[0].plot(v1[:, 0], label = \"Total loss\")\n",
        "      ax[0].plot(v1[:, 1], label = \"Gaussian loss\")\n",
        "      ax[0].plot(v1[:, 2], label = \"KL divergence loss\")\n",
        "      ax[0].plot(v1[:, 3], label = \"Discrete KL divergence loss\")\n",
        "      ax[0].plot(v1[:, 4], label = \"Entropy\")\n",
        "      ax[0].plot(v1[:, 5], label = \"Cross-entropy\")\n",
        "      #ax[0].scatter([self.index_min_valid] * v2.shape[1], v1[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "      ax[0].legend()\n",
        "\n",
        "      ax[1].set_title(\"Validation curves\")\n",
        "      ax[1].plot(v2[:, 0], label = \"Total loss\")\n",
        "      ax[1].plot(v2[:, 1], label = \"Gaussian loss\")\n",
        "      ax[1].plot(v2[:, 2], label = \"KL divergence loss\")\n",
        "      ax[1].plot(v2[:, 3], label = \"Discrete KL divergence loss\")\n",
        "      ax[1].plot(v2[:, 4], label = \"Entropy\")\n",
        "      ax[1].plot(v2[:, 5], label = \"Cross-entropy\")\n",
        "      #ax[1].scatter([self.index_min_valid] * v2.shape[1], v2[self.index_min_valid, :], marker = \"x\", color = \"r\", label = \"minimum validation index\")\n",
        "      ax[1].legend()\n",
        "\n",
        "      fig.tight_layout()\n",
        "      plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "Tv4CK5b1ww2n",
        "outputId": "d726eaf9-736c-4eb3-8a7d-2affb9e3decb"
      },
      "source": [
        "\"\"\"\n",
        "data_size = 2\n",
        "no_classes = 5\n",
        "latent_size = 2\n",
        "\n",
        "k = 2\n",
        "L = 1024\n",
        "mixL = 2\n",
        "batch_size = 128\n",
        "CURL_flag = False\n",
        "\n",
        "epochs = 10\n",
        "data_sampler = iVAE_datasets(data_size, no_classes, L, k, batch_size = batch_size, randomise = True, random_seed = False, mod_flag = False, mix_L = mixL, Gauss_source = False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = {  \"ff_layers\":[no_classes, 128, 128, 128, latent_size],\n",
        "                 \"conv_flag\":False }\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n",
        "\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\n",
        "my_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, data_sampler, data_sampler, epochs)\n",
        "\n",
        "my_trainer.train_model()\n",
        "my_trainer.plotter()\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n",
        "\"\"\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata_size = 2\\nno_classes = 5\\nlatent_size = 2\\n\\nk = 2\\nL = 1024\\nmixL = 2\\nbatch_size = 128\\nCURL_flag = False\\n\\nepochs = 10\\ndata_sampler = iVAE_datasets(data_size, no_classes, L, k, batch_size = batch_size, randomise = True, random_seed = False, mod_flag = False, mix_L = mixL, Gauss_source = False)\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nencode_dict = { \"ff_layers\":[data_size, 128, 128, 128, latent_size],\\n                \"conv_flag\":False }\\n\\ndecode_dict = { \"ff_layers\":[latent_size, 128, 128, 128, data_size],\\n                \"conv_flag\":False }\\n\\nprior_dict = {  \"ff_layers\":[no_classes, 128, 128, 128, latent_size],\\n                 \"conv_flag\":False }\\n\\nmodel = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\\n\\nwith torch.no_grad():\\n  labels = torch.arange(0, no_classes)\\n  U = torch.eye(no_classes)\\n  mu_zp, var_zp = model.prior(U)#\\n\\n  mu_zp = mu_zp.cpu().numpy()\\n  var_zp = var_zp.cpu().numpy()\\n\\n  print(mu_zp, var_zp)\\n\\nMoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\\nMoG_VAE_cost = MoG_VAE_loss(no_classes, \"L2\", gamma = 1, beta = 1, alpha = 1)\\nmy_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, data_sampler, data_sampler, epochs)\\n\\nmy_trainer.train_model()\\nmy_trainer.plotter()\\n\\nwith torch.no_grad():\\n  labels = torch.arange(0, no_classes)\\n  U = torch.eye(no_classes)\\n  mu_zp, var_zp = model.prior(U)#\\n\\n  mu_zp = mu_zp.cpu().numpy()\\n  var_zp = var_zp.cpu().numpy()\\n\\n  print(mu_zp, var_zp)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "MlOW9hqI0eW-",
        "outputId": "48c23300-adaa-4098-fc85-560c0689d213"
      },
      "source": [
        "\"\"\"\n",
        "save_fig_flag = False\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    labels = torch.arange(0, no_classes)\n",
        "    U = torch.eye(no_classes)\n",
        "    mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "    mu_zp = mu_zp.cpu().numpy()\n",
        "    var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "    mu_new = mu_zp[data_sampler.sample_labels.numpy(), :]\n",
        "    var_new = var_zp[data_sampler.sample_labels.numpy(), :]\n",
        "\n",
        "    Z_new = mu_new + np.random.randn(len(data_sampler.sample_labels), latent_size) * np.sqrt(var_new)\n",
        "\n",
        "    #Latent space and prior spaces\n",
        "    fig, ax = plt.subplots(1, 5 if CURL_flag else 4, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    #Original sources\n",
        "    ax[0].set_title(\"Original samples\")\n",
        "    ax[0].scatter(data_sampler.data.cpu().numpy()[:, 0], data_sampler.data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[0].set_xlabel(r\"$s_1$\")\n",
        "    ax[0].set_ylabel(r\"$s_2$\")\n",
        "\n",
        "    #Prior space p(z|u)\n",
        "    ax[1].set_title(\"Prior space\")\n",
        "    ax[1].scatter(Z_new[:, 0], Z_new[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[1].set_xlabel(r\"$z_1$\")\n",
        "    ax[1].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    mu_z, var_z, q_y_G_x, class_labels = model.encoder(data_sampler.mixed_data.to(device), expand_flag = False)\n",
        "    z_scatter = mu_z + torch.randn_like(mu_z) * torch.sqrt(var_z)\n",
        "    z_scatter = z_scatter.cpu().numpy()\n",
        "\n",
        "    q_y_G_x_post, q_y_G_x_curl = model.infer_label(data_sampler.mixed_data.to(device))\n",
        "    \n",
        "    recon, _, _ = model.decoder(mu_z, torch.zeros_like(var_z).to(device))\n",
        "\n",
        "    error = torch.sum((recon - data_sampler.mixed_data.to(device))**2, dim = 1).cpu().numpy() / data_size\n",
        "\n",
        "    recon = recon.cpu().numpy()\n",
        "    mu_z = mu_z.cpu().numpy()\n",
        "    var_z = var_z.cpu().numpy()\n",
        "\n",
        "    U1 = F.one_hot(q_y_G_x_post, no_classes)\n",
        "    U1 = U1.cpu().numpy()\n",
        "\n",
        "    q_y_G_x_post = q_y_G_x_post.cpu().numpy()\n",
        "    \n",
        "    if q_y_G_x_curl is not None:\n",
        "        q_y_G_x_curl = q_y_G_x_curl.cpu().numpy()\n",
        "\n",
        "    #Latent space p(z|x, u)\n",
        "    ax[2].set_title(\"Latent space\")\n",
        "    ax[2].scatter(z_scatter[:, 0], z_scatter[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[2].set_xlabel(r\"$z_1$\")\n",
        "    ax[2].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    #Latent space p(z|x, u)\n",
        "    ax[3].set_title(\"Latent space - posterior label head for colour\")\n",
        "    ax[3].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_post)\n",
        "    ax[3].set_xlabel(r\"$z_1$\")\n",
        "    ax[3].set_ylabel(r\"$z_2$\")\n",
        "    \n",
        "    if CURL_flag:\n",
        "      #Latent space p(z|x, u)\n",
        "      ax[4].set_title(\"Latent space - CURL label head for colour\")\n",
        "      ax[4].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_curl)\n",
        "      ax[4].set_xlabel(r\"$z_1$\")\n",
        "      ax[4].set_ylabel(r\"$z_2$\")\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/latent_space_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.imshow(U1[:100, :])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Reconstruction error\")\n",
        "    plt.scatter(np.arange(len(error)), error)\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/Error_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Reconstruction - scatterplot\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Mixed samples\")\n",
        "    ax[0].scatter(data_sampler.mixed_data.cpu().numpy()[:, 0], data_sampler.mixed_data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[0].set_xlabel(r\"$x_1$\")\n",
        "    ax[0].set_ylabel(r\"$x_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Reconstructed samples\")\n",
        "    ax[1].scatter(recon[:, 0], recon[:, 1], c = data_sampler.sample_labels)\n",
        "    ax[1].set_xlabel(r\"$x_1$\")\n",
        "    ax[1].set_ylabel(r\"$x_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/reconstruction_scatter_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Reconstruction\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Mixed samples\")\n",
        "    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 0])\n",
        "    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 1])\n",
        "    ax[0].set_xlabel(r\"$x_1$\")\n",
        "    ax[0].set_ylabel(r\"$x_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Reconstructed samples\")\n",
        "    ax[1].plot(recon[:, 0])\n",
        "    ax[1].plot(recon[:, 1])\n",
        "    ax[1].set_xlabel(r\"$x_1$\")\n",
        "    ax[1].set_ylabel(r\"$x_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/reconstruction_signals_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\n",
        "    #Sources\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "    ax = ax.flatten()\n",
        "    ax[0].set_title(\"Original sources\")\n",
        "    ax[0].plot(data_sampler.data.cpu().numpy()[:, 0])\n",
        "    ax[0].plot(data_sampler.data.cpu().numpy()[:, 1])\n",
        "    ax[0].set_xlabel(r\"$z_1$\")\n",
        "    ax[0].set_ylabel(r\"$z_2$\")\n",
        "    \n",
        "    ax[1].set_title(\"Latent sources\")\n",
        "    ax[1].plot(mu_z[:, 0])\n",
        "    ax[1].plot(mu_z[:, 1])\n",
        "    ax[1].set_xlabel(r\"$z_1$\")\n",
        "    ax[1].set_ylabel(r\"$z_2$\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig_flag:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"./tmp_figures/source_signals_\" + fig_label + \".png\")\n",
        "    plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nsave_fig_flag = False\\n\\nwith torch.no_grad():\\n\\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n    model.to(device)\\n\\n    labels = torch.arange(0, no_classes)\\n    U = torch.eye(no_classes)\\n    mu_zp, var_zp = model.prior(U)#\\n\\n    mu_zp = mu_zp.cpu().numpy()\\n    var_zp = var_zp.cpu().numpy()\\n\\n    mu_new = mu_zp[data_sampler.sample_labels.numpy(), :]\\n    var_new = var_zp[data_sampler.sample_labels.numpy(), :]\\n\\n    Z_new = mu_new + np.random.randn(len(data_sampler.sample_labels), latent_size) * np.sqrt(var_new)\\n\\n    #Latent space and prior spaces\\n    fig, ax = plt.subplots(1, 5 if CURL_flag else 4, figsize = (12, 8))\\n    ax = ax.flatten()\\n\\n    #Original sources\\n    ax[0].set_title(\"Original samples\")\\n    ax[0].scatter(data_sampler.data.cpu().numpy()[:, 0], data_sampler.data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\\n    ax[0].set_xlabel(r\"$s_1$\")\\n    ax[0].set_ylabel(r\"$s_2$\")\\n\\n    #Prior space p(z|u)\\n    ax[1].set_title(\"Prior space\")\\n    ax[1].scatter(Z_new[:, 0], Z_new[:, 1], c = data_sampler.sample_labels)\\n    ax[1].set_xlabel(r\"$z_1$\")\\n    ax[1].set_ylabel(r\"$z_2$\")\\n\\n    mu_z, var_z, q_y_G_x, class_labels = model.encoder(data_sampler.mixed_data.to(device), expand_flag = False)\\n    z_scatter = mu_z + torch.randn_like(mu_z) * torch.sqrt(var_z)\\n    z_scatter = z_scatter.cpu().numpy()\\n\\n    q_y_G_x_post, q_y_G_x_curl = model.infer_label(data_sampler.mixed_data.to(device))\\n    \\n    recon, _, _ = model.decoder(mu_z, torch.zeros_like(var_z).to(device))\\n\\n    error = torch.sum((recon - data_sampler.mixed_data.to(device))**2, dim = 1).cpu().numpy() / data_size\\n\\n    recon = recon.cpu().numpy()\\n    mu_z = mu_z.cpu().numpy()\\n    var_z = var_z.cpu().numpy()\\n\\n    U1 = F.one_hot(q_y_G_x_post, no_classes)\\n    U1 = U1.cpu().numpy()\\n\\n    q_y_G_x_post = q_y_G_x_post.cpu().numpy()\\n    \\n    if q_y_G_x_curl is not None:\\n        q_y_G_x_curl = q_y_G_x_curl.cpu().numpy()\\n\\n    #Latent space p(z|x, u)\\n    ax[2].set_title(\"Latent space\")\\n    ax[2].scatter(z_scatter[:, 0], z_scatter[:, 1], c = data_sampler.sample_labels)\\n    ax[2].set_xlabel(r\"$z_1$\")\\n    ax[2].set_ylabel(r\"$z_2$\")\\n\\n    #Latent space p(z|x, u)\\n    ax[3].set_title(\"Latent space - posterior label head for colour\")\\n    ax[3].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_post)\\n    ax[3].set_xlabel(r\"$z_1$\")\\n    ax[3].set_ylabel(r\"$z_2$\")\\n    \\n    if CURL_flag:\\n      #Latent space p(z|x, u)\\n      ax[4].set_title(\"Latent space - CURL label head for colour\")\\n      ax[4].scatter(z_scatter[:, 0], z_scatter[:, 1], c = q_y_G_x_curl)\\n      ax[4].set_xlabel(r\"$z_1$\")\\n      ax[4].set_ylabel(r\"$z_2$\")\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/latent_space_\" + fig_label + \".png\")\\n    plt.show()\\n    \\n    plt.figure()\\n    plt.imshow(U1[:100, :])\\n    plt.show()\\n\\n    plt.figure()\\n    plt.title(\"Reconstruction error\")\\n    plt.scatter(np.arange(len(error)), error)\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/Error_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Reconstruction - scatterplot\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Mixed samples\")\\n    ax[0].scatter(data_sampler.mixed_data.cpu().numpy()[:, 0], data_sampler.mixed_data.cpu().numpy()[:, 1], c = data_sampler.sample_labels)\\n    ax[0].set_xlabel(r\"$x_1$\")\\n    ax[0].set_ylabel(r\"$x_2$\")\\n    \\n    ax[1].set_title(\"Reconstructed samples\")\\n    ax[1].scatter(recon[:, 0], recon[:, 1], c = data_sampler.sample_labels)\\n    ax[1].set_xlabel(r\"$x_1$\")\\n    ax[1].set_ylabel(r\"$x_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/reconstruction_scatter_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Reconstruction\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Mixed samples\")\\n    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 0])\\n    ax[0].plot(data_sampler.mixed_data.cpu().numpy()[:, 1])\\n    ax[0].set_xlabel(r\"$x_1$\")\\n    ax[0].set_ylabel(r\"$x_2$\")\\n    \\n    ax[1].set_title(\"Reconstructed samples\")\\n    ax[1].plot(recon[:, 0])\\n    ax[1].plot(recon[:, 1])\\n    ax[1].set_xlabel(r\"$x_1$\")\\n    ax[1].set_ylabel(r\"$x_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/reconstruction_signals_\" + fig_label + \".png\")\\n    plt.show()\\n\\n    #Sources\\n    fig, ax = plt.subplots(1, 2, figsize = (12, 8))\\n    ax = ax.flatten()\\n    ax[0].set_title(\"Original sources\")\\n    ax[0].plot(data_sampler.data.cpu().numpy()[:, 0])\\n    ax[0].plot(data_sampler.data.cpu().numpy()[:, 1])\\n    ax[0].set_xlabel(r\"$z_1$\")\\n    ax[0].set_ylabel(r\"$z_2$\")\\n    \\n    ax[1].set_title(\"Latent sources\")\\n    ax[1].plot(mu_z[:, 0])\\n    ax[1].plot(mu_z[:, 1])\\n    ax[1].set_xlabel(r\"$z_1$\")\\n    ax[1].set_ylabel(r\"$z_2$\")\\n    plt.tight_layout()\\n\\n    if save_fig_flag:\\n        plt.tight_layout()\\n        plt.savefig(\"./tmp_figures/source_signals_\" + fig_label + \".png\")\\n    plt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG6iC5tRCa0a"
      },
      "source": [
        "# MNIST test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdRLIYtoCaS3",
        "outputId": "b186b883-3446-43b2-848e-16a11fc2e4b0"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "transform_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x)),])#(0.1307,), (0.3081,)\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=512, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=512, shuffle=True)\n",
        "\n",
        "\n",
        "a = iter(train_loader)\n",
        "print(next(a)[0][0, :])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3804, 0.9373,\n",
            "        0.5373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0510, 0.1098, 0.4627, 0.4627, 0.4627, 0.7882,\n",
            "        0.9922, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1686, 0.4549, 0.8784, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9961, 0.9686, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0745, 0.6824, 0.9569, 0.9922, 0.9569, 0.8353, 0.8353, 0.4863,\n",
            "        0.8078, 0.9961, 0.7059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.2392, 0.8118, 0.9922, 0.9294, 0.6078, 0.3255, 0.0000, 0.0000,\n",
            "        0.0000, 0.3843, 0.9961, 0.5294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0392, 0.5255, 1.0000, 0.9961, 0.8353, 0.2078, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.7686, 1.0000, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0549, 0.8078, 0.9922, 0.9961, 0.9255, 0.1647, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.7647, 0.9765, 0.1412, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.2902, 0.8980, 0.9922, 0.8706, 0.4549, 0.1647, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1098, 0.9216, 0.7647, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.2157, 0.9804, 0.9922, 0.9922, 0.6667, 0.5373, 0.5333, 0.5333, 0.5333,\n",
            "        0.5333, 0.5373, 0.5333, 0.4196, 0.7255, 0.9922, 0.8000, 0.0824, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5255, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.8863,\n",
            "        0.7647, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1804, 0.9608, 0.9961, 0.9961, 0.9961, 1.0000, 0.9961,\n",
            "        0.9216, 0.8902, 0.9961, 1.0000, 0.8157, 0.9961, 0.9961, 0.9961, 1.0000,\n",
            "        0.9961, 0.9961, 0.9961, 0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.1529, 0.1529, 0.1529, 0.1529,\n",
            "        0.1529, 0.1059, 0.0824, 0.1529, 0.1529, 0.0353, 0.7020, 0.9922, 0.8118,\n",
            "        0.4471, 0.3294, 0.5294, 0.1804, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.9922,\n",
            "        0.3451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863,\n",
            "        0.7882, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "        0.9216, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4627, 0.9961, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.4902, 0.9686, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.8392, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.8392, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.3059, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "k0wzXF2sDW3P",
        "outputId": "654ccd9c-8e80-4a86-b91a-b8dddece0994"
      },
      "source": [
        "data_size = 784\n",
        "no_classes = 10\n",
        "latent_size = 100\n",
        "\n",
        "k = 2\n",
        "L = 1024\n",
        "mixL = 2\n",
        "batch_size = 128\n",
        "CURL_flag = False\n",
        "\n",
        "epochs = 100\n",
        "#data_sampler = iVAE_datasets(data_size, no_classes, L, k, batch_size = batch_size, randomise = True, random_seed = False, mod_flag = False, mix_L = mixL, Gauss_source = False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encode_dict = { \"ff_layers\":[data_size, 512, 256, 128, latent_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "decode_dict = { \"ff_layers\":[latent_size, 512, 256, 128, data_size],\n",
        "                \"conv_flag\":False }\n",
        "\n",
        "prior_dict = {  \"ff_layers\":[no_classes, 512, 256, 128, latent_size],\n",
        "                 \"conv_flag\":False }\n",
        "\n",
        "model = MoG_VAE_model(data_size, latent_size, no_classes, encode_dict, decode_dict, prior_dict, var_decode = False, continuous_prior = False, CURL_flag = CURL_flag)\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  #print(mu_zp, var_zp)\n",
        "\n",
        "MoG_VAE_opt = MoG_VAE_optimiser(model, Params = None)\n",
        "MoG_VAE_cost = MoG_VAE_loss(no_classes, \"BCE\", gamma = 0, beta = 0, alpha = 10000)\n",
        "my_trainer = MoG_VAE_trainer(model, MoG_VAE_opt, MoG_VAE_cost, train_loader, test_loader, epochs) #Not correct, as we need to split train into 80-20 but ignored for now\n",
        "\n",
        "my_trainer.train_model()\n",
        "my_trainer.plotter()\n",
        "\n",
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "cost at epoch 0: inf:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Take note, this decoder also returns the latent sample, as you need it for the VaDE estimation step (and if you want to do it analytically)\n",
            "Making binary layer\n",
            "\n",
            "\n",
            "default LR is 1e-3.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e7b377917e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmy_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoG_VAE_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoG_VAE_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoG_VAE_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Not correct, as we need to split train into 80-20 but ignored for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mmy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-e5535eca6d5a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mq_y_G_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_y_G_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mcost_train_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-e5535eca6d5a>\u001b[0m in \u001b[0;36moptimise\u001b[0;34m(self, real_data, recon_data, mu_z_encoder, var_z_encoder, mu_z_prior, var_z_prior, q_y_G_x, update)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_y_G_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#compute and return loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_kl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_z_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_y_G_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURL_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-b693af7105f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, recon_x, mu_0, var_0, mu_1, var_1, q_y_G_x, prior_prob, CURL)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mLrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mLrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLrecon\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Sum all values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIwcgkEmnzE"
      },
      "source": [
        "with torch.no_grad():\n",
        "  labels = torch.arange(0, no_classes)\n",
        "  U = torch.eye(no_classes)\n",
        "  mu_zp, var_zp = model.prior(U)#\n",
        "\n",
        "  mu_zp = mu_zp.cpu().numpy()\n",
        "  var_zp = var_zp.cpu().numpy()\n",
        "\n",
        "  print(mu_zp, var_zp)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(mu_zp[:, 0], mu_zp[:, 1])\n",
        "plt.show()\n",
        "\n",
        "q_post = []\n",
        "q_curl = []\n",
        "l_list = []\n",
        "\n",
        "for i in test_loader:\n",
        "    d, l = i\n",
        "    d = d.to(\"cuda:0\")\n",
        "    q_y_G_x_post, q_y_G_x_curl = model.infer_label(d)\n",
        "\n",
        "    q_y_G_x_post = q_y_G_x_post.detach().cpu().numpy()\n",
        "    q_y_G_x_curl = q_y_G_x_curl.detach().cpu().numpy()\n",
        "    l = l.numpy()\n",
        "\n",
        "    q_post.append(q_y_G_x_post)\n",
        "    q_curl.append(q_y_G_x_curl)\n",
        "    l_list.append(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X_CcT0mvYd4"
      },
      "source": [
        "print(q_y_G_x_curl, \"\\n\\n\")\n",
        "print(q_y_G_x_post, \"\\n\\n\")\n",
        "print(l.shape, \"\\n\\n\")\n",
        "\n",
        "d, l = next(iter(test_loader))\n",
        "d = d.to(\"cuda:0\")\n",
        "print(l)\n",
        "\n",
        "o = model.encoder(d)\n",
        "\n",
        "print(o[2])\n",
        "print(torch.argmax(o[2], dim = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq9GjeEKeI6U"
      },
      "source": [
        "\n",
        "for scale in [1, 10, 100, 1000, 10000]:\n",
        "  a = torch.rand(10, 10, requires_grad = False)\n",
        "  a[:, 0] = scale\n",
        "  for i in range(a.size(0)):\n",
        "      a[i, :] /= torch.sum(torch.sqrt(a[i, :]**2))\n",
        "\n",
        "  a = a.requires_grad_(True)\n",
        "  #print(a)\n",
        "\n",
        "  l = discrete_KL_divergence(10)\n",
        "  a = torch.repeat_interleave(a, 10, dim =0)\n",
        "  print(l(a, torch.ones(1,10)/10)[1])\n",
        "\n",
        "#a = a / torch.sum(a)\n",
        "\n",
        "#print(a)\n",
        "#print(-1 * torch.sum(a * torch.log(a)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}